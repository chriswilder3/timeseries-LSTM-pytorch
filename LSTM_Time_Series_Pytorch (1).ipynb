{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxneaj3TSwOL",
        "outputId": "97504cdd-22f9-4607-c714-0ac7e7de077c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opendatasets\n",
            "  Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from opendatasets) (4.66.2)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (from opendatasets) (1.5.16)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from opendatasets) (8.1.7)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.31.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle->opendatasets) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (3.6)\n",
            "Installing collected packages: opendatasets\n",
            "Successfully installed opendatasets-0.1.22\n"
          ]
        }
      ],
      "source": [
        "pip install opendatasets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the data from Kaggle"
      ],
      "metadata": {
        "id": "LlJgGaqzXdlA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import opendatasets as od\n",
        "od.download('https://www.kaggle.com/datasets/shenba/time-series-datasets/data')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VRpI0CUUG5j",
        "outputId": "888f3a2e-6b90-4a11-b70e-948ad354744a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: sachinsd\n",
            "Your Kaggle Key: ··········\n",
            "Downloading time-series-datasets.zip to ./time-series-datasets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 19.2k/19.2k [00:00<00:00, 21.3MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "z4IDPTdTUM9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('time-series-datasets/Electric_Production.csv',index_col='DATE',parse_dates=True)"
      ],
      "metadata": {
        "id": "60zRx7KtUhiY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "iF4826dCUlLs",
        "outputId": "6a7bea1d-3693-46d1-b283-95df55bdd347"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            IPG2211A2N\n",
              "DATE                  \n",
              "1985-01-01     72.5052\n",
              "1985-02-01     70.6720\n",
              "1985-03-01     62.4502\n",
              "1985-04-01     57.4714\n",
              "1985-05-01     55.3151"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-400030ec-0848-4ca3-aff6-c3b59ace1a91\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>IPG2211A2N</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DATE</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1985-01-01</th>\n",
              "      <td>72.5052</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1985-02-01</th>\n",
              "      <td>70.6720</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1985-03-01</th>\n",
              "      <td>62.4502</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1985-04-01</th>\n",
              "      <td>57.4714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1985-05-01</th>\n",
              "      <td>55.3151</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-400030ec-0848-4ca3-aff6-c3b59ace1a91')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-400030ec-0848-4ca3-aff6-c3b59ace1a91 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-400030ec-0848-4ca3-aff6-c3b59ace1a91');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b7eb53ba-b02a-4065-9da7-31c89fda5c5e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b7eb53ba-b02a-4065-9da7-31c89fda5c5e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b7eb53ba-b02a-4065-9da7-31c89fda5c5e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 397,\n  \"fields\": [\n    {\n      \"column\": \"DATE\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"1985-01-01 00:00:00\",\n        \"max\": \"2018-01-01 00:00:00\",\n        \"num_unique_values\": 397,\n        \"samples\": [\n          \"1994-07-01 00:00:00\",\n          \"2008-03-01 00:00:00\",\n          \"2004-10-01 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"IPG2211A2N\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 15.387833664730902,\n        \"min\": 55.3151,\n        \"max\": 129.4048,\n        \"num_unique_values\": 397,\n        \"samples\": [\n          83.277,\n          100.4386,\n          87.5262\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.plot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "6ya2Ib_uU5aB",
        "outputId": "bd7f05f5-d647-4c3e-f14e-e99a2e90ce9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: xlabel='DATE'>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Pre-Process**\n",
        "\n",
        "Time Series data needs to arranged in Sliding Window format for training. So that, all the values (except last) in the Window are taken as X, and the value at the next timestep (last element of Window) is taken as Y. So We make as many sliding windows as possible for training."
      ],
      "metadata": {
        "id": "XtpZpJA7WKPq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "winSize = 12\n",
        "nFeatures = 1 #Here the Data is single variable only"
      ],
      "metadata": {
        "id": "T-8JHfTcV_tp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = data.copy()"
      ],
      "metadata": {
        "id": "0CsmwuKAXscu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scale the Data (normalize) since we are using RNN"
      ],
      "metadata": {
        "id": "zJWDg4ldXxg3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "trainScaled = scaler.fit_transform(train)"
      ],
      "metadata": {
        "id": "V9GP_LqDXvaD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A function to extract data in sliding windows\n",
        "\n",
        "def slidingWindow( data, winSize):\n",
        "  Xtrain = []\n",
        "  ytrain = []\n",
        "  for i in range( winSize, len(data) ):\n",
        "    # Here i points to end of Window at each iteration, So minus it by winSize to go to start of window\n",
        "    Xtrain.append( data[i-winSize:i] ) #Note, this will select all elements as X except last element i because of slicing\n",
        "    ytrain.append( data[i] ) # Make ith(end of window) element as Y instance values\n",
        "  return np.array(Xtrain), np.array(ytrain) # Convert them to np arrays since torch uses that"
      ],
      "metadata": {
        "id": "k5yB1IWjZNBs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X , y = slidingWindow(trainScaled , winSize)"
      ],
      "metadata": {
        "id": "txOCRu1BaS3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fCBU_idotNGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print Sample data format\n",
        "print( f\" Given Time series X values :\\n {X[0].flatten()}\" )\n",
        "print( f\" The next Time Step value Y is : {y[0]} \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpPaZ9GAcQ7T",
        "outputId": "d7e61010-62c9-4caf-bc09-a41793e95616"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Given Time series X values :\n",
            " [0.23201741 0.20727443 0.09630353 0.02910391 0.         0.03745865\n",
            " 0.09859805 0.10707831 0.07112325 0.0135012  0.03624525 0.18085375]\n",
            " The next Time Step value Y is : [0.24282188] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Make Train, Test Split:**\n",
        "\n",
        "We use last 3 windows data as test, all previous of it as Training data"
      ],
      "metadata": {
        "id": "7tBc1joMdxpx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainSize = len(train) - winSize*3\n",
        "\n",
        "testSize = len(train) - trainSize"
      ],
      "metadata": {
        "id": "A-I05eHlc_Jl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "xy7XTn9yh3GE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xtrain = torch.tensor( np.array( X[:trainSize] ) , requires_grad = True)\n",
        "ytrain = torch.tensor( np.array( y[:trainSize] ) , requires_grad = True)\n",
        "\n",
        "Xtest = torch.tensor( np.array( X[testSize:] ) , requires_grad = True)\n",
        "ytest = torch.tensor( np.array( y[testSize:] ) , requires_grad = True)"
      ],
      "metadata": {
        "id": "PuQsH67QerVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xtrain.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9-RBChOty7Q",
        "outputId": "29ce6369-30d8-4928-95df-0997da73256e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([361, 12, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.functional as F"
      ],
      "metadata": {
        "id": "daRKdu1MpzX6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LSTM Architecture Define**\n",
        "\n",
        "Note that in LSTM,\n",
        "\n",
        "input_size is the number of features of X,\n",
        "hidden_size is the number of neurons in hidden layer\n",
        "num_layers is the number of hidden layers.\n",
        "\n",
        "Also Since the dimension of our data is of the form (batch_size i.e number of windows , seq_size i.e window size, number of features)\n",
        "instead of the standard (seq_size, batch_size, no of features), We need to give option **batch_first = True**\n",
        "# ---------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "ENcWuHGxe7RP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note : The fully connected layers, dense layers (also known as fully connected layers) are used after the LSTM layer for several reasons:\n",
        "\n",
        "Dimensionality Reduction: LSTM outputs may have a high dimensionality, which can be reduced to a manageable size using fully connected layers.\n",
        "\n",
        "Feature Extraction: While LSTM layers capture temporal dependencies well, they may not always extract the most relevant features. Fully connected layers enable additional feature extraction, allowing the model to learn abstract representations from LSTM outputs.\n",
        "\n",
        "Non-linearity: LSTM outputs are often sequences of hidden states and may lack complex non-linear relationships in the data. Fully connected layers followed by non-linear activation functions, such as ReLU, enable the model to learn more complex mappings between input and output.\n",
        "\n",
        "Output Transformation: The direct output of LSTM layers may not always be interpretable or suitable for the task at hand. Fully connected layers facilitate the transformation of LSTM outputs into the desired output format, such as scalar values or class probabilities, making them more interpretable and suitable for the task.\n",
        "\n",
        "Overall, the combination of LSTM layers followed by fully connected layers allows the model to effectively learn from sequential data while also extracting relevant features and transforming the output for the task at hand"
      ],
      "metadata": {
        "id": "rm9BDVe8o5R9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class myLSTM( nn.Module ):\n",
        "\n",
        "  def __init__( self, inSize , hiddenSize, nLayers ):\n",
        "    super().__init__()\n",
        "\n",
        "    self.inSize = inSize\n",
        "    self.hiddenSize = hiddenSize\n",
        "    self.nLayers = nLayers\n",
        "\n",
        "    self.LSTM = nn.LSTM ( input_size = self.inSize,\n",
        "                          hidden_size = self.hiddenSize,\n",
        "                          num_layers = self.nLayers,\n",
        "                          batch_first = True\n",
        "                        )\n",
        "\n",
        "    self.fc1 = nn.Linear( in_features = self.hiddenSize, out_features = 40)\n",
        "    # Fully connected Layer, takes output of LSTM, has 40 neuron outputs\n",
        "    self.fc2 = nn.Linear(in_features = 40, out_features =1)\n",
        "    # 2nd FC, takes o/p of fc1, has one nueron output to be used for prediction\n",
        "\n",
        "    self.relu = nn.ReLU() #Rectified Linear Unit act. fun\n",
        "\n",
        "  def forward( self, x):\n",
        "\n",
        "    # Define the hidden and cell states of LSTM (have size = (layers X batchsize X hiddensize)\n",
        "    # since its not stackedRNN hence layers = 1\n",
        "    # batchsize in the number of windows i.e, Xtrain.size(0)\n",
        "    # and these states are initialized to 0 )\n",
        "\n",
        "    h0 = torch.zeros ( self.nLayers, x.size(0), self.hiddenSize )\n",
        "    c0 = torch.zeros ( self.nLayers, x.size(0), self.hiddenSize )\n",
        "\n",
        "    _ , ( hout , _ ) = self.LSTM( x, ( h0, c0 ) )\n",
        "    # The input format of LSTM is (inputdata, (h_0, c_0))\n",
        "    # The output format of LSTM is (outputdata, (h_n, c_n))\n",
        "    # We are not interested in outputdata, which packs the output of LSTM(h_t) at each timestep\n",
        "    # Note that here we only require final hidden state of LSTM at the last stage i.e, h_n hence we ignore others as _\n",
        "\n",
        "    hout = hout.view( -1, self.hiddenSize )\n",
        "\n",
        "    # View works similar to reshape but The new tensor will always share its data with the original tensor.\n",
        "    # This means that if you change the original tensor, the reshaped tensor will change and vice versa.\n",
        "    # if we give -1, PyTorch should infer the size of that dimension based on the size of the other dimensions\n",
        "    # and the total number of elements in the tensor.\n",
        "    # We did this since we are going to pass hout to fc1 which expects 'hiddenSize' input\n",
        "\n",
        "    out = self.fc2( self.relu( self.fc1( hout ) ) )\n",
        "\n",
        "    return out\n"
      ],
      "metadata": {
        "id": "HZ14lNpCfuhL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set Training Parameters"
      ],
      "metadata": {
        "id": "nEksYLifSBlj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 2000\n",
        "lr = 0.002\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "inputSize = nFeatures # inp embedding size i.e, no of features in the X\n",
        "hiddenSize = 100      # Hidden layer neurons\n",
        "nLayers = 1           # no of layers\n",
        "\n",
        "Model = myLSTM( inputSize, hiddenSize, nLayers )\n",
        "Model.to( device )\n",
        "\n",
        "print( Model)\n",
        "\n",
        "loss = torch.nn.MSELoss()\n",
        "opt = torch.optim.Adam( Model.parameters() , lr )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzXeEyl7ppUt",
        "outputId": "2910732e-30f0-4342-92cd-b68f74bc412b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "myLSTM(\n",
            "  (LSTM): LSTM(1, 100, batch_first=True)\n",
            "  (fc1): Linear(in_features=100, out_features=40, bias=True)\n",
            "  (fc2): Linear(in_features=40, out_features=1, bias=True)\n",
            "  (relu): ReLU()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training Loop**"
      ],
      "metadata": {
        "id": "z6jBwvMEUZjn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "early_stop_patience = 100 # no of epochs without improvement after which model stops immediately\n",
        "early_stop_counter = 0 # keeps track no of epochs without improvement in metrics\n",
        "\n",
        "valid_loss_min = np.inf # initially assume loss to +infinity, it changes gradually to min values\n",
        "\n",
        "for ep in range(epochs):\n",
        "\n",
        "  opt.zero_grad() # Clears the calculated gradients of all variables in the prev. iteration\n",
        "                  # so that new iter. grads are calculated. This must be done before backward pass of this iter.\n",
        "\n",
        "  Model.train()  # put the model in training mode, which enables features like dropout, batch normalization\n",
        "\n",
        "  Xtrain = Xtrain.float()\n",
        "  ytrain = ytrain.float()\n",
        "  Xtest = Xtest.float()\n",
        "  ytest = ytest.float() # Pytorch expects dtype to float32\n",
        "\n",
        "  output = Model( Xtrain )  # Actually train the model on Xtrain and get the output\n",
        "\n",
        "  trainloss = loss( output, ytrain ) # compare the ypred with ytrain and get the loss(mse here)\n",
        "                                # Note the object returned here is a loss function which can be used\n",
        "                                # in backward propogation\n",
        "\n",
        "  trainloss.backward() # Perform backward propogation pass, Here backward only calculates the gradients of\n",
        "                  # loss function wrt parameters (weights) of the model.i.e, calculate dL/dW\n",
        "  opt.step()  # Actually updates the weights of model using calculated gradients Wn = Wold - lr*(dL/dw)\n",
        "\n",
        "  # Now the Evalulation of model starts. During this time we need to disable gradient updation\n",
        "  # So that stable values are estimated. Hence we use no_grad context of torch\n",
        "\n",
        "  with torch.no_grad():\n",
        "\n",
        "    Model.eval()  # put the model in eval mode to disable dropout, batch normalization\n",
        "\n",
        "    outputVal = Model( Xtest )          # calculated the validation output and corresponding loss\n",
        "    validLoss = loss( outputVal, ytest )\n",
        "\n",
        "    if validLoss <= valid_loss_min:\n",
        "\n",
        "      torch.save( Model.state_dict() , './state_dict.pt' ) # save the models state dict in current folder\n",
        "\n",
        "      print(f' epoch : {ep}, Validation loss decreased : {valid_loss_min} --> {validLoss} ' )\n",
        "\n",
        "      valid_loss_min = validLoss\n",
        "\n",
        "      early_stop_counter = 0 # if the loss decreased set counter to 0\n",
        "\n",
        "    else:\n",
        "      early_stop_counter += 1 # if the loss is not decreased\n",
        "      print(f' epoch : {ep}, validation loss did not decrease ')\n",
        "\n",
        "    if early_stop_counter > early_stop_patience :\n",
        "      # if the loss remains same for too long\n",
        "      print('stopping early ', ep)\n",
        "\n",
        "    print(f' Training loss : {trainloss} , validation_loss : {validLoss} , Best Valid Loss : {valid_loss_min} ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pc8ocf_MUces",
        "outputId": "2191d1d2-0d28-4b88-dc01-686023d8ee2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " epoch : 0, Validation loss decreased : inf --> 0.21613545715808868 \n",
            " Training loss : 0.21447406709194183 , validation_loss : 0.21613545715808868 , Best Valid Loss : 0.21613545715808868 \n",
            " epoch : 1, Validation loss decreased : 0.21613545715808868 --> 0.18813903629779816 \n",
            " Training loss : 0.18700814247131348 , validation_loss : 0.18813903629779816 , Best Valid Loss : 0.18813903629779816 \n",
            " epoch : 2, Validation loss decreased : 0.18813903629779816 --> 0.16229543089866638 \n",
            " Training loss : 0.16209964454174042 , validation_loss : 0.16229543089866638 , Best Valid Loss : 0.16229543089866638 \n",
            " epoch : 3, Validation loss decreased : 0.16229543089866638 --> 0.13884589076042175 \n",
            " Training loss : 0.13928797841072083 , validation_loss : 0.13884589076042175 , Best Valid Loss : 0.13884589076042175 \n",
            " epoch : 4, Validation loss decreased : 0.13884589076042175 --> 0.11452673375606537 \n",
            " Training loss : 0.11885053664445877 , validation_loss : 0.11452673375606537 , Best Valid Loss : 0.11452673375606537 \n",
            " epoch : 5, Validation loss decreased : 0.11452673375606537 --> 0.08858566731214523 \n",
            " Training loss : 0.09798119962215424 , validation_loss : 0.08858566731214523 , Best Valid Loss : 0.08858566731214523 \n",
            " epoch : 6, Validation loss decreased : 0.08858566731214523 --> 0.061120469123125076 \n",
            " Training loss : 0.07620314508676529 , validation_loss : 0.061120469123125076 , Best Valid Loss : 0.061120469123125076 \n",
            " epoch : 7, Validation loss decreased : 0.061120469123125076 --> 0.03549940511584282 \n",
            " Training loss : 0.05406360328197479 , validation_loss : 0.03549940511584282 , Best Valid Loss : 0.03549940511584282 \n",
            " epoch : 8, Validation loss decreased : 0.03549940511584282 --> 0.028628423810005188 \n",
            " Training loss : 0.035670891404151917 , validation_loss : 0.028628423810005188 , Best Valid Loss : 0.028628423810005188 \n",
            " epoch : 9, validation loss did not decrease \n",
            " Training loss : 0.038422372192144394 , validation_loss : 0.043481625616550446 , Best Valid Loss : 0.028628423810005188 \n",
            " epoch : 10, validation loss did not decrease \n",
            " Training loss : 0.058477893471717834 , validation_loss : 0.037365637719631195 , Best Valid Loss : 0.028628423810005188 \n",
            " epoch : 11, Validation loss decreased : 0.028628423810005188 --> 0.02828901633620262 \n",
            " Training loss : 0.05076193809509277 , validation_loss : 0.02828901633620262 , Best Valid Loss : 0.02828901633620262 \n",
            " epoch : 12, Validation loss decreased : 0.02828901633620262 --> 0.026715818792581558 \n",
            " Training loss : 0.03782757744193077 , validation_loss : 0.026715818792581558 , Best Valid Loss : 0.026715818792581558 \n",
            " epoch : 13, validation loss did not decrease \n",
            " Training loss : 0.03226310759782791 , validation_loss : 0.03028375655412674 , Best Valid Loss : 0.026715818792581558 \n",
            " epoch : 14, validation loss did not decrease \n",
            " Training loss : 0.03259873762726784 , validation_loss : 0.03507056459784508 , Best Valid Loss : 0.026715818792581558 \n",
            " epoch : 15, validation loss did not decrease \n",
            " Training loss : 0.03508942201733589 , validation_loss : 0.038957465440034866 , Best Valid Loss : 0.026715818792581558 \n",
            " epoch : 16, validation loss did not decrease \n",
            " Training loss : 0.037517763674259186 , validation_loss : 0.041209347546100616 , Best Valid Loss : 0.026715818792581558 \n",
            " epoch : 17, validation loss did not decrease \n",
            " Training loss : 0.03899756073951721 , validation_loss : 0.04175548255443573 , Best Valid Loss : 0.026715818792581558 \n",
            " epoch : 18, validation loss did not decrease \n",
            " Training loss : 0.039326585829257965 , validation_loss : 0.040800075978040695 , Best Valid Loss : 0.026715818792581558 \n",
            " epoch : 19, validation loss did not decrease \n",
            " Training loss : 0.03860898315906525 , validation_loss : 0.03866446763277054 , Best Valid Loss : 0.026715818792581558 \n",
            " epoch : 20, validation loss did not decrease \n",
            " Training loss : 0.03709059953689575 , validation_loss : 0.03573776036500931 , Best Valid Loss : 0.026715818792581558 \n",
            " epoch : 21, validation loss did not decrease \n",
            " Training loss : 0.03509846702218056 , validation_loss : 0.032466690987348557 , Best Valid Loss : 0.026715818792581558 \n",
            " epoch : 22, validation loss did not decrease \n",
            " Training loss : 0.03301839902997017 , validation_loss : 0.029342802241444588 , Best Valid Loss : 0.026715818792581558 \n",
            " epoch : 23, validation loss did not decrease \n",
            " Training loss : 0.031268879771232605 , validation_loss : 0.0268496572971344 , Best Valid Loss : 0.026715818792581558 \n",
            " epoch : 24, Validation loss decreased : 0.026715818792581558 --> 0.025336435064673424 \n",
            " Training loss : 0.030234402045607567 , validation_loss : 0.025336435064673424 , Best Valid Loss : 0.025336435064673424 \n",
            " epoch : 25, Validation loss decreased : 0.025336435064673424 --> 0.024830128997564316 \n",
            " Training loss : 0.03012820892035961 , validation_loss : 0.024830128997564316 , Best Valid Loss : 0.024830128997564316 \n",
            " epoch : 26, validation loss did not decrease \n",
            " Training loss : 0.03080684319138527 , validation_loss : 0.024928081780672073 , Best Valid Loss : 0.024830128997564316 \n",
            " epoch : 27, validation loss did not decrease \n",
            " Training loss : 0.031693100929260254 , validation_loss : 0.02500837855041027 , Best Valid Loss : 0.024830128997564316 \n",
            " epoch : 28, Validation loss decreased : 0.024830128997564316 --> 0.024714739993214607 \n",
            " Training loss : 0.03204729035496712 , validation_loss : 0.024714739993214607 , Best Valid Loss : 0.024714739993214607 \n",
            " epoch : 29, Validation loss decreased : 0.024714739993214607 --> 0.024204082787036896 \n",
            " Training loss : 0.03150464594364166 , validation_loss : 0.024204082787036896 , Best Valid Loss : 0.024204082787036896 \n",
            " epoch : 30, Validation loss decreased : 0.024204082787036896 --> 0.023891011252999306 \n",
            " Training loss : 0.030320370569825172 , validation_loss : 0.023891011252999306 , Best Valid Loss : 0.023891011252999306 \n",
            " epoch : 31, validation loss did not decrease \n",
            " Training loss : 0.029067568480968475 , validation_loss : 0.024051222950220108 , Best Valid Loss : 0.023891011252999306 \n",
            " epoch : 32, validation loss did not decrease \n",
            " Training loss : 0.028188806027173996 , validation_loss : 0.024662736803293228 , Best Valid Loss : 0.023891011252999306 \n",
            " epoch : 33, validation loss did not decrease \n",
            " Training loss : 0.02780294232070446 , validation_loss : 0.02548723854124546 , Best Valid Loss : 0.023891011252999306 \n",
            " epoch : 34, validation loss did not decrease \n",
            " Training loss : 0.02777310088276863 , validation_loss : 0.02622079662978649 , Best Valid Loss : 0.023891011252999306 \n",
            " epoch : 35, validation loss did not decrease \n",
            " Training loss : 0.027858853340148926 , validation_loss : 0.026605557650327682 , Best Valid Loss : 0.023891011252999306 \n",
            " epoch : 36, validation loss did not decrease \n",
            " Training loss : 0.027835290879011154 , validation_loss : 0.02648553065955639 , Best Valid Loss : 0.023891011252999306 \n",
            " epoch : 37, validation loss did not decrease \n",
            " Training loss : 0.027556102722883224 , validation_loss : 0.025826236233115196 , Best Valid Loss : 0.023891011252999306 \n",
            " epoch : 38, validation loss did not decrease \n",
            " Training loss : 0.026977386325597763 , validation_loss : 0.024715838953852654 , Best Valid Loss : 0.023891011252999306 \n",
            " epoch : 39, Validation loss decreased : 0.023891011252999306 --> 0.0233520045876503 \n",
            " Training loss : 0.026159247383475304 , validation_loss : 0.0233520045876503 , Best Valid Loss : 0.0233520045876503 \n",
            " epoch : 40, Validation loss decreased : 0.0233520045876503 --> 0.022003330290317535 \n",
            " Training loss : 0.02524968795478344 , validation_loss : 0.022003330290317535 , Best Valid Loss : 0.022003330290317535 \n",
            " epoch : 41, Validation loss decreased : 0.022003330290317535 --> 0.020924439653754234 \n",
            " Training loss : 0.02444128319621086 , validation_loss : 0.020924439653754234 , Best Valid Loss : 0.020924439653754234 \n",
            " epoch : 42, Validation loss decreased : 0.020924439653754234 --> 0.020222840830683708 \n",
            " Training loss : 0.023884013295173645 , validation_loss : 0.020222840830683708 , Best Valid Loss : 0.020222840830683708 \n",
            " epoch : 43, Validation loss decreased : 0.020222840830683708 --> 0.019761472940444946 \n",
            " Training loss : 0.02356058731675148 , validation_loss : 0.019761472940444946 , Best Valid Loss : 0.019761472940444946 \n",
            " epoch : 44, Validation loss decreased : 0.019761472940444946 --> 0.019273074343800545 \n",
            " Training loss : 0.023218046873807907 , validation_loss : 0.019273074343800545 , Best Valid Loss : 0.019273074343800545 \n",
            " epoch : 45, Validation loss decreased : 0.019273074343800545 --> 0.01867903210222721 \n",
            " Training loss : 0.02252689190208912 , validation_loss : 0.01867903210222721 , Best Valid Loss : 0.01867903210222721 \n",
            " epoch : 46, Validation loss decreased : 0.01867903210222721 --> 0.018203383311629295 \n",
            " Training loss : 0.02142949402332306 , validation_loss : 0.018203383311629295 , Best Valid Loss : 0.018203383311629295 \n",
            " epoch : 47, Validation loss decreased : 0.018203383311629295 --> 0.018045831471681595 \n",
            " Training loss : 0.02024609036743641 , validation_loss : 0.018045831471681595 , Best Valid Loss : 0.018045831471681595 \n",
            " epoch : 48, Validation loss decreased : 0.018045831471681595 --> 0.01800660975277424 \n",
            " Training loss : 0.019322482869029045 , validation_loss : 0.01800660975277424 , Best Valid Loss : 0.01800660975277424 \n",
            " epoch : 49, Validation loss decreased : 0.01800660975277424 --> 0.017540663480758667 \n",
            " Training loss : 0.01862935721874237 , validation_loss : 0.017540663480758667 , Best Valid Loss : 0.017540663480758667 \n",
            " epoch : 50, Validation loss decreased : 0.017540663480758667 --> 0.01629265397787094 \n",
            " Training loss : 0.01777232065796852 , validation_loss : 0.01629265397787094 , Best Valid Loss : 0.01629265397787094 \n",
            " epoch : 51, Validation loss decreased : 0.01629265397787094 --> 0.014723661355674267 \n",
            " Training loss : 0.0164490994066 , validation_loss : 0.014723661355674267 , Best Valid Loss : 0.014723661355674267 \n",
            " epoch : 52, Validation loss decreased : 0.014723661355674267 --> 0.013974673114717007 \n",
            " Training loss : 0.014988349750638008 , validation_loss : 0.013974673114717007 , Best Valid Loss : 0.013974673114717007 \n",
            " epoch : 53, Validation loss decreased : 0.013974673114717007 --> 0.013763073831796646 \n",
            " Training loss : 0.014191706664860249 , validation_loss : 0.013763073831796646 , Best Valid Loss : 0.013763073831796646 \n",
            " epoch : 54, Validation loss decreased : 0.013763073831796646 --> 0.013006893917918205 \n",
            " Training loss : 0.013578933663666248 , validation_loss : 0.013006893917918205 , Best Valid Loss : 0.013006893917918205 \n",
            " epoch : 55, validation loss did not decrease \n",
            " Training loss : 0.012339961715042591 , validation_loss : 0.013582048006355762 , Best Valid Loss : 0.013006893917918205 \n",
            " epoch : 56, validation loss did not decrease \n",
            " Training loss : 0.012468171305954456 , validation_loss : 0.013829605653882027 , Best Valid Loss : 0.013006893917918205 \n",
            " epoch : 57, validation loss did not decrease \n",
            " Training loss : 0.012617158703505993 , validation_loss : 0.014225793071091175 , Best Valid Loss : 0.013006893917918205 \n",
            " epoch : 58, validation loss did not decrease \n",
            " Training loss : 0.01288695354014635 , validation_loss : 0.015102451667189598 , Best Valid Loss : 0.013006893917918205 \n",
            " epoch : 59, validation loss did not decrease \n",
            " Training loss : 0.013636327348649502 , validation_loss : 0.014752590097486973 , Best Valid Loss : 0.013006893917918205 \n",
            " epoch : 60, validation loss did not decrease \n",
            " Training loss : 0.013569880276918411 , validation_loss : 0.014812513254582882 , Best Valid Loss : 0.013006893917918205 \n",
            " epoch : 61, validation loss did not decrease \n",
            " Training loss : 0.013638104312121868 , validation_loss : 0.014172164723277092 , Best Valid Loss : 0.013006893917918205 \n",
            " epoch : 62, validation loss did not decrease \n",
            " Training loss : 0.01289677806198597 , validation_loss : 0.014132710173726082 , Best Valid Loss : 0.013006893917918205 \n",
            " epoch : 63, validation loss did not decrease \n",
            " Training loss : 0.012779757380485535 , validation_loss : 0.013334867544472218 , Best Valid Loss : 0.013006893917918205 \n",
            " epoch : 64, validation loss did not decrease \n",
            " Training loss : 0.012135028839111328 , validation_loss : 0.013215895742177963 , Best Valid Loss : 0.013006893917918205 \n",
            " epoch : 65, validation loss did not decrease \n",
            " Training loss : 0.0120646758005023 , validation_loss : 0.013094620779156685 , Best Valid Loss : 0.013006893917918205 \n",
            " epoch : 66, Validation loss decreased : 0.013006893917918205 --> 0.01280246116220951 \n",
            " Training loss : 0.0119981924071908 , validation_loss : 0.01280246116220951 , Best Valid Loss : 0.01280246116220951 \n",
            " epoch : 67, validation loss did not decrease \n",
            " Training loss : 0.011834284290671349 , validation_loss : 0.012806527316570282 , Best Valid Loss : 0.01280246116220951 \n",
            " epoch : 68, validation loss did not decrease \n",
            " Training loss : 0.011955320835113525 , validation_loss : 0.012823888100683689 , Best Valid Loss : 0.01280246116220951 \n",
            " epoch : 69, Validation loss decreased : 0.01280246116220951 --> 0.012770316563546658 \n",
            " Training loss : 0.012047632597386837 , validation_loss : 0.012770316563546658 , Best Valid Loss : 0.012770316563546658 \n",
            " epoch : 70, validation loss did not decrease \n",
            " Training loss : 0.012008958496153355 , validation_loss : 0.012868099845945835 , Best Valid Loss : 0.012770316563546658 \n",
            " epoch : 71, validation loss did not decrease \n",
            " Training loss : 0.012065622955560684 , validation_loss : 0.012952988967299461 , Best Valid Loss : 0.012770316563546658 \n",
            " epoch : 72, validation loss did not decrease \n",
            " Training loss : 0.01212164293974638 , validation_loss : 0.012855096720159054 , Best Valid Loss : 0.012770316563546658 \n",
            " epoch : 73, Validation loss decreased : 0.012770316563546658 --> 0.01272528525441885 \n",
            " Training loss : 0.01204665843397379 , validation_loss : 0.01272528525441885 , Best Valid Loss : 0.01272528525441885 \n",
            " epoch : 74, Validation loss decreased : 0.01272528525441885 --> 0.012687024660408497 \n",
            " Training loss : 0.011954104527831078 , validation_loss : 0.012687024660408497 , Best Valid Loss : 0.012687024660408497 \n",
            " epoch : 75, Validation loss decreased : 0.012687024660408497 --> 0.012635717168450356 \n",
            " Training loss : 0.01191421877592802 , validation_loss : 0.012635717168450356 , Best Valid Loss : 0.012635717168450356 \n",
            " epoch : 76, Validation loss decreased : 0.012635717168450356 --> 0.012567662633955479 \n",
            " Training loss : 0.011812138371169567 , validation_loss : 0.012567662633955479 , Best Valid Loss : 0.012567662633955479 \n",
            " epoch : 77, validation loss did not decrease \n",
            " Training loss : 0.011659112758934498 , validation_loss : 0.012572766281664371 , Best Valid Loss : 0.012567662633955479 \n",
            " epoch : 78, Validation loss decreased : 0.012567662633955479 --> 0.012563593685626984 \n",
            " Training loss : 0.011571855284273624 , validation_loss : 0.012563593685626984 , Best Valid Loss : 0.012563593685626984 \n",
            " epoch : 79, Validation loss decreased : 0.012563593685626984 --> 0.012486139312386513 \n",
            " Training loss : 0.011500715278089046 , validation_loss : 0.012486139312386513 , Best Valid Loss : 0.012486139312386513 \n",
            " epoch : 80, Validation loss decreased : 0.012486139312386513 --> 0.012468411587178707 \n",
            " Training loss : 0.011396833695471287 , validation_loss : 0.012468411587178707 , Best Valid Loss : 0.012468411587178707 \n",
            " epoch : 81, validation loss did not decrease \n",
            " Training loss : 0.011354147456586361 , validation_loss : 0.012506701983511448 , Best Valid Loss : 0.012468411587178707 \n",
            " epoch : 82, validation loss did not decrease \n",
            " Training loss : 0.011361023411154747 , validation_loss : 0.01249533612281084 , Best Valid Loss : 0.012468411587178707 \n",
            " epoch : 83, validation loss did not decrease \n",
            " Training loss : 0.011333968490362167 , validation_loss : 0.012496971525251865 , Best Valid Loss : 0.012468411587178707 \n",
            " epoch : 84, validation loss did not decrease \n",
            " Training loss : 0.011334775947034359 , validation_loss : 0.012500918470323086 , Best Valid Loss : 0.012468411587178707 \n",
            " epoch : 85, Validation loss decreased : 0.012468411587178707 --> 0.01244815532118082 \n",
            " Training loss : 0.01134161651134491 , validation_loss : 0.01244815532118082 , Best Valid Loss : 0.01244815532118082 \n",
            " epoch : 86, Validation loss decreased : 0.01244815532118082 --> 0.012401808053255081 \n",
            " Training loss : 0.011290090158581734 , validation_loss : 0.012401808053255081 , Best Valid Loss : 0.012401808053255081 \n",
            " epoch : 87, Validation loss decreased : 0.012401808053255081 --> 0.012350150384008884 \n",
            " Training loss : 0.011238832958042622 , validation_loss : 0.012350150384008884 , Best Valid Loss : 0.012350150384008884 \n",
            " epoch : 88, Validation loss decreased : 0.012350150384008884 --> 0.012263068929314613 \n",
            " Training loss : 0.011186891235411167 , validation_loss : 0.012263068929314613 , Best Valid Loss : 0.012263068929314613 \n",
            " epoch : 89, Validation loss decreased : 0.012263068929314613 --> 0.012204061262309551 \n",
            " Training loss : 0.011107631959021091 , validation_loss : 0.012204061262309551 , Best Valid Loss : 0.012204061262309551 \n",
            " epoch : 90, Validation loss decreased : 0.012204061262309551 --> 0.012170414440333843 \n",
            " Training loss : 0.011052089743316174 , validation_loss : 0.012170414440333843 , Best Valid Loss : 0.012170414440333843 \n",
            " epoch : 91, Validation loss decreased : 0.012170414440333843 --> 0.012126208283007145 \n",
            " Training loss : 0.01101875863969326 , validation_loss : 0.012126208283007145 , Best Valid Loss : 0.012126208283007145 \n",
            " epoch : 92, Validation loss decreased : 0.012126208283007145 --> 0.01209212839603424 \n",
            " Training loss : 0.010981726460158825 , validation_loss : 0.01209212839603424 , Best Valid Loss : 0.01209212839603424 \n",
            " epoch : 93, Validation loss decreased : 0.01209212839603424 --> 0.012074601836502552 \n",
            " Training loss : 0.010960080660879612 , validation_loss : 0.012074601836502552 , Best Valid Loss : 0.012074601836502552 \n",
            " epoch : 94, Validation loss decreased : 0.012074601836502552 --> 0.012054111808538437 \n",
            " Training loss : 0.010951502248644829 , validation_loss : 0.012054111808538437 , Best Valid Loss : 0.012054111808538437 \n",
            " epoch : 95, Validation loss decreased : 0.012054111808538437 --> 0.01203568372875452 \n",
            " Training loss : 0.01093065831810236 , validation_loss : 0.01203568372875452 , Best Valid Loss : 0.01203568372875452 \n",
            " epoch : 96, Validation loss decreased : 0.01203568372875452 --> 0.01202085055410862 \n",
            " Training loss : 0.01090247742831707 , validation_loss : 0.01202085055410862 , Best Valid Loss : 0.01202085055410862 \n",
            " epoch : 97, Validation loss decreased : 0.01202085055410862 --> 0.011990114115178585 \n",
            " Training loss : 0.010875956155359745 , validation_loss : 0.011990114115178585 , Best Valid Loss : 0.011990114115178585 \n",
            " epoch : 98, Validation loss decreased : 0.011990114115178585 --> 0.01194634661078453 \n",
            " Training loss : 0.010839855298399925 , validation_loss : 0.01194634661078453 , Best Valid Loss : 0.01194634661078453 \n",
            " epoch : 99, Validation loss decreased : 0.01194634661078453 --> 0.01191034447401762 \n",
            " Training loss : 0.010796836577355862 , validation_loss : 0.01191034447401762 , Best Valid Loss : 0.01191034447401762 \n",
            " epoch : 100, Validation loss decreased : 0.01191034447401762 --> 0.011880719102919102 \n",
            " Training loss : 0.010762418620288372 , validation_loss : 0.011880719102919102 , Best Valid Loss : 0.011880719102919102 \n",
            " epoch : 101, Validation loss decreased : 0.011880719102919102 --> 0.011849461123347282 \n",
            " Training loss : 0.01073449570685625 , validation_loss : 0.011849461123347282 , Best Valid Loss : 0.011849461123347282 \n",
            " epoch : 102, Validation loss decreased : 0.011849461123347282 --> 0.011822577565908432 \n",
            " Training loss : 0.010708487592637539 , validation_loss : 0.011822577565908432 , Best Valid Loss : 0.011822577565908432 \n",
            " epoch : 103, Validation loss decreased : 0.011822577565908432 --> 0.011798534542322159 \n",
            " Training loss : 0.010692008771002293 , validation_loss : 0.011798534542322159 , Best Valid Loss : 0.011798534542322159 \n",
            " epoch : 104, Validation loss decreased : 0.011798534542322159 --> 0.011772243306040764 \n",
            " Training loss : 0.010679613798856735 , validation_loss : 0.011772243306040764 , Best Valid Loss : 0.011772243306040764 \n",
            " epoch : 105, Validation loss decreased : 0.011772243306040764 --> 0.011749743483960629 \n",
            " Training loss : 0.010660304687917233 , validation_loss : 0.011749743483960629 , Best Valid Loss : 0.011749743483960629 \n",
            " epoch : 106, Validation loss decreased : 0.011749743483960629 --> 0.011729428544640541 \n",
            " Training loss : 0.010638094507157803 , validation_loss : 0.011729428544640541 , Best Valid Loss : 0.011729428544640541 \n",
            " epoch : 107, Validation loss decreased : 0.011729428544640541 --> 0.011705627664923668 \n",
            " Training loss : 0.010614435188472271 , validation_loss : 0.011705627664923668 , Best Valid Loss : 0.011705627664923668 \n",
            " epoch : 108, Validation loss decreased : 0.011705627664923668 --> 0.011685777455568314 \n",
            " Training loss : 0.010586435906589031 , validation_loss : 0.011685777455568314 , Best Valid Loss : 0.011685777455568314 \n",
            " epoch : 109, Validation loss decreased : 0.011685777455568314 --> 0.01167351845651865 \n",
            " Training loss : 0.010560874827206135 , validation_loss : 0.01167351845651865 , Best Valid Loss : 0.01167351845651865 \n",
            " epoch : 110, Validation loss decreased : 0.01167351845651865 --> 0.011661705560982227 \n",
            " Training loss : 0.010541419498622417 , validation_loss : 0.011661705560982227 , Best Valid Loss : 0.011661705560982227 \n",
            " epoch : 111, Validation loss decreased : 0.011661705560982227 --> 0.011647905223071575 \n",
            " Training loss : 0.010523456148803234 , validation_loss : 0.011647905223071575 , Best Valid Loss : 0.011647905223071575 \n",
            " epoch : 112, Validation loss decreased : 0.011647905223071575 --> 0.011632872745394707 \n",
            " Training loss : 0.010506229475140572 , validation_loss : 0.011632872745394707 , Best Valid Loss : 0.011632872745394707 \n",
            " epoch : 113, Validation loss decreased : 0.011632872745394707 --> 0.01161318738013506 \n",
            " Training loss : 0.010490277782082558 , validation_loss : 0.01161318738013506 , Best Valid Loss : 0.01161318738013506 \n",
            " epoch : 114, Validation loss decreased : 0.01161318738013506 --> 0.011588222347199917 \n",
            " Training loss : 0.010471349582076073 , validation_loss : 0.011588222347199917 , Best Valid Loss : 0.011588222347199917 \n",
            " epoch : 115, Validation loss decreased : 0.011588222347199917 --> 0.011560635641217232 \n",
            " Training loss : 0.010448921471834183 , validation_loss : 0.011560635641217232 , Best Valid Loss : 0.011560635641217232 \n",
            " epoch : 116, Validation loss decreased : 0.011560635641217232 --> 0.011530300602316856 \n",
            " Training loss : 0.010426552034914494 , validation_loss : 0.011530300602316856 , Best Valid Loss : 0.011530300602316856 \n",
            " epoch : 117, Validation loss decreased : 0.011530300602316856 --> 0.01149898860603571 \n",
            " Training loss : 0.010404140688478947 , validation_loss : 0.01149898860603571 , Best Valid Loss : 0.01149898860603571 \n",
            " epoch : 118, Validation loss decreased : 0.01149898860603571 --> 0.011470510624349117 \n",
            " Training loss : 0.010381915606558323 , validation_loss : 0.011470510624349117 , Best Valid Loss : 0.011470510624349117 \n",
            " epoch : 119, Validation loss decreased : 0.011470510624349117 --> 0.01144405733793974 \n",
            " Training loss : 0.010361981578171253 , validation_loss : 0.01144405733793974 , Best Valid Loss : 0.01144405733793974 \n",
            " epoch : 120, Validation loss decreased : 0.01144405733793974 --> 0.011417506262660027 \n",
            " Training loss : 0.010342960245907307 , validation_loss : 0.011417506262660027 , Best Valid Loss : 0.011417506262660027 \n",
            " epoch : 121, Validation loss decreased : 0.011417506262660027 --> 0.011392694897949696 \n",
            " Training loss : 0.010322419926524162 , validation_loss : 0.011392694897949696 , Best Valid Loss : 0.011392694897949696 \n",
            " epoch : 122, Validation loss decreased : 0.011392694897949696 --> 0.011370583437383175 \n",
            " Training loss : 0.010300886817276478 , validation_loss : 0.011370583437383175 , Best Valid Loss : 0.011370583437383175 \n",
            " epoch : 123, Validation loss decreased : 0.011370583437383175 --> 0.01135020051151514 \n",
            " Training loss : 0.010278153233230114 , validation_loss : 0.01135020051151514 , Best Valid Loss : 0.01135020051151514 \n",
            " epoch : 124, Validation loss decreased : 0.01135020051151514 --> 0.01133115217089653 \n",
            " Training loss : 0.010253832675516605 , validation_loss : 0.01133115217089653 , Best Valid Loss : 0.01133115217089653 \n",
            " epoch : 125, Validation loss decreased : 0.01133115217089653 --> 0.011312042362987995 \n",
            " Training loss : 0.010229787789285183 , validation_loss : 0.011312042362987995 , Best Valid Loss : 0.011312042362987995 \n",
            " epoch : 126, Validation loss decreased : 0.011312042362987995 --> 0.01129121333360672 \n",
            " Training loss : 0.010206461884081364 , validation_loss : 0.01129121333360672 , Best Valid Loss : 0.01129121333360672 \n",
            " epoch : 127, Validation loss decreased : 0.01129121333360672 --> 0.011268793605268002 \n",
            " Training loss : 0.010182945057749748 , validation_loss : 0.011268793605268002 , Best Valid Loss : 0.011268793605268002 \n",
            " epoch : 128, Validation loss decreased : 0.011268793605268002 --> 0.011244198307394981 \n",
            " Training loss : 0.010159458965063095 , validation_loss : 0.011244198307394981 , Best Valid Loss : 0.011244198307394981 \n",
            " epoch : 129, Validation loss decreased : 0.011244198307394981 --> 0.011216490529477596 \n",
            " Training loss : 0.010135450400412083 , validation_loss : 0.011216490529477596 , Best Valid Loss : 0.011216490529477596 \n",
            " epoch : 130, Validation loss decreased : 0.011216490529477596 --> 0.011186645366251469 \n",
            " Training loss : 0.01011008769273758 , validation_loss : 0.011186645366251469 , Best Valid Loss : 0.011186645366251469 \n",
            " epoch : 131, Validation loss decreased : 0.011186645366251469 --> 0.011155479587614536 \n",
            " Training loss : 0.010084006004035473 , validation_loss : 0.011155479587614536 , Best Valid Loss : 0.011155479587614536 \n",
            " epoch : 132, Validation loss decreased : 0.011155479587614536 --> 0.01112319901585579 \n",
            " Training loss : 0.010057622566819191 , validation_loss : 0.01112319901585579 , Best Valid Loss : 0.01112319901585579 \n",
            " epoch : 133, Validation loss decreased : 0.01112319901585579 --> 0.011090874671936035 \n",
            " Training loss : 0.010030808858573437 , validation_loss : 0.011090874671936035 , Best Valid Loss : 0.011090874671936035 \n",
            " epoch : 134, Validation loss decreased : 0.011090874671936035 --> 0.011059188283979893 \n",
            " Training loss : 0.010004105046391487 , validation_loss : 0.011059188283979893 , Best Valid Loss : 0.011059188283979893 \n",
            " epoch : 135, Validation loss decreased : 0.011059188283979893 --> 0.011028203181922436 \n",
            " Training loss : 0.009977280162274837 , validation_loss : 0.011028203181922436 , Best Valid Loss : 0.011028203181922436 \n",
            " epoch : 136, Validation loss decreased : 0.011028203181922436 --> 0.010997919365763664 \n",
            " Training loss : 0.009949644096195698 , validation_loss : 0.010997919365763664 , Best Valid Loss : 0.010997919365763664 \n",
            " epoch : 137, Validation loss decreased : 0.010997919365763664 --> 0.010967575944960117 \n",
            " Training loss : 0.009921330027282238 , validation_loss : 0.010967575944960117 , Best Valid Loss : 0.010967575944960117 \n",
            " epoch : 138, Validation loss decreased : 0.010967575944960117 --> 0.010936782695353031 \n",
            " Training loss : 0.009892135858535767 , validation_loss : 0.010936782695353031 , Best Valid Loss : 0.010936782695353031 \n",
            " epoch : 139, Validation loss decreased : 0.010936782695353031 --> 0.010905887931585312 \n",
            " Training loss : 0.009862092323601246 , validation_loss : 0.010905887931585312 , Best Valid Loss : 0.010905887931585312 \n",
            " epoch : 140, Validation loss decreased : 0.010905887931585312 --> 0.010874318890273571 \n",
            " Training loss : 0.00983169861137867 , validation_loss : 0.010874318890273571 , Best Valid Loss : 0.010874318890273571 \n",
            " epoch : 141, Validation loss decreased : 0.010874318890273571 --> 0.010841598734259605 \n",
            " Training loss : 0.00980075541883707 , validation_loss : 0.010841598734259605 , Best Valid Loss : 0.010841598734259605 \n",
            " epoch : 142, Validation loss decreased : 0.010841598734259605 --> 0.010807487182319164 \n",
            " Training loss : 0.009769240394234657 , validation_loss : 0.010807487182319164 , Best Valid Loss : 0.010807487182319164 \n",
            " epoch : 143, Validation loss decreased : 0.010807487182319164 --> 0.010771648958325386 \n",
            " Training loss : 0.009737159125506878 , validation_loss : 0.010771648958325386 , Best Valid Loss : 0.010771648958325386 \n",
            " epoch : 144, Validation loss decreased : 0.010771648958325386 --> 0.010734409093856812 \n",
            " Training loss : 0.009704253636300564 , validation_loss : 0.010734409093856812 , Best Valid Loss : 0.010734409093856812 \n",
            " epoch : 145, Validation loss decreased : 0.010734409093856812 --> 0.010696027427911758 \n",
            " Training loss : 0.009670572355389595 , validation_loss : 0.010696027427911758 , Best Valid Loss : 0.010696027427911758 \n",
            " epoch : 146, Validation loss decreased : 0.010696027427911758 --> 0.01065689604729414 \n",
            " Training loss : 0.009636223316192627 , validation_loss : 0.01065689604729414 , Best Valid Loss : 0.01065689604729414 \n",
            " epoch : 147, Validation loss decreased : 0.01065689604729414 --> 0.01061752624809742 \n",
            " Training loss : 0.009601359255611897 , validation_loss : 0.01061752624809742 , Best Valid Loss : 0.01061752624809742 \n",
            " epoch : 148, Validation loss decreased : 0.01061752624809742 --> 0.010577857494354248 \n",
            " Training loss : 0.009566111490130424 , validation_loss : 0.010577857494354248 , Best Valid Loss : 0.010577857494354248 \n",
            " epoch : 149, Validation loss decreased : 0.010577857494354248 --> 0.010538125410676003 \n",
            " Training loss : 0.009530310519039631 , validation_loss : 0.010538125410676003 , Best Valid Loss : 0.010538125410676003 \n",
            " epoch : 150, Validation loss decreased : 0.010538125410676003 --> 0.01049856748431921 \n",
            " Training loss : 0.009494062513113022 , validation_loss : 0.01049856748431921 , Best Valid Loss : 0.01049856748431921 \n",
            " epoch : 151, Validation loss decreased : 0.01049856748431921 --> 0.01045912317931652 \n",
            " Training loss : 0.009457309730350971 , validation_loss : 0.01045912317931652 , Best Valid Loss : 0.01045912317931652 \n",
            " epoch : 152, Validation loss decreased : 0.01045912317931652 --> 0.010419793426990509 \n",
            " Training loss : 0.009420111775398254 , validation_loss : 0.010419793426990509 , Best Valid Loss : 0.010419793426990509 \n",
            " epoch : 153, Validation loss decreased : 0.010419793426990509 --> 0.010380168445408344 \n",
            " Training loss : 0.009382723830640316 , validation_loss : 0.010380168445408344 , Best Valid Loss : 0.010380168445408344 \n",
            " epoch : 154, Validation loss decreased : 0.010380168445408344 --> 0.010340302251279354 \n",
            " Training loss : 0.009345135651528835 , validation_loss : 0.010340302251279354 , Best Valid Loss : 0.010340302251279354 \n",
            " epoch : 155, Validation loss decreased : 0.010340302251279354 --> 0.01029996294528246 \n",
            " Training loss : 0.009307453408837318 , validation_loss : 0.01029996294528246 , Best Valid Loss : 0.01029996294528246 \n",
            " epoch : 156, Validation loss decreased : 0.01029996294528246 --> 0.010260389186441898 \n",
            " Training loss : 0.009269604459404945 , validation_loss : 0.010260389186441898 , Best Valid Loss : 0.010260389186441898 \n",
            " epoch : 157, Validation loss decreased : 0.010260389186441898 --> 0.010226047597825527 \n",
            " Training loss : 0.009232757613062859 , validation_loss : 0.010226047597825527 , Best Valid Loss : 0.010226047597825527 \n",
            " epoch : 158, Validation loss decreased : 0.010226047597825527 --> 0.010183573700487614 \n",
            " Training loss : 0.009200680069625378 , validation_loss : 0.010183573700487614 , Best Valid Loss : 0.010183573700487614 \n",
            " epoch : 159, Validation loss decreased : 0.010183573700487614 --> 0.010140377096831799 \n",
            " Training loss : 0.009162022732198238 , validation_loss : 0.010140377096831799 , Best Valid Loss : 0.010140377096831799 \n",
            " epoch : 160, Validation loss decreased : 0.010140377096831799 --> 0.010101345367729664 \n",
            " Training loss : 0.009122705087065697 , validation_loss : 0.010101345367729664 , Best Valid Loss : 0.010101345367729664 \n",
            " epoch : 161, Validation loss decreased : 0.010101345367729664 --> 0.01006320957094431 \n",
            " Training loss : 0.009086462669074535 , validation_loss : 0.01006320957094431 , Best Valid Loss : 0.01006320957094431 \n",
            " epoch : 162, Validation loss decreased : 0.01006320957094431 --> 0.010025463998317719 \n",
            " Training loss : 0.00905012246221304 , validation_loss : 0.010025463998317719 , Best Valid Loss : 0.010025463998317719 \n",
            " epoch : 163, Validation loss decreased : 0.010025463998317719 --> 0.00998802948743105 \n",
            " Training loss : 0.009013449773192406 , validation_loss : 0.00998802948743105 , Best Valid Loss : 0.00998802948743105 \n",
            " epoch : 164, Validation loss decreased : 0.00998802948743105 --> 0.009950513020157814 \n",
            " Training loss : 0.008976703509688377 , validation_loss : 0.009950513020157814 , Best Valid Loss : 0.009950513020157814 \n",
            " epoch : 165, Validation loss decreased : 0.009950513020157814 --> 0.009912380017340183 \n",
            " Training loss : 0.008939891122281551 , validation_loss : 0.009912380017340183 , Best Valid Loss : 0.009912380017340183 \n",
            " epoch : 166, Validation loss decreased : 0.009912380017340183 --> 0.009873121976852417 \n",
            " Training loss : 0.008902860805392265 , validation_loss : 0.009873121976852417 , Best Valid Loss : 0.009873121976852417 \n",
            " epoch : 167, Validation loss decreased : 0.009873121976852417 --> 0.009832494892179966 \n",
            " Training loss : 0.00886545330286026 , validation_loss : 0.009832494892179966 , Best Valid Loss : 0.009832494892179966 \n",
            " epoch : 168, Validation loss decreased : 0.009832494892179966 --> 0.009790657088160515 \n",
            " Training loss : 0.008827541023492813 , validation_loss : 0.009790657088160515 , Best Valid Loss : 0.009790657088160515 \n",
            " epoch : 169, Validation loss decreased : 0.009790657088160515 --> 0.009748139418661594 \n",
            " Training loss : 0.008789176121354103 , validation_loss : 0.009748139418661594 , Best Valid Loss : 0.009748139418661594 \n",
            " epoch : 170, Validation loss decreased : 0.009748139418661594 --> 0.009705252945423126 \n",
            " Training loss : 0.008750630542635918 , validation_loss : 0.009705252945423126 , Best Valid Loss : 0.009705252945423126 \n",
            " epoch : 171, Validation loss decreased : 0.009705252945423126 --> 0.009662383235991001 \n",
            " Training loss : 0.008711686357855797 , validation_loss : 0.009662383235991001 , Best Valid Loss : 0.009662383235991001 \n",
            " epoch : 172, Validation loss decreased : 0.009662383235991001 --> 0.00961940735578537 \n",
            " Training loss : 0.00867228489369154 , validation_loss : 0.00961940735578537 , Best Valid Loss : 0.00961940735578537 \n",
            " epoch : 173, Validation loss decreased : 0.00961940735578537 --> 0.00957608874887228 \n",
            " Training loss : 0.008632319048047066 , validation_loss : 0.00957608874887228 , Best Valid Loss : 0.00957608874887228 \n",
            " epoch : 174, Validation loss decreased : 0.00957608874887228 --> 0.009532026946544647 \n",
            " Training loss : 0.008591687306761742 , validation_loss : 0.009532026946544647 , Best Valid Loss : 0.009532026946544647 \n",
            " epoch : 175, Validation loss decreased : 0.009532026946544647 --> 0.00948711670935154 \n",
            " Training loss : 0.008550331927835941 , validation_loss : 0.00948711670935154 , Best Valid Loss : 0.00948711670935154 \n",
            " epoch : 176, Validation loss decreased : 0.00948711670935154 --> 0.00944069679826498 \n",
            " Training loss : 0.00850832648575306 , validation_loss : 0.00944069679826498 , Best Valid Loss : 0.00944069679826498 \n",
            " epoch : 177, Validation loss decreased : 0.00944069679826498 --> 0.009392311796545982 \n",
            " Training loss : 0.008465512655675411 , validation_loss : 0.009392311796545982 , Best Valid Loss : 0.009392311796545982 \n",
            " epoch : 178, Validation loss decreased : 0.009392311796545982 --> 0.00934204924851656 \n",
            " Training loss : 0.008421658538281918 , validation_loss : 0.00934204924851656 , Best Valid Loss : 0.00934204924851656 \n",
            " epoch : 179, Validation loss decreased : 0.00934204924851656 --> 0.009290125221014023 \n",
            " Training loss : 0.008376137353479862 , validation_loss : 0.009290125221014023 , Best Valid Loss : 0.009290125221014023 \n",
            " epoch : 180, Validation loss decreased : 0.009290125221014023 --> 0.009236576035618782 \n",
            " Training loss : 0.008328242227435112 , validation_loss : 0.009236576035618782 , Best Valid Loss : 0.009236576035618782 \n",
            " epoch : 181, Validation loss decreased : 0.009236576035618782 --> 0.009183354675769806 \n",
            " Training loss : 0.008280208334326744 , validation_loss : 0.009183354675769806 , Best Valid Loss : 0.009183354675769806 \n",
            " epoch : 182, Validation loss decreased : 0.009183354675769806 --> 0.009130289778113365 \n",
            " Training loss : 0.008231792598962784 , validation_loss : 0.009130289778113365 , Best Valid Loss : 0.009130289778113365 \n",
            " epoch : 183, Validation loss decreased : 0.009130289778113365 --> 0.009075506590306759 \n",
            " Training loss : 0.008182656951248646 , validation_loss : 0.009075506590306759 , Best Valid Loss : 0.009075506590306759 \n",
            " epoch : 184, Validation loss decreased : 0.009075506590306759 --> 0.009015771560370922 \n",
            " Training loss : 0.008131664246320724 , validation_loss : 0.009015771560370922 , Best Valid Loss : 0.009015771560370922 \n",
            " epoch : 185, Validation loss decreased : 0.009015771560370922 --> 0.008952140808105469 \n",
            " Training loss : 0.008076932281255722 , validation_loss : 0.008952140808105469 , Best Valid Loss : 0.008952140808105469 \n",
            " epoch : 186, Validation loss decreased : 0.008952140808105469 --> 0.008886057883501053 \n",
            " Training loss : 0.008021687157452106 , validation_loss : 0.008886057883501053 , Best Valid Loss : 0.008886057883501053 \n",
            " epoch : 187, Validation loss decreased : 0.008886057883501053 --> 0.00881644431501627 \n",
            " Training loss : 0.007964466698467731 , validation_loss : 0.00881644431501627 , Best Valid Loss : 0.00881644431501627 \n",
            " epoch : 188, Validation loss decreased : 0.00881644431501627 --> 0.008743451908230782 \n",
            " Training loss : 0.007904581725597382 , validation_loss : 0.008743451908230782 , Best Valid Loss : 0.008743451908230782 \n",
            " epoch : 189, Validation loss decreased : 0.008743451908230782 --> 0.008669329807162285 \n",
            " Training loss : 0.007841341197490692 , validation_loss : 0.008669329807162285 , Best Valid Loss : 0.008669329807162285 \n",
            " epoch : 190, Validation loss decreased : 0.008669329807162285 --> 0.008586915209889412 \n",
            " Training loss : 0.007773693185299635 , validation_loss : 0.008586915209889412 , Best Valid Loss : 0.008586915209889412 \n",
            " epoch : 191, Validation loss decreased : 0.008586915209889412 --> 0.008518991991877556 \n",
            " Training loss : 0.007703114300966263 , validation_loss : 0.008518991991877556 , Best Valid Loss : 0.008518991991877556 \n",
            " epoch : 192, Validation loss decreased : 0.008518991991877556 --> 0.008472333662211895 \n",
            " Training loss : 0.007633802946656942 , validation_loss : 0.008472333662211895 , Best Valid Loss : 0.008472333662211895 \n",
            " epoch : 193, validation loss did not decrease \n",
            " Training loss : 0.007626503240317106 , validation_loss : 0.00881966482847929 , Best Valid Loss : 0.008472333662211895 \n",
            " epoch : 194, validation loss did not decrease \n",
            " Training loss : 0.007886680774390697 , validation_loss : 0.00895728450268507 , Best Valid Loss : 0.008472333662211895 \n",
            " epoch : 195, validation loss did not decrease \n",
            " Training loss : 0.00810670480132103 , validation_loss : 0.008507225662469864 , Best Valid Loss : 0.008472333662211895 \n",
            " epoch : 196, Validation loss decreased : 0.008472333662211895 --> 0.008165011182427406 \n",
            " Training loss : 0.007604272570461035 , validation_loss : 0.008165011182427406 , Best Valid Loss : 0.008165011182427406 \n",
            " epoch : 197, validation loss did not decrease \n",
            " Training loss : 0.007301878649741411 , validation_loss : 0.008493178524076939 , Best Valid Loss : 0.008165011182427406 \n",
            " epoch : 198, validation loss did not decrease \n",
            " Training loss : 0.0076675270684063435 , validation_loss : 0.008479572832584381 , Best Valid Loss : 0.008165011182427406 \n",
            " epoch : 199, Validation loss decreased : 0.008165011182427406 --> 0.007870446890592575 \n",
            " Training loss : 0.0075692180544137955 , validation_loss : 0.007870446890592575 , Best Valid Loss : 0.007870446890592575 \n",
            " epoch : 200, validation loss did not decrease \n",
            " Training loss : 0.007071640808135271 , validation_loss : 0.007897556759417057 , Best Valid Loss : 0.007870446890592575 \n",
            " epoch : 201, validation loss did not decrease \n",
            " Training loss : 0.007128712255507708 , validation_loss : 0.008327800780534744 , Best Valid Loss : 0.007870446890592575 \n",
            " epoch : 202, Validation loss decreased : 0.007870446890592575 --> 0.007820325903594494 \n",
            " Training loss : 0.007429782766848803 , validation_loss : 0.007820325903594494 , Best Valid Loss : 0.007820325903594494 \n",
            " epoch : 203, Validation loss decreased : 0.007820325903594494 --> 0.0075243497267365456 \n",
            " Training loss : 0.007096497807651758 , validation_loss : 0.0075243497267365456 , Best Valid Loss : 0.0075243497267365456 \n",
            " epoch : 204, Validation loss decreased : 0.0075243497267365456 --> 0.007341395132243633 \n",
            " Training loss : 0.006750827189534903 , validation_loss : 0.007341395132243633 , Best Valid Loss : 0.007341395132243633 \n",
            " epoch : 205, Validation loss decreased : 0.007341395132243633 --> 0.007291004993021488 \n",
            " Training loss : 0.00659877248108387 , validation_loss : 0.007291004993021488 , Best Valid Loss : 0.007291004993021488 \n",
            " epoch : 206, validation loss did not decrease \n",
            " Training loss : 0.006581336259841919 , validation_loss : 0.007686996832489967 , Best Valid Loss : 0.007291004993021488 \n",
            " epoch : 207, validation loss did not decrease \n",
            " Training loss : 0.0068669007159769535 , validation_loss : 0.008987915702164173 , Best Valid Loss : 0.007291004993021488 \n",
            " epoch : 208, validation loss did not decrease \n",
            " Training loss : 0.008236969821155071 , validation_loss : 0.011838742531836033 , Best Valid Loss : 0.007291004993021488 \n",
            " epoch : 209, validation loss did not decrease \n",
            " Training loss : 0.010725313797593117 , validation_loss : 0.009713680483400822 , Best Valid Loss : 0.007291004993021488 \n",
            " epoch : 210, validation loss did not decrease \n",
            " Training loss : 0.008731498382985592 , validation_loss : 0.007396817672997713 , Best Valid Loss : 0.007291004993021488 \n",
            " epoch : 211, validation loss did not decrease \n",
            " Training loss : 0.006592452060431242 , validation_loss : 0.010104190558195114 , Best Valid Loss : 0.007291004993021488 \n",
            " epoch : 212, Validation loss decreased : 0.007291004993021488 --> 0.007284536026418209 \n",
            " Training loss : 0.009193121455609798 , validation_loss : 0.007284536026418209 , Best Valid Loss : 0.007284536026418209 \n",
            " epoch : 213, validation loss did not decrease \n",
            " Training loss : 0.0065238275565207005 , validation_loss : 0.008163843303918839 , Best Valid Loss : 0.007284536026418209 \n",
            " epoch : 214, validation loss did not decrease \n",
            " Training loss : 0.007544516120105982 , validation_loss : 0.00883481465280056 , Best Valid Loss : 0.007284536026418209 \n",
            " epoch : 215, Validation loss decreased : 0.007284536026418209 --> 0.006734065245836973 \n",
            " Training loss : 0.007831295020878315 , validation_loss : 0.006734065245836973 , Best Valid Loss : 0.006734065245836973 \n",
            " epoch : 216, validation loss did not decrease \n",
            " Training loss : 0.0060272677801549435 , validation_loss : 0.008435775525867939 , Best Valid Loss : 0.006734065245836973 \n",
            " epoch : 217, validation loss did not decrease \n",
            " Training loss : 0.00783898402005434 , validation_loss : 0.006837746594101191 , Best Valid Loss : 0.006734065245836973 \n",
            " epoch : 218, validation loss did not decrease \n",
            " Training loss : 0.00607664417475462 , validation_loss : 0.007570590358227491 , Best Valid Loss : 0.006734065245836973 \n",
            " epoch : 219, validation loss did not decrease \n",
            " Training loss : 0.006772398483008146 , validation_loss : 0.0072729382663965225 , Best Valid Loss : 0.006734065245836973 \n",
            " epoch : 220, Validation loss decreased : 0.006734065245836973 --> 0.006517881061881781 \n",
            " Training loss : 0.00656554102897644 , validation_loss : 0.006517881061881781 , Best Valid Loss : 0.006517881061881781 \n",
            " epoch : 221, validation loss did not decrease \n",
            " Training loss : 0.005890694446861744 , validation_loss : 0.007570753805339336 , Best Valid Loss : 0.006517881061881781 \n",
            " epoch : 222, Validation loss decreased : 0.006517881061881781 --> 0.006091312039643526 \n",
            " Training loss : 0.006790091283619404 , validation_loss : 0.006091312039643526 , Best Valid Loss : 0.006091312039643526 \n",
            " epoch : 223, validation loss did not decrease \n",
            " Training loss : 0.005542395636439323 , validation_loss : 0.006643264554440975 , Best Valid Loss : 0.006091312039643526 \n",
            " epoch : 224, validation loss did not decrease \n",
            " Training loss : 0.006125491578131914 , validation_loss : 0.0069840713404119015 , Best Valid Loss : 0.006091312039643526 \n",
            " epoch : 225, Validation loss decreased : 0.006091312039643526 --> 0.0057092285715043545 \n",
            " Training loss : 0.006247691344469786 , validation_loss : 0.0057092285715043545 , Best Valid Loss : 0.0057092285715043545 \n",
            " epoch : 226, validation loss did not decrease \n",
            " Training loss : 0.0051949480548501015 , validation_loss : 0.006245001684874296 , Best Valid Loss : 0.0057092285715043545 \n",
            " epoch : 227, validation loss did not decrease \n",
            " Training loss : 0.0057419356890022755 , validation_loss : 0.006594865117222071 , Best Valid Loss : 0.0057092285715043545 \n",
            " epoch : 228, Validation loss decreased : 0.0057092285715043545 --> 0.005440625827759504 \n",
            " Training loss : 0.005916128400713205 , validation_loss : 0.005440625827759504 , Best Valid Loss : 0.005440625827759504 \n",
            " epoch : 229, Validation loss decreased : 0.005440625827759504 --> 0.00543841952458024 \n",
            " Training loss : 0.004954295698553324 , validation_loss : 0.00543841952458024 , Best Valid Loss : 0.00543841952458024 \n",
            " epoch : 230, validation loss did not decrease \n",
            " Training loss : 0.004974982235580683 , validation_loss : 0.006372375413775444 , Best Valid Loss : 0.00543841952458024 \n",
            " epoch : 231, validation loss did not decrease \n",
            " Training loss : 0.005679007153958082 , validation_loss : 0.006268296390771866 , Best Valid Loss : 0.00543841952458024 \n",
            " epoch : 232, validation loss did not decrease \n",
            " Training loss : 0.005867153871804476 , validation_loss : 0.0065469276160001755 , Best Valid Loss : 0.00543841952458024 \n",
            " epoch : 233, validation loss did not decrease \n",
            " Training loss : 0.005815736949443817 , validation_loss : 0.005682771559804678 , Best Valid Loss : 0.00543841952458024 \n",
            " epoch : 234, validation loss did not decrease \n",
            " Training loss : 0.005299896467477083 , validation_loss : 0.005445912946015596 , Best Valid Loss : 0.00543841952458024 \n",
            " epoch : 235, Validation loss decreased : 0.00543841952458024 --> 0.004809425212442875 \n",
            " Training loss : 0.0048677390441298485 , validation_loss : 0.004809425212442875 , Best Valid Loss : 0.004809425212442875 \n",
            " epoch : 236, Validation loss decreased : 0.004809425212442875 --> 0.004691973328590393 \n",
            " Training loss : 0.004452584311366081 , validation_loss : 0.004691973328590393 , Best Valid Loss : 0.004691973328590393 \n",
            " epoch : 237, Validation loss decreased : 0.004691973328590393 --> 0.004511688835918903 \n",
            " Training loss : 0.00421785656362772 , validation_loss : 0.004511688835918903 , Best Valid Loss : 0.004511688835918903 \n",
            " epoch : 238, validation loss did not decrease \n",
            " Training loss : 0.004248649813234806 , validation_loss : 0.005947520956397057 , Best Valid Loss : 0.004511688835918903 \n",
            " epoch : 239, validation loss did not decrease \n",
            " Training loss : 0.005270858760923147 , validation_loss : 0.010695151053369045 , Best Valid Loss : 0.004511688835918903 \n",
            " epoch : 240, validation loss did not decrease \n",
            " Training loss : 0.010022031143307686 , validation_loss : 0.012363427318632603 , Best Valid Loss : 0.004511688835918903 \n",
            " epoch : 241, validation loss did not decrease \n",
            " Training loss : 0.011216314509510994 , validation_loss : 0.010503162629902363 , Best Valid Loss : 0.004511688835918903 \n",
            " epoch : 242, validation loss did not decrease \n",
            " Training loss : 0.009355539456009865 , validation_loss : 0.006415283773094416 , Best Valid Loss : 0.004511688835918903 \n",
            " epoch : 243, validation loss did not decrease \n",
            " Training loss : 0.005824265535920858 , validation_loss : 0.013911981135606766 , Best Valid Loss : 0.004511688835918903 \n",
            " epoch : 244, validation loss did not decrease \n",
            " Training loss : 0.013228543102741241 , validation_loss : 0.005629578605294228 , Best Valid Loss : 0.004511688835918903 \n",
            " epoch : 245, validation loss did not decrease \n",
            " Training loss : 0.005058073438704014 , validation_loss : 0.009742182679474354 , Best Valid Loss : 0.004511688835918903 \n",
            " epoch : 246, validation loss did not decrease \n",
            " Training loss : 0.008779545314610004 , validation_loss : 0.004878165200352669 , Best Valid Loss : 0.004511688835918903 \n",
            " epoch : 247, validation loss did not decrease \n",
            " Training loss : 0.004342303611338139 , validation_loss : 0.008424593135714531 , Best Valid Loss : 0.004511688835918903 \n",
            " epoch : 248, validation loss did not decrease \n",
            " Training loss : 0.007451133336871862 , validation_loss : 0.004996047355234623 , Best Valid Loss : 0.004511688835918903 \n",
            " epoch : 249, validation loss did not decrease \n",
            " Training loss : 0.005118900444358587 , validation_loss : 0.006110299378633499 , Best Valid Loss : 0.004511688835918903 \n",
            " epoch : 250, validation loss did not decrease \n",
            " Training loss : 0.0061229742132127285 , validation_loss : 0.005505622364580631 , Best Valid Loss : 0.004511688835918903 \n",
            " epoch : 251, validation loss did not decrease \n",
            " Training loss : 0.004887621384114027 , validation_loss : 0.006225699558854103 , Best Valid Loss : 0.004511688835918903 \n",
            " epoch : 252, validation loss did not decrease \n",
            " Training loss : 0.005570302251726389 , validation_loss : 0.00508774584159255 , Best Valid Loss : 0.004511688835918903 \n",
            " epoch : 253, validation loss did not decrease \n",
            " Training loss : 0.004596426151692867 , validation_loss : 0.006182234734296799 , Best Valid Loss : 0.004511688835918903 \n",
            " epoch : 254, validation loss did not decrease \n",
            " Training loss : 0.005614058114588261 , validation_loss : 0.004539163783192635 , Best Valid Loss : 0.004511688835918903 \n",
            " epoch : 255, validation loss did not decrease \n",
            " Training loss : 0.004171597771346569 , validation_loss : 0.0058393594808876514 , Best Valid Loss : 0.004511688835918903 \n",
            " epoch : 256, Validation loss decreased : 0.004511688835918903 --> 0.0042667752131819725 \n",
            " Training loss : 0.005292583256959915 , validation_loss : 0.0042667752131819725 , Best Valid Loss : 0.0042667752131819725 \n",
            " epoch : 257, validation loss did not decrease \n",
            " Training loss : 0.003983041737228632 , validation_loss : 0.005322609096765518 , Best Valid Loss : 0.0042667752131819725 \n",
            " epoch : 258, validation loss did not decrease \n",
            " Training loss : 0.005043582525104284 , validation_loss : 0.004266812466084957 , Best Valid Loss : 0.0042667752131819725 \n",
            " epoch : 259, validation loss did not decrease \n",
            " Training loss : 0.003949922975152731 , validation_loss : 0.005172942765057087 , Best Valid Loss : 0.0042667752131819725 \n",
            " epoch : 260, Validation loss decreased : 0.0042667752131819725 --> 0.00418201694265008 \n",
            " Training loss : 0.004676764830946922 , validation_loss : 0.00418201694265008 , Best Valid Loss : 0.00418201694265008 \n",
            " epoch : 261, validation loss did not decrease \n",
            " Training loss : 0.0039355079643428326 , validation_loss : 0.004464342258870602 , Best Valid Loss : 0.00418201694265008 \n",
            " epoch : 262, Validation loss decreased : 0.00418201694265008 --> 0.004157721996307373 \n",
            " Training loss : 0.004185973666608334 , validation_loss : 0.004157721996307373 , Best Valid Loss : 0.004157721996307373 \n",
            " epoch : 263, validation loss did not decrease \n",
            " Training loss : 0.0038463277742266655 , validation_loss : 0.004180293530225754 , Best Valid Loss : 0.004157721996307373 \n",
            " epoch : 264, Validation loss decreased : 0.004157721996307373 --> 0.004137442447245121 \n",
            " Training loss : 0.003858909709379077 , validation_loss : 0.004137442447245121 , Best Valid Loss : 0.004137442447245121 \n",
            " epoch : 265, Validation loss decreased : 0.004137442447245121 --> 0.003831305541098118 \n",
            " Training loss : 0.0038470777217298746 , validation_loss : 0.003831305541098118 , Best Valid Loss : 0.003831305541098118 \n",
            " epoch : 266, validation loss did not decrease \n",
            " Training loss : 0.0035641416907310486 , validation_loss : 0.004224160220474005 , Best Valid Loss : 0.003831305541098118 \n",
            " epoch : 267, Validation loss decreased : 0.003831305541098118 --> 0.003518149023875594 \n",
            " Training loss : 0.0038139214739203453 , validation_loss : 0.003518149023875594 , Best Valid Loss : 0.003518149023875594 \n",
            " epoch : 268, validation loss did not decrease \n",
            " Training loss : 0.003294335911050439 , validation_loss : 0.003752094227820635 , Best Valid Loss : 0.003518149023875594 \n",
            " epoch : 269, validation loss did not decrease \n",
            " Training loss : 0.0036143530160188675 , validation_loss : 0.003518979763612151 , Best Valid Loss : 0.003518149023875594 \n",
            " epoch : 270, validation loss did not decrease \n",
            " Training loss : 0.003254992188885808 , validation_loss : 0.003545328974723816 , Best Valid Loss : 0.003518149023875594 \n",
            " epoch : 271, validation loss did not decrease \n",
            " Training loss : 0.0032478051725775003 , validation_loss : 0.0035653305239975452 , Best Valid Loss : 0.003518149023875594 \n",
            " epoch : 272, Validation loss decreased : 0.003518149023875594 --> 0.0032519297674298286 \n",
            " Training loss : 0.003340534633025527 , validation_loss : 0.0032519297674298286 , Best Valid Loss : 0.0032519297674298286 \n",
            " epoch : 273, validation loss did not decrease \n",
            " Training loss : 0.0030039874836802483 , validation_loss : 0.003585821483284235 , Best Valid Loss : 0.0032519297674298286 \n",
            " epoch : 274, validation loss did not decrease \n",
            " Training loss : 0.0032621172722429037 , validation_loss : 0.003401000052690506 , Best Valid Loss : 0.0032519297674298286 \n",
            " epoch : 275, Validation loss decreased : 0.0032519297674298286 --> 0.003008961910381913 \n",
            " Training loss : 0.0031711121555417776 , validation_loss : 0.003008961910381913 , Best Valid Loss : 0.003008961910381913 \n",
            " epoch : 276, validation loss did not decrease \n",
            " Training loss : 0.0027849460020661354 , validation_loss : 0.0034595991019159555 , Best Valid Loss : 0.003008961910381913 \n",
            " epoch : 277, validation loss did not decrease \n",
            " Training loss : 0.003127020550891757 , validation_loss : 0.0035945859272032976 , Best Valid Loss : 0.003008961910381913 \n",
            " epoch : 278, Validation loss decreased : 0.003008961910381913 --> 0.003004537895321846 \n",
            " Training loss : 0.0034239173401147127 , validation_loss : 0.003004537895321846 , Best Valid Loss : 0.003004537895321846 \n",
            " epoch : 279, Validation loss decreased : 0.003004537895321846 --> 0.00277760555036366 \n",
            " Training loss : 0.002733832923695445 , validation_loss : 0.00277760555036366 , Best Valid Loss : 0.00277760555036366 \n",
            " epoch : 280, validation loss did not decrease \n",
            " Training loss : 0.0025396773125976324 , validation_loss : 0.0030959390569478273 , Best Valid Loss : 0.00277760555036366 \n",
            " epoch : 281, validation loss did not decrease \n",
            " Training loss : 0.002879305509850383 , validation_loss : 0.003510502865538001 , Best Valid Loss : 0.00277760555036366 \n",
            " epoch : 282, validation loss did not decrease \n",
            " Training loss : 0.00316294701769948 , validation_loss : 0.003796637523919344 , Best Valid Loss : 0.00277760555036366 \n",
            " epoch : 283, validation loss did not decrease \n",
            " Training loss : 0.0035009568091481924 , validation_loss : 0.0034258586820214987 , Best Valid Loss : 0.00277760555036366 \n",
            " epoch : 284, validation loss did not decrease \n",
            " Training loss : 0.0030941267032176256 , validation_loss : 0.0031600629445165396 , Best Valid Loss : 0.00277760555036366 \n",
            " epoch : 285, validation loss did not decrease \n",
            " Training loss : 0.002882624277845025 , validation_loss : 0.002843244466930628 , Best Valid Loss : 0.00277760555036366 \n",
            " epoch : 286, Validation loss decreased : 0.00277760555036366 --> 0.0026570402551442385 \n",
            " Training loss : 0.0025585133116692305 , validation_loss : 0.0026570402551442385 , Best Valid Loss : 0.0026570402551442385 \n",
            " epoch : 287, validation loss did not decrease \n",
            " Training loss : 0.0024215441662818193 , validation_loss : 0.0026603194419294596 , Best Valid Loss : 0.0026570402551442385 \n",
            " epoch : 288, validation loss did not decrease \n",
            " Training loss : 0.002381713828071952 , validation_loss : 0.0028114323504269123 , Best Valid Loss : 0.0026570402551442385 \n",
            " epoch : 289, validation loss did not decrease \n",
            " Training loss : 0.0026059886440634727 , validation_loss : 0.0039006867446005344 , Best Valid Loss : 0.0026570402551442385 \n",
            " epoch : 290, validation loss did not decrease \n",
            " Training loss : 0.0034660794772207737 , validation_loss : 0.008252100087702274 , Best Valid Loss : 0.0026570402551442385 \n",
            " epoch : 291, validation loss did not decrease \n",
            " Training loss : 0.007640277035534382 , validation_loss : 0.013658955693244934 , Best Valid Loss : 0.0026570402551442385 \n",
            " epoch : 292, validation loss did not decrease \n",
            " Training loss : 0.012574284337460995 , validation_loss : 0.017729628831148148 , Best Valid Loss : 0.0026570402551442385 \n",
            " epoch : 293, validation loss did not decrease \n",
            " Training loss : 0.01561475358903408 , validation_loss : 0.0048859561793506145 , Best Valid Loss : 0.0026570402551442385 \n",
            " epoch : 294, validation loss did not decrease \n",
            " Training loss : 0.004305408801883459 , validation_loss : 0.01582862250506878 , Best Valid Loss : 0.0026570402551442385 \n",
            " epoch : 295, validation loss did not decrease \n",
            " Training loss : 0.015847153961658478 , validation_loss : 0.0055124894715845585 , Best Valid Loss : 0.0026570402551442385 \n",
            " epoch : 296, validation loss did not decrease \n",
            " Training loss : 0.005270821042358875 , validation_loss : 0.013392167165875435 , Best Valid Loss : 0.0026570402551442385 \n",
            " epoch : 297, validation loss did not decrease \n",
            " Training loss : 0.011440880596637726 , validation_loss : 0.008938819169998169 , Best Valid Loss : 0.0026570402551442385 \n",
            " epoch : 298, validation loss did not decrease \n",
            " Training loss : 0.007627185899764299 , validation_loss : 0.006309069227427244 , Best Valid Loss : 0.0026570402551442385 \n",
            " epoch : 299, validation loss did not decrease \n",
            " Training loss : 0.00561309652402997 , validation_loss : 0.009106379933655262 , Best Valid Loss : 0.0026570402551442385 \n",
            " epoch : 300, validation loss did not decrease \n",
            " Training loss : 0.0081171914935112 , validation_loss : 0.003926296252757311 , Best Valid Loss : 0.0026570402551442385 \n",
            " epoch : 301, validation loss did not decrease \n",
            " Training loss : 0.004482286050915718 , validation_loss : 0.007368503138422966 , Best Valid Loss : 0.0026570402551442385 \n",
            " epoch : 302, validation loss did not decrease \n",
            " Training loss : 0.008276376873254776 , validation_loss : 0.0038414769805967808 , Best Valid Loss : 0.0026570402551442385 \n",
            " epoch : 303, validation loss did not decrease \n",
            " Training loss : 0.0038065998815000057 , validation_loss : 0.006767280399799347 , Best Valid Loss : 0.0026570402551442385 \n",
            " epoch : 304, validation loss did not decrease \n",
            " Training loss : 0.005993323400616646 , validation_loss : 0.005025642458349466 , Best Valid Loss : 0.0026570402551442385 \n",
            " epoch : 305, validation loss did not decrease \n",
            " Training loss : 0.0045422459952533245 , validation_loss : 0.004904500208795071 , Best Valid Loss : 0.0026570402551442385 \n",
            " epoch : 306, validation loss did not decrease \n",
            " Training loss : 0.004488110076636076 , validation_loss : 0.006309281103312969 , Best Valid Loss : 0.0026570402551442385 \n",
            " epoch : 307, validation loss did not decrease \n",
            " Training loss : 0.005787947215139866 , validation_loss : 0.004052434116601944 , Best Valid Loss : 0.0026570402551442385 \n",
            " epoch : 308, validation loss did not decrease \n",
            " Training loss : 0.003869563341140747 , validation_loss : 0.004899551160633564 , Best Valid Loss : 0.0026570402551442385 \n",
            " epoch : 309, validation loss did not decrease \n",
            " Training loss : 0.004626628942787647 , validation_loss : 0.004556228872388601 , Best Valid Loss : 0.0026570402551442385 \n",
            " epoch : 310, validation loss did not decrease \n",
            " Training loss : 0.004283214919269085 , validation_loss : 0.0036675946321338415 , Best Valid Loss : 0.0026570402551442385 \n",
            " epoch : 311, validation loss did not decrease \n",
            " Training loss : 0.003585655242204666 , validation_loss : 0.0048265703953802586 , Best Valid Loss : 0.0026570402551442385 \n",
            " epoch : 312, validation loss did not decrease \n",
            " Training loss : 0.004683723207563162 , validation_loss : 0.0033957241103053093 , Best Valid Loss : 0.0026570402551442385 \n",
            " epoch : 313, validation loss did not decrease \n",
            " Training loss : 0.0033202627673745155 , validation_loss : 0.0048302290961146355 , Best Valid Loss : 0.0026570402551442385 \n",
            " epoch : 314, validation loss did not decrease \n",
            " Training loss : 0.004481915850192308 , validation_loss : 0.0033125628251582384 , Best Valid Loss : 0.0026570402551442385 \n",
            " epoch : 315, validation loss did not decrease \n",
            " Training loss : 0.003235757118090987 , validation_loss : 0.004045605659484863 , Best Valid Loss : 0.0026570402551442385 \n",
            " epoch : 316, validation loss did not decrease \n",
            " Training loss : 0.003963856492191553 , validation_loss : 0.003386060707271099 , Best Valid Loss : 0.0026570402551442385 \n",
            " epoch : 317, validation loss did not decrease \n",
            " Training loss : 0.003360604401677847 , validation_loss : 0.003580766264349222 , Best Valid Loss : 0.0026570402551442385 \n",
            " epoch : 318, validation loss did not decrease \n",
            " Training loss : 0.003498377278447151 , validation_loss : 0.003567441599443555 , Best Valid Loss : 0.0026570402551442385 \n",
            " epoch : 319, validation loss did not decrease \n",
            " Training loss : 0.0034913935232907534 , validation_loss : 0.00319740385748446 , Best Valid Loss : 0.0026570402551442385 \n",
            " epoch : 320, validation loss did not decrease \n",
            " Training loss : 0.003158237086609006 , validation_loss : 0.003576794872060418 , Best Valid Loss : 0.0026570402551442385 \n",
            " epoch : 321, validation loss did not decrease \n",
            " Training loss : 0.0034603276289999485 , validation_loss : 0.0029330605175346136 , Best Valid Loss : 0.0026570402551442385 \n",
            " epoch : 322, validation loss did not decrease \n",
            " Training loss : 0.002846040530130267 , validation_loss : 0.003467367496341467 , Best Valid Loss : 0.0026570402551442385 \n",
            " epoch : 323, validation loss did not decrease \n",
            " Training loss : 0.0032604492735117674 , validation_loss : 0.00285148317925632 , Best Valid Loss : 0.0026570402551442385 \n",
            " epoch : 324, validation loss did not decrease \n",
            " Training loss : 0.0027293888852000237 , validation_loss : 0.003206485416740179 , Best Valid Loss : 0.0026570402551442385 \n",
            " epoch : 325, validation loss did not decrease \n",
            " Training loss : 0.003095573280006647 , validation_loss : 0.0028204703703522682 , Best Valid Loss : 0.0026570402551442385 \n",
            " epoch : 326, validation loss did not decrease \n",
            " Training loss : 0.00272237416356802 , validation_loss : 0.0031618401408195496 , Best Valid Loss : 0.0026570402551442385 \n",
            " epoch : 327, validation loss did not decrease \n",
            " Training loss : 0.0029581577982753515 , validation_loss : 0.002778193447738886 , Best Valid Loss : 0.0026570402551442385 \n",
            " epoch : 328, validation loss did not decrease \n",
            " Training loss : 0.002635149285197258 , validation_loss : 0.0029138377867639065 , Best Valid Loss : 0.0026570402551442385 \n",
            " epoch : 329, validation loss did not decrease \n",
            " Training loss : 0.002783742733299732 , validation_loss : 0.002726350910961628 , Best Valid Loss : 0.0026570402551442385 \n",
            " epoch : 330, validation loss did not decrease \n",
            " Training loss : 0.0025822720490396023 , validation_loss : 0.0028646059799939394 , Best Valid Loss : 0.0026570402551442385 \n",
            " epoch : 331, validation loss did not decrease \n",
            " Training loss : 0.002670872490853071 , validation_loss : 0.002707090927287936 , Best Valid Loss : 0.0026570402551442385 \n",
            " epoch : 332, validation loss did not decrease \n",
            " Training loss : 0.0025300763081759214 , validation_loss : 0.002740313531830907 , Best Valid Loss : 0.0026570402551442385 \n",
            " epoch : 333, Validation loss decreased : 0.0026570402551442385 --> 0.002603272907435894 \n",
            " Training loss : 0.002571853343397379 , validation_loss : 0.002603272907435894 , Best Valid Loss : 0.002603272907435894 \n",
            " epoch : 334, validation loss did not decrease \n",
            " Training loss : 0.002445708494633436 , validation_loss : 0.002648459980264306 , Best Valid Loss : 0.002603272907435894 \n",
            " epoch : 335, Validation loss decreased : 0.002603272907435894 --> 0.00248222635127604 \n",
            " Training loss : 0.0024657873436808586 , validation_loss : 0.00248222635127604 , Best Valid Loss : 0.00248222635127604 \n",
            " epoch : 336, validation loss did not decrease \n",
            " Training loss : 0.002327363472431898 , validation_loss : 0.0025200550444424152 , Best Valid Loss : 0.00248222635127604 \n",
            " epoch : 337, Validation loss decreased : 0.00248222635127604 --> 0.002364346059039235 \n",
            " Training loss : 0.002402271144092083 , validation_loss : 0.002364346059039235 , Best Valid Loss : 0.002364346059039235 \n",
            " epoch : 338, validation loss did not decrease \n",
            " Training loss : 0.002242372138425708 , validation_loss : 0.002513687126338482 , Best Valid Loss : 0.002364346059039235 \n",
            " epoch : 339, Validation loss decreased : 0.002364346059039235 --> 0.0023083840496838093 \n",
            " Training loss : 0.0023420259822160006 , validation_loss : 0.0023083840496838093 , Best Valid Loss : 0.0023083840496838093 \n",
            " epoch : 340, validation loss did not decrease \n",
            " Training loss : 0.0021812126506119967 , validation_loss : 0.0023521108087152243 , Best Valid Loss : 0.0023083840496838093 \n",
            " epoch : 341, validation loss did not decrease \n",
            " Training loss : 0.0022200339008122683 , validation_loss : 0.0023283346090465784 , Best Valid Loss : 0.0023083840496838093 \n",
            " epoch : 342, Validation loss decreased : 0.0023083840496838093 --> 0.00227065640501678 \n",
            " Training loss : 0.0021604164503514767 , validation_loss : 0.00227065640501678 , Best Valid Loss : 0.00227065640501678 \n",
            " epoch : 343, validation loss did not decrease \n",
            " Training loss : 0.002105024876073003 , validation_loss : 0.0023102695122361183 , Best Valid Loss : 0.00227065640501678 \n",
            " epoch : 344, Validation loss decreased : 0.00227065640501678 --> 0.002216104883700609 \n",
            " Training loss : 0.002147960476577282 , validation_loss : 0.002216104883700609 , Best Valid Loss : 0.002216104883700609 \n",
            " epoch : 345, validation loss did not decrease \n",
            " Training loss : 0.0020479296799749136 , validation_loss : 0.0022622186224907637 , Best Valid Loss : 0.002216104883700609 \n",
            " epoch : 346, validation loss did not decrease \n",
            " Training loss : 0.0020812328439205885 , validation_loss : 0.00222321436740458 , Best Valid Loss : 0.002216104883700609 \n",
            " epoch : 347, Validation loss decreased : 0.002216104883700609 --> 0.002156107686460018 \n",
            " Training loss : 0.0020557951647788286 , validation_loss : 0.002156107686460018 , Best Valid Loss : 0.002156107686460018 \n",
            " epoch : 348, validation loss did not decrease \n",
            " Training loss : 0.0019875660073012114 , validation_loss : 0.002216266468167305 , Best Valid Loss : 0.002156107686460018 \n",
            " epoch : 349, validation loss did not decrease \n",
            " Training loss : 0.0020308957900851965 , validation_loss : 0.002177475020289421 , Best Valid Loss : 0.002156107686460018 \n",
            " epoch : 350, Validation loss decreased : 0.002156107686460018 --> 0.002125254599377513 \n",
            " Training loss : 0.0020117261447012424 , validation_loss : 0.002125254599377513 , Best Valid Loss : 0.002125254599377513 \n",
            " epoch : 351, validation loss did not decrease \n",
            " Training loss : 0.0019510377896949649 , validation_loss : 0.002166129881516099 , Best Valid Loss : 0.002125254599377513 \n",
            " epoch : 352, validation loss did not decrease \n",
            " Training loss : 0.001976789440959692 , validation_loss : 0.0021775932982563972 , Best Valid Loss : 0.002125254599377513 \n",
            " epoch : 353, validation loss did not decrease \n",
            " Training loss : 0.001995735801756382 , validation_loss : 0.0021410330664366484 , Best Valid Loss : 0.002125254599377513 \n",
            " epoch : 354, Validation loss decreased : 0.002125254599377513 --> 0.002122588222846389 \n",
            " Training loss : 0.0019432451808825135 , validation_loss : 0.002122588222846389 , Best Valid Loss : 0.002122588222846389 \n",
            " epoch : 355, validation loss did not decrease \n",
            " Training loss : 0.0019217642256990075 , validation_loss : 0.00215946976095438 , Best Valid Loss : 0.002122588222846389 \n",
            " epoch : 356, validation loss did not decrease \n",
            " Training loss : 0.001953280298039317 , validation_loss : 0.0021767360158264637 , Best Valid Loss : 0.002122588222846389 \n",
            " epoch : 357, validation loss did not decrease \n",
            " Training loss : 0.0019591187592595816 , validation_loss : 0.0021422081626951694 , Best Valid Loss : 0.002122588222846389 \n",
            " epoch : 358, Validation loss decreased : 0.002122588222846389 --> 0.002121561672538519 \n",
            " Training loss : 0.0019288859330117702 , validation_loss : 0.002121561672538519 , Best Valid Loss : 0.002121561672538519 \n",
            " epoch : 359, validation loss did not decrease \n",
            " Training loss : 0.0019073095172643661 , validation_loss : 0.0021389247849583626 , Best Valid Loss : 0.002121561672538519 \n",
            " epoch : 360, validation loss did not decrease \n",
            " Training loss : 0.0019214486237615347 , validation_loss : 0.0021561472676694393 , Best Valid Loss : 0.002121561672538519 \n",
            " epoch : 361, validation loss did not decrease \n",
            " Training loss : 0.0019446746446192265 , validation_loss : 0.002161922864615917 , Best Valid Loss : 0.002121561672538519 \n",
            " epoch : 362, validation loss did not decrease \n",
            " Training loss : 0.001942139700986445 , validation_loss : 0.0021330704912543297 , Best Valid Loss : 0.002121561672538519 \n",
            " epoch : 363, Validation loss decreased : 0.002121561672538519 --> 0.0021198480390012264 \n",
            " Training loss : 0.0019235732033848763 , validation_loss : 0.0021198480390012264 , Best Valid Loss : 0.0021198480390012264 \n",
            " epoch : 364, Validation loss decreased : 0.0021198480390012264 --> 0.002117391210049391 \n",
            " Training loss : 0.0019047284731641412 , validation_loss : 0.002117391210049391 , Best Valid Loss : 0.002117391210049391 \n",
            " epoch : 365, validation loss did not decrease \n",
            " Training loss : 0.001900365692563355 , validation_loss : 0.0021276073530316353 , Best Valid Loss : 0.002117391210049391 \n",
            " epoch : 366, validation loss did not decrease \n",
            " Training loss : 0.0019088329281657934 , validation_loss : 0.0021466324105858803 , Best Valid Loss : 0.002117391210049391 \n",
            " epoch : 367, validation loss did not decrease \n",
            " Training loss : 0.0019189328886568546 , validation_loss : 0.0021484477911144495 , Best Valid Loss : 0.002117391210049391 \n",
            " epoch : 368, validation loss did not decrease \n",
            " Training loss : 0.0019224155694246292 , validation_loss : 0.0021452573128044605 , Best Valid Loss : 0.002117391210049391 \n",
            " epoch : 369, validation loss did not decrease \n",
            " Training loss : 0.001914524007588625 , validation_loss : 0.002128582214936614 , Best Valid Loss : 0.002117391210049391 \n",
            " epoch : 370, validation loss did not decrease \n",
            " Training loss : 0.0019017873564735055 , validation_loss : 0.0021175905130803585 , Best Valid Loss : 0.002117391210049391 \n",
            " epoch : 371, Validation loss decreased : 0.002117391210049391 --> 0.0021103816106915474 \n",
            " Training loss : 0.0018908771453425288 , validation_loss : 0.0021103816106915474 , Best Valid Loss : 0.0021103816106915474 \n",
            " epoch : 372, Validation loss decreased : 0.0021103816106915474 --> 0.00210887030698359 \n",
            " Training loss : 0.0018862243741750717 , validation_loss : 0.00210887030698359 , Best Valid Loss : 0.00210887030698359 \n",
            " epoch : 373, validation loss did not decrease \n",
            " Training loss : 0.001887679798528552 , validation_loss : 0.002114856382831931 , Best Valid Loss : 0.00210887030698359 \n",
            " epoch : 374, validation loss did not decrease \n",
            " Training loss : 0.001891738036647439 , validation_loss : 0.002112387213855982 , Best Valid Loss : 0.00210887030698359 \n",
            " epoch : 375, validation loss did not decrease \n",
            " Training loss : 0.0018939075525850058 , validation_loss : 0.002115222392603755 , Best Valid Loss : 0.00210887030698359 \n",
            " epoch : 376, Validation loss decreased : 0.00210887030698359 --> 0.002106894738972187 \n",
            " Training loss : 0.0018919574795290828 , validation_loss : 0.002106894738972187 , Best Valid Loss : 0.002106894738972187 \n",
            " epoch : 377, Validation loss decreased : 0.002106894738972187 --> 0.00210408098064363 \n",
            " Training loss : 0.0018873701337724924 , validation_loss : 0.00210408098064363 , Best Valid Loss : 0.00210408098064363 \n",
            " epoch : 378, Validation loss decreased : 0.00210408098064363 --> 0.0020956587977707386 \n",
            " Training loss : 0.0018805419094860554 , validation_loss : 0.0020956587977707386 , Best Valid Loss : 0.0020956587977707386 \n",
            " epoch : 379, Validation loss decreased : 0.0020956587977707386 --> 0.0020920834504067898 \n",
            " Training loss : 0.0018737808568403125 , validation_loss : 0.0020920834504067898 , Best Valid Loss : 0.0020920834504067898 \n",
            " epoch : 380, Validation loss decreased : 0.0020920834504067898 --> 0.0020895812194794416 \n",
            " Training loss : 0.0018688905984163284 , validation_loss : 0.0020895812194794416 , Best Valid Loss : 0.0020895812194794416 \n",
            " epoch : 381, Validation loss decreased : 0.0020895812194794416 --> 0.0020880333613604307 \n",
            " Training loss : 0.0018666513497009873 , validation_loss : 0.0020880333613604307 , Best Valid Loss : 0.0020880333613604307 \n",
            " epoch : 382, validation loss did not decrease \n",
            " Training loss : 0.0018663739319890738 , validation_loss : 0.0020892913453280926 , Best Valid Loss : 0.0020880333613604307 \n",
            " epoch : 383, Validation loss decreased : 0.0020880333613604307 --> 0.0020859295036643744 \n",
            " Training loss : 0.0018670177087187767 , validation_loss : 0.0020859295036643744 , Best Valid Loss : 0.0020859295036643744 \n",
            " epoch : 384, Validation loss decreased : 0.0020859295036643744 --> 0.0020858075004070997 \n",
            " Training loss : 0.001866864156909287 , validation_loss : 0.0020858075004070997 , Best Valid Loss : 0.0020858075004070997 \n",
            " epoch : 385, Validation loss decreased : 0.0020858075004070997 --> 0.0020790966227650642 \n",
            " Training loss : 0.0018652654252946377 , validation_loss : 0.0020790966227650642 , Best Valid Loss : 0.0020790966227650642 \n",
            " epoch : 386, Validation loss decreased : 0.0020790966227650642 --> 0.002077072160318494 \n",
            " Training loss : 0.001862010103650391 , validation_loss : 0.002077072160318494 , Best Valid Loss : 0.002077072160318494 \n",
            " epoch : 387, Validation loss decreased : 0.002077072160318494 --> 0.002071741037070751 \n",
            " Training loss : 0.0018581976182758808 , validation_loss : 0.002071741037070751 , Best Valid Loss : 0.002071741037070751 \n",
            " epoch : 388, Validation loss decreased : 0.002071741037070751 --> 0.0020699682645499706 \n",
            " Training loss : 0.0018543865298852324 , validation_loss : 0.0020699682645499706 , Best Valid Loss : 0.0020699682645499706 \n",
            " epoch : 389, Validation loss decreased : 0.0020699682645499706 --> 0.0020690790843218565 \n",
            " Training loss : 0.0018515840638428926 , validation_loss : 0.0020690790843218565 , Best Valid Loss : 0.0020690790843218565 \n",
            " epoch : 390, Validation loss decreased : 0.0020690790843218565 --> 0.0020677654538303614 \n",
            " Training loss : 0.0018498866120353341 , validation_loss : 0.0020677654538303614 , Best Valid Loss : 0.0020677654538303614 \n",
            " epoch : 391, validation loss did not decrease \n",
            " Training loss : 0.0018488374771550298 , validation_loss : 0.0020677978172898293 , Best Valid Loss : 0.0020677654538303614 \n",
            " epoch : 392, Validation loss decreased : 0.0020677654538303614 --> 0.002064045751467347 \n",
            " Training loss : 0.0018471770454198122 , validation_loss : 0.002064045751467347 , Best Valid Loss : 0.002064045751467347 \n",
            " epoch : 393, Validation loss decreased : 0.002064045751467347 --> 0.0020609148778021336 \n",
            " Training loss : 0.0018447941401973367 , validation_loss : 0.0020609148778021336 , Best Valid Loss : 0.0020609148778021336 \n",
            " epoch : 394, Validation loss decreased : 0.0020609148778021336 --> 0.002055208897218108 \n",
            " Training loss : 0.0018404608126729727 , validation_loss : 0.002055208897218108 , Best Valid Loss : 0.002055208897218108 \n",
            " epoch : 395, Validation loss decreased : 0.002055208897218108 --> 0.002051176270470023 \n",
            " Training loss : 0.0018368003657087684 , validation_loss : 0.002051176270470023 , Best Valid Loss : 0.002051176270470023 \n",
            " epoch : 396, Validation loss decreased : 0.002051176270470023 --> 0.0020473217591643333 \n",
            " Training loss : 0.0018322429386898875 , validation_loss : 0.0020473217591643333 , Best Valid Loss : 0.0020473217591643333 \n",
            " epoch : 397, Validation loss decreased : 0.0020473217591643333 --> 0.0020455014891922474 \n",
            " Training loss : 0.001828368054702878 , validation_loss : 0.0020455014891922474 , Best Valid Loss : 0.0020455014891922474 \n",
            " epoch : 398, Validation loss decreased : 0.0020455014891922474 --> 0.002043832093477249 \n",
            " Training loss : 0.0018262927187606692 , validation_loss : 0.002043832093477249 , Best Valid Loss : 0.002043832093477249 \n",
            " epoch : 399, Validation loss decreased : 0.002043832093477249 --> 0.0020406185649335384 \n",
            " Training loss : 0.0018245379906147718 , validation_loss : 0.0020406185649335384 , Best Valid Loss : 0.0020406185649335384 \n",
            " epoch : 400, Validation loss decreased : 0.0020406185649335384 --> 0.002039402024820447 \n",
            " Training loss : 0.0018228390254080296 , validation_loss : 0.002039402024820447 , Best Valid Loss : 0.002039402024820447 \n",
            " epoch : 401, Validation loss decreased : 0.002039402024820447 --> 0.002035568468272686 \n",
            " Training loss : 0.0018211797578260303 , validation_loss : 0.002035568468272686 , Best Valid Loss : 0.002035568468272686 \n",
            " epoch : 402, validation loss did not decrease \n",
            " Training loss : 0.0018195826560258865 , validation_loss : 0.0020358844194561243 , Best Valid Loss : 0.002035568468272686 \n",
            " epoch : 403, Validation loss decreased : 0.002035568468272686 --> 0.0020325127989053726 \n",
            " Training loss : 0.0018180793849751353 , validation_loss : 0.0020325127989053726 , Best Valid Loss : 0.0020325127989053726 \n",
            " epoch : 404, validation loss did not decrease \n",
            " Training loss : 0.0018165960209444165 , validation_loss : 0.0020348906982690096 , Best Valid Loss : 0.0020325127989053726 \n",
            " epoch : 405, Validation loss decreased : 0.0020325127989053726 --> 0.002032437128946185 \n",
            " Training loss : 0.0018153309356421232 , validation_loss : 0.002032437128946185 , Best Valid Loss : 0.002032437128946185 \n",
            " epoch : 406, validation loss did not decrease \n",
            " Training loss : 0.0018146542133763433 , validation_loss : 0.002037954516708851 , Best Valid Loss : 0.002032437128946185 \n",
            " epoch : 407, validation loss did not decrease \n",
            " Training loss : 0.0018147971713915467 , validation_loss : 0.0020359272602945566 , Best Valid Loss : 0.002032437128946185 \n",
            " epoch : 408, validation loss did not decrease \n",
            " Training loss : 0.0018158751772716641 , validation_loss : 0.002045964589342475 , Best Valid Loss : 0.002032437128946185 \n",
            " epoch : 409, validation loss did not decrease \n",
            " Training loss : 0.0018190236296504736 , validation_loss : 0.002047697314992547 , Best Valid Loss : 0.002032437128946185 \n",
            " epoch : 410, validation loss did not decrease \n",
            " Training loss : 0.0018262456869706511 , validation_loss : 0.0020727249793708324 , Best Valid Loss : 0.002032437128946185 \n",
            " epoch : 411, validation loss did not decrease \n",
            " Training loss : 0.001840507728047669 , validation_loss : 0.002091334667056799 , Best Valid Loss : 0.002032437128946185 \n",
            " epoch : 412, validation loss did not decrease \n",
            " Training loss : 0.0018677519401535392 , validation_loss : 0.0021621049381792545 , Best Valid Loss : 0.002032437128946185 \n",
            " epoch : 413, validation loss did not decrease \n",
            " Training loss : 0.001917712390422821 , validation_loss : 0.0022605392150580883 , Best Valid Loss : 0.002032437128946185 \n",
            " epoch : 414, validation loss did not decrease \n",
            " Training loss : 0.0020251725800335407 , validation_loss : 0.0024771811440587044 , Best Valid Loss : 0.002032437128946185 \n",
            " epoch : 415, validation loss did not decrease \n",
            " Training loss : 0.0021987927611917257 , validation_loss : 0.0028921987395733595 , Best Valid Loss : 0.002032437128946185 \n",
            " epoch : 416, validation loss did not decrease \n",
            " Training loss : 0.0026042331010103226 , validation_loss : 0.003353765932843089 , Best Valid Loss : 0.002032437128946185 \n",
            " epoch : 417, validation loss did not decrease \n",
            " Training loss : 0.0029963466804474592 , validation_loss : 0.004308992065489292 , Best Valid Loss : 0.002032437128946185 \n",
            " epoch : 418, validation loss did not decrease \n",
            " Training loss : 0.0038820647168904543 , validation_loss : 0.004033904522657394 , Best Valid Loss : 0.002032437128946185 \n",
            " epoch : 419, validation loss did not decrease \n",
            " Training loss : 0.0036331769078969955 , validation_loss : 0.00362326018512249 , Best Valid Loss : 0.002032437128946185 \n",
            " epoch : 420, validation loss did not decrease \n",
            " Training loss : 0.0032193693332374096 , validation_loss : 0.002281525870785117 , Best Valid Loss : 0.002032437128946185 \n",
            " epoch : 421, validation loss did not decrease \n",
            " Training loss : 0.002017907565459609 , validation_loss : 0.002351778792217374 , Best Valid Loss : 0.002032437128946185 \n",
            " epoch : 422, validation loss did not decrease \n",
            " Training loss : 0.0020826980471611023 , validation_loss : 0.0032339789904654026 , Best Valid Loss : 0.002032437128946185 \n",
            " epoch : 423, validation loss did not decrease \n",
            " Training loss : 0.002912855241447687 , validation_loss : 0.0028190298471599817 , Best Valid Loss : 0.002032437128946185 \n",
            " epoch : 424, validation loss did not decrease \n",
            " Training loss : 0.002504283096641302 , validation_loss : 0.0021140386816114187 , Best Valid Loss : 0.002032437128946185 \n",
            " epoch : 425, validation loss did not decrease \n",
            " Training loss : 0.0019249182660132647 , validation_loss : 0.0021369776222854853 , Best Valid Loss : 0.002032437128946185 \n",
            " epoch : 426, validation loss did not decrease \n",
            " Training loss : 0.0019645043648779392 , validation_loss : 0.002647869521752 , Best Valid Loss : 0.002032437128946185 \n",
            " epoch : 427, validation loss did not decrease \n",
            " Training loss : 0.0023613579105585814 , validation_loss : 0.002568810945376754 , Best Valid Loss : 0.002032437128946185 \n",
            " epoch : 428, validation loss did not decrease \n",
            " Training loss : 0.002372702118009329 , validation_loss : 0.0021102672908455133 , Best Valid Loss : 0.002032437128946185 \n",
            " epoch : 429, validation loss did not decrease \n",
            " Training loss : 0.0018909169593825936 , validation_loss : 0.0022127446718513966 , Best Valid Loss : 0.002032437128946185 \n",
            " epoch : 430, validation loss did not decrease \n",
            " Training loss : 0.0019729386549443007 , validation_loss : 0.0025303789880126715 , Best Valid Loss : 0.002032437128946185 \n",
            " epoch : 431, validation loss did not decrease \n",
            " Training loss : 0.0022784587927162647 , validation_loss : 0.002244732342660427 , Best Valid Loss : 0.002032437128946185 \n",
            " epoch : 432, validation loss did not decrease \n",
            " Training loss : 0.002001472283154726 , validation_loss : 0.002067508175969124 , Best Valid Loss : 0.002032437128946185 \n",
            " epoch : 433, validation loss did not decrease \n",
            " Training loss : 0.0018464670283719897 , validation_loss : 0.002272519748657942 , Best Valid Loss : 0.002032437128946185 \n",
            " epoch : 434, validation loss did not decrease \n",
            " Training loss : 0.002046017674729228 , validation_loss : 0.002292245626449585 , Best Valid Loss : 0.002032437128946185 \n",
            " epoch : 435, validation loss did not decrease \n",
            " Training loss : 0.0020472484175115824 , validation_loss : 0.0020756355952471495 , Best Valid Loss : 0.002032437128946185 \n",
            " epoch : 436, Validation loss decreased : 0.002032437128946185 --> 0.002022720640525222 \n",
            " Training loss : 0.001876596244983375 , validation_loss : 0.002022720640525222 , Best Valid Loss : 0.002022720640525222 \n",
            " epoch : 437, validation loss did not decrease \n",
            " Training loss : 0.0018266233382746577 , validation_loss : 0.0021766256541013718 , Best Valid Loss : 0.002022720640525222 \n",
            " epoch : 438, validation loss did not decrease \n",
            " Training loss : 0.00194693508092314 , validation_loss : 0.0022208618465811014 , Best Valid Loss : 0.002022720640525222 \n",
            " epoch : 439, validation loss did not decrease \n",
            " Training loss : 0.002015954814851284 , validation_loss : 0.0021177956368774176 , Best Valid Loss : 0.002022720640525222 \n",
            " epoch : 440, Validation loss decreased : 0.002022720640525222 --> 0.002012278651818633 \n",
            " Training loss : 0.0018908820347860456 , validation_loss : 0.002012278651818633 , Best Valid Loss : 0.002012278651818633 \n",
            " epoch : 441, validation loss did not decrease \n",
            " Training loss : 0.001799034420400858 , validation_loss : 0.00206136261112988 , Best Valid Loss : 0.002012278651818633 \n",
            " epoch : 442, validation loss did not decrease \n",
            " Training loss : 0.0018415297381579876 , validation_loss : 0.002148672007024288 , Best Valid Loss : 0.002012278651818633 \n",
            " epoch : 443, validation loss did not decrease \n",
            " Training loss : 0.0019099290948361158 , validation_loss : 0.0021344164852052927 , Best Valid Loss : 0.002012278651818633 \n",
            " epoch : 444, validation loss did not decrease \n",
            " Training loss : 0.0019036243902519345 , validation_loss : 0.002052740892395377 , Best Valid Loss : 0.002012278651818633 \n",
            " epoch : 445, Validation loss decreased : 0.002012278651818633 --> 0.001999560510739684 \n",
            " Training loss : 0.0018198589095845819 , validation_loss : 0.001999560510739684 , Best Valid Loss : 0.001999560510739684 \n",
            " epoch : 446, validation loss did not decrease \n",
            " Training loss : 0.0017751400591805577 , validation_loss : 0.0020198114216327667 , Best Valid Loss : 0.001999560510739684 \n",
            " epoch : 447, validation loss did not decrease \n",
            " Training loss : 0.0018000903073698282 , validation_loss : 0.0020869807340204716 , Best Valid Loss : 0.001999560510739684 \n",
            " epoch : 448, validation loss did not decrease \n",
            " Training loss : 0.0018472635420039296 , validation_loss : 0.0020979498513042927 , Best Valid Loss : 0.001999560510739684 \n",
            " epoch : 449, validation loss did not decrease \n",
            " Training loss : 0.0018804207211360335 , validation_loss : 0.002106355968862772 , Best Valid Loss : 0.001999560510739684 \n",
            " epoch : 450, validation loss did not decrease \n",
            " Training loss : 0.0018601567717269063 , validation_loss : 0.002048628404736519 , Best Valid Loss : 0.001999560510739684 \n",
            " epoch : 451, validation loss did not decrease \n",
            " Training loss : 0.0018225038656964898 , validation_loss : 0.002017506631091237 , Best Valid Loss : 0.001999560510739684 \n",
            " epoch : 452, Validation loss decreased : 0.001999560510739684 --> 0.0019957604818046093 \n",
            " Training loss : 0.0017765709199011326 , validation_loss : 0.0019957604818046093 , Best Valid Loss : 0.0019957604818046093 \n",
            " epoch : 453, validation loss did not decrease \n",
            " Training loss : 0.00175678136292845 , validation_loss : 0.00200444832444191 , Best Valid Loss : 0.0019957604818046093 \n",
            " epoch : 454, validation loss did not decrease \n",
            " Training loss : 0.001764187472872436 , validation_loss : 0.0020382844377309084 , Best Valid Loss : 0.0019957604818046093 \n",
            " epoch : 455, validation loss did not decrease \n",
            " Training loss : 0.001788054476492107 , validation_loss : 0.002062508137896657 , Best Valid Loss : 0.0019957604818046093 \n",
            " epoch : 456, validation loss did not decrease \n",
            " Training loss : 0.0018237328622490168 , validation_loss : 0.002107825595885515 , Best Valid Loss : 0.0019957604818046093 \n",
            " epoch : 457, validation loss did not decrease \n",
            " Training loss : 0.0018493573879823089 , validation_loss : 0.002123792190104723 , Best Valid Loss : 0.0019957604818046093 \n",
            " epoch : 458, validation loss did not decrease \n",
            " Training loss : 0.001888552331365645 , validation_loss : 0.0021871139761060476 , Best Valid Loss : 0.0019957604818046093 \n",
            " epoch : 459, validation loss did not decrease \n",
            " Training loss : 0.0019185830606147647 , validation_loss : 0.002223494928330183 , Best Valid Loss : 0.0019957604818046093 \n",
            " epoch : 460, validation loss did not decrease \n",
            " Training loss : 0.001980341039597988 , validation_loss : 0.002313363365828991 , Best Valid Loss : 0.0019957604818046093 \n",
            " epoch : 461, validation loss did not decrease \n",
            " Training loss : 0.002028536517173052 , validation_loss : 0.0023853846359997988 , Best Valid Loss : 0.0019957604818046093 \n",
            " epoch : 462, validation loss did not decrease \n",
            " Training loss : 0.0021198641043156385 , validation_loss : 0.0024555514100939035 , Best Valid Loss : 0.0019957604818046093 \n",
            " epoch : 463, validation loss did not decrease \n",
            " Training loss : 0.002156090224161744 , validation_loss : 0.0025193484034389257 , Best Valid Loss : 0.0019957604818046093 \n",
            " epoch : 464, validation loss did not decrease \n",
            " Training loss : 0.0022334957029670477 , validation_loss : 0.0024767753202468157 , Best Valid Loss : 0.0019957604818046093 \n",
            " epoch : 465, validation loss did not decrease \n",
            " Training loss : 0.002175666159018874 , validation_loss : 0.0023970070760697126 , Best Valid Loss : 0.0019957604818046093 \n",
            " epoch : 466, validation loss did not decrease \n",
            " Training loss : 0.002120332093909383 , validation_loss : 0.0022366801276803017 , Best Valid Loss : 0.0019957604818046093 \n",
            " epoch : 467, validation loss did not decrease \n",
            " Training loss : 0.001957849832251668 , validation_loss : 0.0020675058476626873 , Best Valid Loss : 0.0019957604818046093 \n",
            " epoch : 468, Validation loss decreased : 0.0019957604818046093 --> 0.001988629810512066 \n",
            " Training loss : 0.00182243378367275 , validation_loss : 0.001988629810512066 , Best Valid Loss : 0.001988629810512066 \n",
            " epoch : 469, Validation loss decreased : 0.001988629810512066 --> 0.0019836346618831158 \n",
            " Training loss : 0.001745081041008234 , validation_loss : 0.0019836346618831158 , Best Valid Loss : 0.0019836346618831158 \n",
            " epoch : 470, validation loss did not decrease \n",
            " Training loss : 0.0017450209707021713 , validation_loss : 0.0020259551238268614 , Best Valid Loss : 0.0019836346618831158 \n",
            " epoch : 471, validation loss did not decrease \n",
            " Training loss : 0.0018015254754573107 , validation_loss : 0.002130035310983658 , Best Valid Loss : 0.0019836346618831158 \n",
            " epoch : 472, validation loss did not decrease \n",
            " Training loss : 0.0018702130764722824 , validation_loss : 0.0021632728166878223 , Best Valid Loss : 0.0019836346618831158 \n",
            " epoch : 473, validation loss did not decrease \n",
            " Training loss : 0.001929782098159194 , validation_loss : 0.0021912441588938236 , Best Valid Loss : 0.0019836346618831158 \n",
            " epoch : 474, validation loss did not decrease \n",
            " Training loss : 0.0019203705014660954 , validation_loss : 0.0021235106978565454 , Best Valid Loss : 0.0019836346618831158 \n",
            " epoch : 475, validation loss did not decrease \n",
            " Training loss : 0.0018753345357254148 , validation_loss : 0.0020545674487948418 , Best Valid Loss : 0.0019836346618831158 \n",
            " epoch : 476, validation loss did not decrease \n",
            " Training loss : 0.0017967658350244164 , validation_loss : 0.0019896021112799644 , Best Valid Loss : 0.0019836346618831158 \n",
            " epoch : 477, Validation loss decreased : 0.0019836346618831158 --> 0.001975606195628643 \n",
            " Training loss : 0.001742845051921904 , validation_loss : 0.001975606195628643 , Best Valid Loss : 0.001975606195628643 \n",
            " epoch : 478, validation loss did not decrease \n",
            " Training loss : 0.0017311287811025977 , validation_loss : 0.0020051600877195597 , Best Valid Loss : 0.001975606195628643 \n",
            " epoch : 479, validation loss did not decrease \n",
            " Training loss : 0.0017562501598149538 , validation_loss : 0.0020347319077700377 , Best Valid Loss : 0.001975606195628643 \n",
            " epoch : 480, validation loss did not decrease \n",
            " Training loss : 0.001800080295652151 , validation_loss : 0.0021035356912761927 , Best Valid Loss : 0.001975606195628643 \n",
            " epoch : 481, validation loss did not decrease \n",
            " Training loss : 0.0018437375547364354 , validation_loss : 0.002122375648468733 , Best Valid Loss : 0.001975606195628643 \n",
            " epoch : 482, validation loss did not decrease \n",
            " Training loss : 0.0018876498797908425 , validation_loss : 0.0021638546604663134 , Best Valid Loss : 0.001975606195628643 \n",
            " epoch : 483, validation loss did not decrease \n",
            " Training loss : 0.0018945225747302175 , validation_loss : 0.002144966507330537 , Best Valid Loss : 0.001975606195628643 \n",
            " epoch : 484, validation loss did not decrease \n",
            " Training loss : 0.0018975652055814862 , validation_loss : 0.002127342391759157 , Best Valid Loss : 0.001975606195628643 \n",
            " epoch : 485, validation loss did not decrease \n",
            " Training loss : 0.0018591119442135096 , validation_loss : 0.0020725212525576353 , Best Valid Loss : 0.001975606195628643 \n",
            " epoch : 486, validation loss did not decrease \n",
            " Training loss : 0.0018185768276453018 , validation_loss : 0.0020296506118029356 , Best Valid Loss : 0.001975606195628643 \n",
            " epoch : 487, validation loss did not decrease \n",
            " Training loss : 0.0017699598101899028 , validation_loss : 0.0019827282521873713 , Best Valid Loss : 0.001975606195628643 \n",
            " epoch : 488, Validation loss decreased : 0.001975606195628643 --> 0.001963958377018571 \n",
            " Training loss : 0.0017341135535389185 , validation_loss : 0.001963958377018571 , Best Valid Loss : 0.001963958377018571 \n",
            " epoch : 489, Validation loss decreased : 0.001963958377018571 --> 0.0019566721748560667 \n",
            " Training loss : 0.0017158356495201588 , validation_loss : 0.0019566721748560667 , Best Valid Loss : 0.0019566721748560667 \n",
            " epoch : 490, validation loss did not decrease \n",
            " Training loss : 0.0017128994222730398 , validation_loss : 0.0019587434362620115 , Best Valid Loss : 0.0019566721748560667 \n",
            " epoch : 491, validation loss did not decrease \n",
            " Training loss : 0.0017225027550011873 , validation_loss : 0.0019941492937505245 , Best Valid Loss : 0.0019566721748560667 \n",
            " epoch : 492, validation loss did not decrease \n",
            " Training loss : 0.00174406124278903 , validation_loss : 0.0020152332726866007 , Best Valid Loss : 0.0019566721748560667 \n",
            " epoch : 493, validation loss did not decrease \n",
            " Training loss : 0.001778778270818293 , validation_loss : 0.002100978745147586 , Best Valid Loss : 0.0019566721748560667 \n",
            " epoch : 494, validation loss did not decrease \n",
            " Training loss : 0.0018311541061848402 , validation_loss : 0.0021731476299464703 , Best Valid Loss : 0.0019566721748560667 \n",
            " epoch : 495, validation loss did not decrease \n",
            " Training loss : 0.0019164640689268708 , validation_loss : 0.0022858211304992437 , Best Valid Loss : 0.0019566721748560667 \n",
            " epoch : 496, validation loss did not decrease \n",
            " Training loss : 0.0019933898001909256 , validation_loss : 0.002420159289613366 , Best Valid Loss : 0.0019566721748560667 \n",
            " epoch : 497, validation loss did not decrease \n",
            " Training loss : 0.002135090297088027 , validation_loss : 0.0025376586709171534 , Best Valid Loss : 0.0019566721748560667 \n",
            " epoch : 498, validation loss did not decrease \n",
            " Training loss : 0.0022223133128136396 , validation_loss : 0.0026859811041504145 , Best Valid Loss : 0.0019566721748560667 \n",
            " epoch : 499, validation loss did not decrease \n",
            " Training loss : 0.0023787058889865875 , validation_loss : 0.0026719830930233 , Best Valid Loss : 0.0019566721748560667 \n",
            " epoch : 500, validation loss did not decrease \n",
            " Training loss : 0.002343616681173444 , validation_loss : 0.0026526516303420067 , Best Valid Loss : 0.0019566721748560667 \n",
            " epoch : 501, validation loss did not decrease \n",
            " Training loss : 0.002352205803617835 , validation_loss : 0.0024499620776623487 , Best Valid Loss : 0.0019566721748560667 \n",
            " epoch : 502, validation loss did not decrease \n",
            " Training loss : 0.002140050521120429 , validation_loss : 0.002222442766651511 , Best Valid Loss : 0.0019566721748560667 \n",
            " epoch : 503, validation loss did not decrease \n",
            " Training loss : 0.001958986511453986 , validation_loss : 0.0020437149796634912 , Best Valid Loss : 0.0019566721748560667 \n",
            " epoch : 504, Validation loss decreased : 0.0019566721748560667 --> 0.0019503692165017128 \n",
            " Training loss : 0.001777649624273181 , validation_loss : 0.0019503692165017128 , Best Valid Loss : 0.0019503692165017128 \n",
            " epoch : 505, validation loss did not decrease \n",
            " Training loss : 0.001706297742202878 , validation_loss : 0.0019843943882733583 , Best Valid Loss : 0.0019503692165017128 \n",
            " epoch : 506, validation loss did not decrease \n",
            " Training loss : 0.0017516869120299816 , validation_loss : 0.0021184468641877174 , Best Valid Loss : 0.0019503692165017128 \n",
            " epoch : 507, validation loss did not decrease \n",
            " Training loss : 0.0018484473694115877 , validation_loss : 0.0021840252447873354 , Best Valid Loss : 0.0019503692165017128 \n",
            " epoch : 508, validation loss did not decrease \n",
            " Training loss : 0.0019498508190736175 , validation_loss : 0.002248509554192424 , Best Valid Loss : 0.0019503692165017128 \n",
            " epoch : 509, validation loss did not decrease \n",
            " Training loss : 0.0019597583450376987 , validation_loss : 0.002188575454056263 , Best Valid Loss : 0.0019503692165017128 \n",
            " epoch : 510, validation loss did not decrease \n",
            " Training loss : 0.0019360844744369388 , validation_loss : 0.0020981128327548504 , Best Valid Loss : 0.0019503692165017128 \n",
            " epoch : 511, validation loss did not decrease \n",
            " Training loss : 0.0018247298430651426 , validation_loss : 0.0019905096851289272 , Best Valid Loss : 0.0019503692165017128 \n",
            " epoch : 512, validation loss did not decrease \n",
            " Training loss : 0.001737171900458634 , validation_loss : 0.0019524224335327744 , Best Valid Loss : 0.0019503692165017128 \n",
            " epoch : 513, validation loss did not decrease \n",
            " Training loss : 0.0016996137565001845 , validation_loss : 0.001990838209167123 , Best Valid Loss : 0.0019503692165017128 \n",
            " epoch : 514, validation loss did not decrease \n",
            " Training loss : 0.0017319818725809455 , validation_loss : 0.002051344607025385 , Best Valid Loss : 0.0019503692165017128 \n",
            " epoch : 515, validation loss did not decrease \n",
            " Training loss : 0.001807631109841168 , validation_loss : 0.0021546799689531326 , Best Valid Loss : 0.0019503692165017128 \n",
            " epoch : 516, validation loss did not decrease \n",
            " Training loss : 0.0018758864607661963 , validation_loss : 0.002190197352319956 , Best Valid Loss : 0.0019503692165017128 \n",
            " epoch : 517, validation loss did not decrease \n",
            " Training loss : 0.001944738207384944 , validation_loss : 0.002234008628875017 , Best Valid Loss : 0.0019503692165017128 \n",
            " epoch : 518, validation loss did not decrease \n",
            " Training loss : 0.001944631920196116 , validation_loss : 0.0022144371178001165 , Best Valid Loss : 0.0019503692165017128 \n",
            " epoch : 519, validation loss did not decrease \n",
            " Training loss : 0.0019547026604413986 , validation_loss : 0.002174180466681719 , Best Valid Loss : 0.0019503692165017128 \n",
            " epoch : 520, validation loss did not decrease \n",
            " Training loss : 0.0018904008902609348 , validation_loss : 0.0020980234257876873 , Best Valid Loss : 0.0019503692165017128 \n",
            " epoch : 521, validation loss did not decrease \n",
            " Training loss : 0.001833433285355568 , validation_loss : 0.0020300615578889847 , Best Valid Loss : 0.0019503692165017128 \n",
            " epoch : 522, validation loss did not decrease \n",
            " Training loss : 0.0017596029210835695 , validation_loss : 0.0019643851555883884 , Best Valid Loss : 0.0019503692165017128 \n",
            " epoch : 523, Validation loss decreased : 0.0019503692165017128 --> 0.0019385858904570341 \n",
            " Training loss : 0.0017089087050408125 , validation_loss : 0.0019385858904570341 , Best Valid Loss : 0.0019385858904570341 \n",
            " epoch : 524, validation loss did not decrease \n",
            " Training loss : 0.0016841754550114274 , validation_loss : 0.0019409364322200418 , Best Valid Loss : 0.0019385858904570341 \n",
            " epoch : 525, validation loss did not decrease \n",
            " Training loss : 0.0016882949275895953 , validation_loss : 0.0019535806495696306 , Best Valid Loss : 0.0019385858904570341 \n",
            " epoch : 526, validation loss did not decrease \n",
            " Training loss : 0.0017136413371190429 , validation_loss : 0.0020223334431648254 , Best Valid Loss : 0.0019385858904570341 \n",
            " epoch : 527, validation loss did not decrease \n",
            " Training loss : 0.0017558102263137698 , validation_loss : 0.00206909142434597 , Best Valid Loss : 0.0019385858904570341 \n",
            " epoch : 528, validation loss did not decrease \n",
            " Training loss : 0.0018240370554849505 , validation_loss : 0.002199268899857998 , Best Valid Loss : 0.0019385858904570341 \n",
            " epoch : 529, validation loss did not decrease \n",
            " Training loss : 0.0019064118387177587 , validation_loss : 0.0023158735129982233 , Best Valid Loss : 0.0019385858904570341 \n",
            " epoch : 530, validation loss did not decrease \n",
            " Training loss : 0.002039615297690034 , validation_loss : 0.0024234429001808167 , Best Valid Loss : 0.0019385858904570341 \n",
            " epoch : 531, validation loss did not decrease \n",
            " Training loss : 0.0021087469067424536 , validation_loss : 0.0025192222092300653 , Best Valid Loss : 0.0019385858904570341 \n",
            " epoch : 532, validation loss did not decrease \n",
            " Training loss : 0.0022148177959024906 , validation_loss : 0.0024902389850467443 , Best Valid Loss : 0.0019385858904570341 \n",
            " epoch : 533, validation loss did not decrease \n",
            " Training loss : 0.002170163206756115 , validation_loss : 0.0024316003546118736 , Best Valid Loss : 0.0019385858904570341 \n",
            " epoch : 534, validation loss did not decrease \n",
            " Training loss : 0.002135738031938672 , validation_loss : 0.002259891014546156 , Best Valid Loss : 0.0019385858904570341 \n",
            " epoch : 535, validation loss did not decrease \n",
            " Training loss : 0.00195862352848053 , validation_loss : 0.002077885437756777 , Best Valid Loss : 0.0019385858904570341 \n",
            " epoch : 536, validation loss did not decrease \n",
            " Training loss : 0.0018196686869487166 , validation_loss : 0.001981303095817566 , Best Valid Loss : 0.0019385858904570341 \n",
            " epoch : 537, Validation loss decreased : 0.0019385858904570341 --> 0.0019224501447752118 \n",
            " Training loss : 0.001715684193186462 , validation_loss : 0.0019224501447752118 , Best Valid Loss : 0.0019224501447752118 \n",
            " epoch : 538, validation loss did not decrease \n",
            " Training loss : 0.0016762838931754231 , validation_loss : 0.001930878614075482 , Best Valid Loss : 0.0019224501447752118 \n",
            " epoch : 539, validation loss did not decrease \n",
            " Training loss : 0.0016907363897189498 , validation_loss : 0.0020033700857311487 , Best Valid Loss : 0.0019224501447752118 \n",
            " epoch : 540, validation loss did not decrease \n",
            " Training loss : 0.0017367576947435737 , validation_loss : 0.002048742026090622 , Best Valid Loss : 0.0019224501447752118 \n",
            " epoch : 541, validation loss did not decrease \n",
            " Training loss : 0.0018020352581515908 , validation_loss : 0.002148493891581893 , Best Valid Loss : 0.0019224501447752118 \n",
            " epoch : 542, validation loss did not decrease \n",
            " Training loss : 0.0018587326630949974 , validation_loss : 0.0021883719600737095 , Best Valid Loss : 0.0019224501447752118 \n",
            " epoch : 543, validation loss did not decrease \n",
            " Training loss : 0.0019179113442078233 , validation_loss : 0.002209237078204751 , Best Valid Loss : 0.0019224501447752118 \n",
            " epoch : 544, validation loss did not decrease \n",
            " Training loss : 0.0019130492582917213 , validation_loss : 0.0021755832713097334 , Best Valid Loss : 0.0019224501447752118 \n",
            " epoch : 545, validation loss did not decrease \n",
            " Training loss : 0.0018990938551723957 , validation_loss : 0.0021199421025812626 , Best Valid Loss : 0.0019224501447752118 \n",
            " epoch : 546, validation loss did not decrease \n",
            " Training loss : 0.0018325127894058824 , validation_loss : 0.0020325020886957645 , Best Valid Loss : 0.0019224501447752118 \n",
            " epoch : 547, validation loss did not decrease \n",
            " Training loss : 0.0017713248962536454 , validation_loss : 0.001987915253266692 , Best Valid Loss : 0.0019224501447752118 \n",
            " epoch : 548, validation loss did not decrease \n",
            " Training loss : 0.0017171071376651525 , validation_loss : 0.0019372192909941077 , Best Valid Loss : 0.0019224501447752118 \n",
            " epoch : 549, validation loss did not decrease \n",
            " Training loss : 0.0016875489382073283 , validation_loss : 0.0019274717196822166 , Best Valid Loss : 0.0019224501447752118 \n",
            " epoch : 550, Validation loss decreased : 0.0019224501447752118 --> 0.001915950677357614 \n",
            " Training loss : 0.0016702982829883695 , validation_loss : 0.001915950677357614 , Best Valid Loss : 0.001915950677357614 \n",
            " epoch : 551, validation loss did not decrease \n",
            " Training loss : 0.0016630575992166996 , validation_loss : 0.0019174042390659451 , Best Valid Loss : 0.001915950677357614 \n",
            " epoch : 552, validation loss did not decrease \n",
            " Training loss : 0.001662378665059805 , validation_loss : 0.0019328546477481723 , Best Valid Loss : 0.001915950677357614 \n",
            " epoch : 553, validation loss did not decrease \n",
            " Training loss : 0.0016683336580172181 , validation_loss : 0.0019433106062933803 , Best Valid Loss : 0.001915950677357614 \n",
            " epoch : 554, validation loss did not decrease \n",
            " Training loss : 0.0016822502948343754 , validation_loss : 0.001978687010705471 , Best Valid Loss : 0.001915950677357614 \n",
            " epoch : 555, validation loss did not decrease \n",
            " Training loss : 0.001703664194792509 , validation_loss : 0.0020064478740096092 , Best Valid Loss : 0.001915950677357614 \n",
            " epoch : 556, validation loss did not decrease \n",
            " Training loss : 0.0017405811231583357 , validation_loss : 0.002085241721943021 , Best Valid Loss : 0.001915950677357614 \n",
            " epoch : 557, validation loss did not decrease \n",
            " Training loss : 0.0017969178734347224 , validation_loss : 0.002156670205295086 , Best Valid Loss : 0.001915950677357614 \n",
            " epoch : 558, validation loss did not decrease \n",
            " Training loss : 0.0018862307770177722 , validation_loss : 0.0023201052099466324 , Best Valid Loss : 0.001915950677357614 \n",
            " epoch : 559, validation loss did not decrease \n",
            " Training loss : 0.002005994785577059 , validation_loss : 0.002567413728684187 , Best Valid Loss : 0.001915950677357614 \n",
            " epoch : 560, validation loss did not decrease \n",
            " Training loss : 0.002271875273436308 , validation_loss : 0.002944415435194969 , Best Valid Loss : 0.001915950677357614 \n",
            " epoch : 561, validation loss did not decrease \n",
            " Training loss : 0.00257303798571229 , validation_loss : 0.00349105941131711 , Best Valid Loss : 0.001915950677357614 \n",
            " epoch : 562, validation loss did not decrease \n",
            " Training loss : 0.003106186632066965 , validation_loss : 0.0033874979708343744 , Best Valid Loss : 0.001915950677357614 \n",
            " epoch : 563, validation loss did not decrease \n",
            " Training loss : 0.002994611393660307 , validation_loss : 0.0031149766873568296 , Best Valid Loss : 0.001915950677357614 \n",
            " epoch : 564, validation loss did not decrease \n",
            " Training loss : 0.0027236214373260736 , validation_loss : 0.002249290933832526 , Best Valid Loss : 0.001915950677357614 \n",
            " epoch : 565, validation loss did not decrease \n",
            " Training loss : 0.0019452436827123165 , validation_loss : 0.0020066360011696815 , Best Valid Loss : 0.001915950677357614 \n",
            " epoch : 566, validation loss did not decrease \n",
            " Training loss : 0.0017208633944392204 , validation_loss : 0.002381599508225918 , Best Valid Loss : 0.001915950677357614 \n",
            " epoch : 567, validation loss did not decrease \n",
            " Training loss : 0.0021086058113723993 , validation_loss : 0.002788660116493702 , Best Valid Loss : 0.001915950677357614 \n",
            " epoch : 568, validation loss did not decrease \n",
            " Training loss : 0.0024204119108617306 , validation_loss : 0.0026908069849014282 , Best Valid Loss : 0.001915950677357614 \n",
            " epoch : 569, validation loss did not decrease \n",
            " Training loss : 0.0024687270633876324 , validation_loss : 0.0023129386827349663 , Best Valid Loss : 0.001915950677357614 \n",
            " epoch : 570, validation loss did not decrease \n",
            " Training loss : 0.0020049037411808968 , validation_loss : 0.001943328999914229 , Best Valid Loss : 0.001915950677357614 \n",
            " epoch : 571, validation loss did not decrease \n",
            " Training loss : 0.0017029073787853122 , validation_loss : 0.0020165566820651293 , Best Valid Loss : 0.001915950677357614 \n",
            " epoch : 572, validation loss did not decrease \n",
            " Training loss : 0.0017622722079977393 , validation_loss : 0.002279306063428521 , Best Valid Loss : 0.001915950677357614 \n",
            " epoch : 573, validation loss did not decrease \n",
            " Training loss : 0.001972466241568327 , validation_loss : 0.0022771696094423532 , Best Valid Loss : 0.001915950677357614 \n",
            " epoch : 574, validation loss did not decrease \n",
            " Training loss : 0.00199511949904263 , validation_loss : 0.002031696494668722 , Best Valid Loss : 0.001915950677357614 \n",
            " epoch : 575, validation loss did not decrease \n",
            " Training loss : 0.0017551305936649442 , validation_loss : 0.00194327044300735 , Best Valid Loss : 0.001915950677357614 \n",
            " epoch : 576, validation loss did not decrease \n",
            " Training loss : 0.0016820946475490928 , validation_loss : 0.002071004593744874 , Best Valid Loss : 0.001915950677357614 \n",
            " epoch : 577, validation loss did not decrease \n",
            " Training loss : 0.001824278268031776 , validation_loss : 0.0022299017291516066 , Best Valid Loss : 0.001915950677357614 \n",
            " epoch : 578, validation loss did not decrease \n",
            " Training loss : 0.0019309615017846227 , validation_loss : 0.002162395976483822 , Best Valid Loss : 0.001915950677357614 \n",
            " epoch : 579, validation loss did not decrease \n",
            " Training loss : 0.0019191392930224538 , validation_loss : 0.0020344890654087067 , Best Valid Loss : 0.001915950677357614 \n",
            " epoch : 580, validation loss did not decrease \n",
            " Training loss : 0.001760820741765201 , validation_loss : 0.0019201061222702265 , Best Valid Loss : 0.001915950677357614 \n",
            " epoch : 581, validation loss did not decrease \n",
            " Training loss : 0.0016663800925016403 , validation_loss : 0.0019526457181200385 , Best Valid Loss : 0.001915950677357614 \n",
            " epoch : 582, validation loss did not decrease \n",
            " Training loss : 0.0016945363022387028 , validation_loss : 0.002051413292065263 , Best Valid Loss : 0.001915950677357614 \n",
            " epoch : 583, validation loss did not decrease \n",
            " Training loss : 0.001772652380168438 , validation_loss : 0.002073918003588915 , Best Valid Loss : 0.001915950677357614 \n",
            " epoch : 584, validation loss did not decrease \n",
            " Training loss : 0.0018041495932266116 , validation_loss : 0.002030355390161276 , Best Valid Loss : 0.001915950677357614 \n",
            " epoch : 585, validation loss did not decrease \n",
            " Training loss : 0.0017506013391539454 , validation_loss : 0.0019415749702602625 , Best Valid Loss : 0.001915950677357614 \n",
            " epoch : 586, Validation loss decreased : 0.001915950677357614 --> 0.0019092882284894586 \n",
            " Training loss : 0.001680842018686235 , validation_loss : 0.0019092882284894586 , Best Valid Loss : 0.0019092882284894586 \n",
            " epoch : 587, validation loss did not decrease \n",
            " Training loss : 0.0016473683062940836 , validation_loss : 0.0019335270626470447 , Best Valid Loss : 0.0019092882284894586 \n",
            " epoch : 588, validation loss did not decrease \n",
            " Training loss : 0.001665529445745051 , validation_loss : 0.001966218464076519 , Best Valid Loss : 0.0019092882284894586 \n",
            " epoch : 589, validation loss did not decrease \n",
            " Training loss : 0.0017129002371802926 , validation_loss : 0.002049796748906374 , Best Valid Loss : 0.0019092882284894586 \n",
            " epoch : 590, validation loss did not decrease \n",
            " Training loss : 0.0017613021191209555 , validation_loss : 0.0020576221868395805 , Best Valid Loss : 0.0019092882284894586 \n",
            " epoch : 591, validation loss did not decrease \n",
            " Training loss : 0.0017928931629285216 , validation_loss : 0.002082085469737649 , Best Valid Loss : 0.0019092882284894586 \n",
            " epoch : 592, validation loss did not decrease \n",
            " Training loss : 0.0017858872888609767 , validation_loss : 0.0020294419955462217 , Best Valid Loss : 0.0019092882284894586 \n",
            " epoch : 593, validation loss did not decrease \n",
            " Training loss : 0.001752142095938325 , validation_loss : 0.001986223040148616 , Best Valid Loss : 0.0019092882284894586 \n",
            " epoch : 594, validation loss did not decrease \n",
            " Training loss : 0.001698376378044486 , validation_loss : 0.00192800082731992 , Best Valid Loss : 0.0019092882284894586 \n",
            " epoch : 595, Validation loss decreased : 0.0019092882284894586 --> 0.0019083995139226317 \n",
            " Training loss : 0.001654303283430636 , validation_loss : 0.0019083995139226317 , Best Valid Loss : 0.0019083995139226317 \n",
            " epoch : 596, validation loss did not decrease \n",
            " Training loss : 0.0016358897555619478 , validation_loss : 0.0019171691965311766 , Best Valid Loss : 0.0019083995139226317 \n",
            " epoch : 597, validation loss did not decrease \n",
            " Training loss : 0.0016442638589069247 , validation_loss : 0.0019299599807709455 , Best Valid Loss : 0.0019083995139226317 \n",
            " epoch : 598, validation loss did not decrease \n",
            " Training loss : 0.001672182697802782 , validation_loss : 0.002003767993301153 , Best Valid Loss : 0.0019083995139226317 \n",
            " epoch : 599, validation loss did not decrease \n",
            " Training loss : 0.0017163087613880634 , validation_loss : 0.002051575342193246 , Best Valid Loss : 0.0019083995139226317 \n",
            " epoch : 600, validation loss did not decrease \n",
            " Training loss : 0.0017862336244434118 , validation_loss : 0.002187173580750823 , Best Valid Loss : 0.0019083995139226317 \n",
            " epoch : 601, validation loss did not decrease \n",
            " Training loss : 0.0018743138061836362 , validation_loss : 0.002306227572262287 , Best Valid Loss : 0.0019083995139226317 \n",
            " epoch : 602, validation loss did not decrease \n",
            " Training loss : 0.002006870461627841 , validation_loss : 0.0024396933149546385 , Best Valid Loss : 0.0019083995139226317 \n",
            " epoch : 603, validation loss did not decrease \n",
            " Training loss : 0.0021063731983304024 , validation_loss : 0.002539360895752907 , Best Valid Loss : 0.0019083995139226317 \n",
            " epoch : 604, validation loss did not decrease \n",
            " Training loss : 0.0022088121622800827 , validation_loss : 0.002494317479431629 , Best Valid Loss : 0.0019083995139226317 \n",
            " epoch : 605, validation loss did not decrease \n",
            " Training loss : 0.002158390125259757 , validation_loss : 0.00239827623590827 , Best Valid Loss : 0.0019083995139226317 \n",
            " epoch : 606, validation loss did not decrease \n",
            " Training loss : 0.002082589315250516 , validation_loss : 0.002184671349823475 , Best Valid Loss : 0.0019083995139226317 \n",
            " epoch : 607, validation loss did not decrease \n",
            " Training loss : 0.0018726002890616655 , validation_loss : 0.0019904435612261295 , Best Valid Loss : 0.0019083995139226317 \n",
            " epoch : 608, validation loss did not decrease \n",
            " Training loss : 0.0017187051707878709 , validation_loss : 0.0019091923022642732 , Best Valid Loss : 0.0019083995139226317 \n",
            " epoch : 609, validation loss did not decrease \n",
            " Training loss : 0.0016374185215681791 , validation_loss : 0.0019187210127711296 , Best Valid Loss : 0.0019083995139226317 \n",
            " epoch : 610, validation loss did not decrease \n",
            " Training loss : 0.0016485139494761825 , validation_loss : 0.001973111415281892 , Best Valid Loss : 0.0019083995139226317 \n",
            " epoch : 611, validation loss did not decrease \n",
            " Training loss : 0.0017231145175173879 , validation_loss : 0.0021211637649685144 , Best Valid Loss : 0.0019083995139226317 \n",
            " epoch : 612, validation loss did not decrease \n",
            " Training loss : 0.0018178828759118915 , validation_loss : 0.0021752810571342707 , Best Valid Loss : 0.0019083995139226317 \n",
            " epoch : 613, validation loss did not decrease \n",
            " Training loss : 0.0019016920123249292 , validation_loss : 0.002200474264100194 , Best Valid Loss : 0.0019083995139226317 \n",
            " epoch : 614, validation loss did not decrease \n",
            " Training loss : 0.0018879900453612208 , validation_loss : 0.0021106654312461615 , Best Valid Loss : 0.0019083995139226317 \n",
            " epoch : 615, validation loss did not decrease \n",
            " Training loss : 0.0018203324871137738 , validation_loss : 0.001990663819015026 , Best Valid Loss : 0.0019083995139226317 \n",
            " epoch : 616, validation loss did not decrease \n",
            " Training loss : 0.0017004633555188775 , validation_loss : 0.0019103613449260592 , Best Valid Loss : 0.0019083995139226317 \n",
            " epoch : 617, validation loss did not decrease \n",
            " Training loss : 0.0016335922991856933 , validation_loss : 0.001922721159644425 , Best Valid Loss : 0.0019083995139226317 \n",
            " epoch : 618, validation loss did not decrease \n",
            " Training loss : 0.0016549935098737478 , validation_loss : 0.002018638653680682 , Best Valid Loss : 0.0019083995139226317 \n",
            " epoch : 619, validation loss did not decrease \n",
            " Training loss : 0.0017287633381783962 , validation_loss : 0.002058261539787054 , Best Valid Loss : 0.0019083995139226317 \n",
            " epoch : 620, validation loss did not decrease \n",
            " Training loss : 0.0018035693792626262 , validation_loss : 0.0021436642855405807 , Best Valid Loss : 0.0019083995139226317 \n",
            " epoch : 621, validation loss did not decrease \n",
            " Training loss : 0.0018368137534707785 , validation_loss : 0.0021172838751226664 , Best Valid Loss : 0.0019083995139226317 \n",
            " epoch : 622, validation loss did not decrease \n",
            " Training loss : 0.0018459003185853362 , validation_loss : 0.0020887991413474083 , Best Valid Loss : 0.0019083995139226317 \n",
            " epoch : 623, validation loss did not decrease \n",
            " Training loss : 0.0017878807848319411 , validation_loss : 0.00200271955691278 , Best Valid Loss : 0.0019083995139226317 \n",
            " epoch : 624, validation loss did not decrease \n",
            " Training loss : 0.0017189423087984324 , validation_loss : 0.001934366300702095 , Best Valid Loss : 0.0019083995139226317 \n",
            " epoch : 625, Validation loss decreased : 0.0019083995139226317 --> 0.001908023259602487 \n",
            " Training loss : 0.001649586483836174 , validation_loss : 0.001908023259602487 , Best Valid Loss : 0.001908023259602487 \n",
            " epoch : 626, validation loss did not decrease \n",
            " Training loss : 0.0016279877163469791 , validation_loss : 0.0019324228633195162 , Best Valid Loss : 0.001908023259602487 \n",
            " epoch : 627, validation loss did not decrease \n",
            " Training loss : 0.0016615571221336722 , validation_loss : 0.0020126274321228266 , Best Valid Loss : 0.001908023259602487 \n",
            " epoch : 628, validation loss did not decrease \n",
            " Training loss : 0.0017200523288920522 , validation_loss : 0.0020375566091388464 , Best Valid Loss : 0.001908023259602487 \n",
            " epoch : 629, validation loss did not decrease \n",
            " Training loss : 0.0017782819923013449 , validation_loss : 0.002123121637851 , Best Valid Loss : 0.001908023259602487 \n",
            " epoch : 630, validation loss did not decrease \n",
            " Training loss : 0.0018152677221223712 , validation_loss : 0.0021195055451244116 , Best Valid Loss : 0.001908023259602487 \n",
            " epoch : 631, validation loss did not decrease \n",
            " Training loss : 0.0018444543238729239 , validation_loss : 0.002130646724253893 , Best Valid Loss : 0.001908023259602487 \n",
            " epoch : 632, validation loss did not decrease \n",
            " Training loss : 0.0018210784764960408 , validation_loss : 0.002078054007142782 , Best Valid Loss : 0.001908023259602487 \n",
            " epoch : 633, validation loss did not decrease \n",
            " Training loss : 0.0017863343236967921 , validation_loss : 0.0020027111750096083 , Best Valid Loss : 0.001908023259602487 \n",
            " epoch : 634, validation loss did not decrease \n",
            " Training loss : 0.0017057163640856743 , validation_loss : 0.001922209863550961 , Best Valid Loss : 0.001908023259602487 \n",
            " epoch : 635, Validation loss decreased : 0.001908023259602487 --> 0.0018948584329336882 \n",
            " Training loss : 0.001640111324377358 , validation_loss : 0.0018948584329336882 , Best Valid Loss : 0.0018948584329336882 \n",
            " epoch : 636, validation loss did not decrease \n",
            " Training loss : 0.0016168453730642796 , validation_loss : 0.0019208306912332773 , Best Valid Loss : 0.0018948584329336882 \n",
            " epoch : 637, validation loss did not decrease \n",
            " Training loss : 0.001639199093915522 , validation_loss : 0.0019533028826117516 , Best Valid Loss : 0.0018948584329336882 \n",
            " epoch : 638, validation loss did not decrease \n",
            " Training loss : 0.00169328972697258 , validation_loss : 0.002062434097751975 , Best Valid Loss : 0.0018948584329336882 \n",
            " epoch : 639, validation loss did not decrease \n",
            " Training loss : 0.0017596842953935266 , validation_loss : 0.0021170463878661394 , Best Valid Loss : 0.0018948584329336882 \n",
            " epoch : 640, validation loss did not decrease \n",
            " Training loss : 0.0018436603713780642 , validation_loss : 0.0022455411963164806 , Best Valid Loss : 0.0018948584329336882 \n",
            " epoch : 641, validation loss did not decrease \n",
            " Training loss : 0.001920978887937963 , validation_loss : 0.002329046605154872 , Best Valid Loss : 0.0018948584329336882 \n",
            " epoch : 642, validation loss did not decrease \n",
            " Training loss : 0.002016644924879074 , validation_loss : 0.0023141521960496902 , Best Valid Loss : 0.0018948584329336882 \n",
            " epoch : 643, validation loss did not decrease \n",
            " Training loss : 0.001988204661756754 , validation_loss : 0.0022313424851745367 , Best Valid Loss : 0.0018948584329336882 \n",
            " epoch : 644, validation loss did not decrease \n",
            " Training loss : 0.0019181141396984458 , validation_loss : 0.0020820624195039272 , Best Valid Loss : 0.0018948584329336882 \n",
            " epoch : 645, validation loss did not decrease \n",
            " Training loss : 0.0017745515797287226 , validation_loss : 0.0019464058568701148 , Best Valid Loss : 0.0018948584329336882 \n",
            " epoch : 646, Validation loss decreased : 0.0018948584329336882 --> 0.0018930848455056548 \n",
            " Training loss : 0.0016672203782945871 , validation_loss : 0.0018930848455056548 , Best Valid Loss : 0.0018930848455056548 \n",
            " epoch : 647, validation loss did not decrease \n",
            " Training loss : 0.0016160039231181145 , validation_loss : 0.0019017356680706143 , Best Valid Loss : 0.0018930848455056548 \n",
            " epoch : 648, validation loss did not decrease \n",
            " Training loss : 0.001626690966077149 , validation_loss : 0.001935479580424726 , Best Valid Loss : 0.0018930848455056548 \n",
            " epoch : 649, validation loss did not decrease \n",
            " Training loss : 0.00167879369109869 , validation_loss : 0.0020536412484943867 , Best Valid Loss : 0.0018930848455056548 \n",
            " epoch : 650, validation loss did not decrease \n",
            " Training loss : 0.0017501304391771555 , validation_loss : 0.002114861737936735 , Best Valid Loss : 0.0018930848455056548 \n",
            " epoch : 651, validation loss did not decrease \n",
            " Training loss : 0.0018339459784328938 , validation_loss : 0.0022065017838031054 , Best Valid Loss : 0.0018930848455056548 \n",
            " epoch : 652, validation loss did not decrease \n",
            " Training loss : 0.001886103069409728 , validation_loss : 0.0022241310216486454 , Best Valid Loss : 0.0018930848455056548 \n",
            " epoch : 653, validation loss did not decrease \n",
            " Training loss : 0.0019130923319607973 , validation_loss : 0.002140393713489175 , Best Valid Loss : 0.0018930848455056548 \n",
            " epoch : 654, validation loss did not decrease \n",
            " Training loss : 0.0018284872639924288 , validation_loss : 0.0020204319152981043 , Best Valid Loss : 0.0018930848455056548 \n",
            " epoch : 655, validation loss did not decrease \n",
            " Training loss : 0.001727586961351335 , validation_loss : 0.0019258338725194335 , Best Valid Loss : 0.0018930848455056548 \n",
            " epoch : 656, Validation loss decreased : 0.0018930848455056548 --> 0.0018843364669010043 \n",
            " Training loss : 0.00163611164316535 , validation_loss : 0.0018843364669010043 , Best Valid Loss : 0.0018843364669010043 \n",
            " epoch : 657, validation loss did not decrease \n",
            " Training loss : 0.0016088848933577538 , validation_loss : 0.0019014046993106604 , Best Valid Loss : 0.0018843364669010043 \n",
            " epoch : 658, validation loss did not decrease \n",
            " Training loss : 0.0016385088674724102 , validation_loss : 0.0019973083399236202 , Best Valid Loss : 0.0018843364669010043 \n",
            " epoch : 659, validation loss did not decrease \n",
            " Training loss : 0.0017015582416206598 , validation_loss : 0.0020607630722224712 , Best Valid Loss : 0.0018843364669010043 \n",
            " epoch : 660, validation loss did not decrease \n",
            " Training loss : 0.001790897804312408 , validation_loss : 0.002210313454270363 , Best Valid Loss : 0.0018843364669010043 \n",
            " epoch : 661, validation loss did not decrease \n",
            " Training loss : 0.0018864000448957086 , validation_loss : 0.002303875284269452 , Best Valid Loss : 0.0018843364669010043 \n",
            " epoch : 662, validation loss did not decrease \n",
            " Training loss : 0.001991087105125189 , validation_loss : 0.002293965080752969 , Best Valid Loss : 0.0018843364669010043 \n",
            " epoch : 663, validation loss did not decrease \n",
            " Training loss : 0.0019692128989845514 , validation_loss : 0.002208191668614745 , Best Valid Loss : 0.0018843364669010043 \n",
            " epoch : 664, validation loss did not decrease \n",
            " Training loss : 0.001892331289127469 , validation_loss : 0.002038452308624983 , Best Valid Loss : 0.0018843364669010043 \n",
            " epoch : 665, validation loss did not decrease \n",
            " Training loss : 0.0017330580158159137 , validation_loss : 0.0019095557508990169 , Best Valid Loss : 0.0018843364669010043 \n",
            " epoch : 666, Validation loss decreased : 0.0018843364669010043 --> 0.0018809334142133594 \n",
            " Training loss : 0.0016284332377836108 , validation_loss : 0.0018809334142133594 , Best Valid Loss : 0.0018809334142133594 \n",
            " epoch : 667, validation loss did not decrease \n",
            " Training loss : 0.0016075025778263807 , validation_loss : 0.001947009819559753 , Best Valid Loss : 0.0018809334142133594 \n",
            " epoch : 668, validation loss did not decrease \n",
            " Training loss : 0.001659120200201869 , validation_loss : 0.00201599532738328 , Best Valid Loss : 0.0018809334142133594 \n",
            " epoch : 669, validation loss did not decrease \n",
            " Training loss : 0.0017588587943464518 , validation_loss : 0.0022093751467764378 , Best Valid Loss : 0.0018809334142133594 \n",
            " epoch : 670, validation loss did not decrease \n",
            " Training loss : 0.0018819960532709956 , validation_loss : 0.0023522106930613518 , Best Valid Loss : 0.0018809334142133594 \n",
            " epoch : 671, validation loss did not decrease \n",
            " Training loss : 0.002049282193183899 , validation_loss : 0.0024222061038017273 , Best Valid Loss : 0.0018809334142133594 \n",
            " epoch : 672, validation loss did not decrease \n",
            " Training loss : 0.0020827173721045256 , validation_loss : 0.002373294671997428 , Best Valid Loss : 0.0018809334142133594 \n",
            " epoch : 673, validation loss did not decrease \n",
            " Training loss : 0.002038475126028061 , validation_loss : 0.002123424783349037 , Best Valid Loss : 0.0018809334142133594 \n",
            " epoch : 674, validation loss did not decrease \n",
            " Training loss : 0.0018117367289960384 , validation_loss : 0.0019311110954731703 , Best Valid Loss : 0.0018809334142133594 \n",
            " epoch : 675, validation loss did not decrease \n",
            " Training loss : 0.001638826448470354 , validation_loss : 0.0018932570237666368 , Best Valid Loss : 0.0018809334142133594 \n",
            " epoch : 676, validation loss did not decrease \n",
            " Training loss : 0.0016140759689733386 , validation_loss : 0.0020350466948002577 , Best Valid Loss : 0.0018809334142133594 \n",
            " epoch : 677, validation loss did not decrease \n",
            " Training loss : 0.0017303904751315713 , validation_loss : 0.002174154855310917 , Best Valid Loss : 0.0018809334142133594 \n",
            " epoch : 678, validation loss did not decrease \n",
            " Training loss : 0.0019213672494515777 , validation_loss : 0.002455835696309805 , Best Valid Loss : 0.0018809334142133594 \n",
            " epoch : 679, validation loss did not decrease \n",
            " Training loss : 0.0020977361127734184 , validation_loss : 0.002625370165333152 , Best Valid Loss : 0.0018809334142133594 \n",
            " epoch : 680, validation loss did not decrease \n",
            " Training loss : 0.0023127449676394463 , validation_loss : 0.0025786415208131075 , Best Valid Loss : 0.0018809334142133594 \n",
            " epoch : 681, validation loss did not decrease \n",
            " Training loss : 0.0022263971623033285 , validation_loss : 0.0023341120686382055 , Best Valid Loss : 0.0018809334142133594 \n",
            " epoch : 682, validation loss did not decrease \n",
            " Training loss : 0.0019908028189092875 , validation_loss : 0.001975392457097769 , Best Valid Loss : 0.0018809334142133594 \n",
            " epoch : 683, validation loss did not decrease \n",
            " Training loss : 0.0016645991709083319 , validation_loss : 0.0019791428931057453 , Best Valid Loss : 0.0018809334142133594 \n",
            " epoch : 684, validation loss did not decrease \n",
            " Training loss : 0.0016780729638412595 , validation_loss : 0.0022156666964292526 , Best Valid Loss : 0.0018809334142133594 \n",
            " epoch : 685, validation loss did not decrease \n",
            " Training loss : 0.002026298316195607 , validation_loss : 0.0028354779351502657 , Best Valid Loss : 0.0018809334142133594 \n",
            " epoch : 686, validation loss did not decrease \n",
            " Training loss : 0.002431873930618167 , validation_loss : 0.0031553248409181833 , Best Valid Loss : 0.0018809334142133594 \n",
            " epoch : 687, validation loss did not decrease \n",
            " Training loss : 0.00281089567579329 , validation_loss : 0.0027505739126354456 , Best Valid Loss : 0.0018809334142133594 \n",
            " epoch : 688, validation loss did not decrease \n",
            " Training loss : 0.0023936904035508633 , validation_loss : 0.0021907822228968143 , Best Valid Loss : 0.0018809334142133594 \n",
            " epoch : 689, validation loss did not decrease \n",
            " Training loss : 0.0018560719909146428 , validation_loss : 0.0019926882814615965 , Best Valid Loss : 0.0018809334142133594 \n",
            " epoch : 690, validation loss did not decrease \n",
            " Training loss : 0.0016917908797040582 , validation_loss : 0.0024006254971027374 , Best Valid Loss : 0.0018809334142133594 \n",
            " epoch : 691, validation loss did not decrease \n",
            " Training loss : 0.002068224595859647 , validation_loss : 0.0028352830559015274 , Best Valid Loss : 0.0018809334142133594 \n",
            " epoch : 692, validation loss did not decrease \n",
            " Training loss : 0.002522010589018464 , validation_loss : 0.0027274969033896923 , Best Valid Loss : 0.0018809334142133594 \n",
            " epoch : 693, validation loss did not decrease \n",
            " Training loss : 0.0023361979983747005 , validation_loss : 0.002276575891301036 , Best Valid Loss : 0.0018809334142133594 \n",
            " epoch : 694, validation loss did not decrease \n",
            " Training loss : 0.002008657669648528 , validation_loss : 0.0019418214214965701 , Best Valid Loss : 0.0018809334142133594 \n",
            " epoch : 695, validation loss did not decrease \n",
            " Training loss : 0.0016517003532499075 , validation_loss : 0.001968477852642536 , Best Valid Loss : 0.0018809334142133594 \n",
            " epoch : 696, validation loss did not decrease \n",
            " Training loss : 0.0016721352003514767 , validation_loss : 0.0022084247320890427 , Best Valid Loss : 0.0018809334142133594 \n",
            " epoch : 697, validation loss did not decrease \n",
            " Training loss : 0.0018962972098961473 , validation_loss : 0.0021695548202842474 , Best Valid Loss : 0.0018809334142133594 \n",
            " epoch : 698, validation loss did not decrease \n",
            " Training loss : 0.0018477393314242363 , validation_loss : 0.0019529492128640413 , Best Valid Loss : 0.0018809334142133594 \n",
            " epoch : 699, validation loss did not decrease \n",
            " Training loss : 0.0016617237124592066 , validation_loss : 0.0019098337506875396 , Best Valid Loss : 0.0018809334142133594 \n",
            " epoch : 700, validation loss did not decrease \n",
            " Training loss : 0.001630534534342587 , validation_loss : 0.0020803946536034346 , Best Valid Loss : 0.0018809334142133594 \n",
            " epoch : 701, validation loss did not decrease \n",
            " Training loss : 0.0017652930691838264 , validation_loss : 0.0020931274630129337 , Best Valid Loss : 0.0018809334142133594 \n",
            " epoch : 702, validation loss did not decrease \n",
            " Training loss : 0.0018440295243635774 , validation_loss : 0.0020461224485188723 , Best Valid Loss : 0.0018809334142133594 \n",
            " epoch : 703, validation loss did not decrease \n",
            " Training loss : 0.0017343942308798432 , validation_loss : 0.0018973287660628557 , Best Valid Loss : 0.0018809334142133594 \n",
            " epoch : 704, validation loss did not decrease \n",
            " Training loss : 0.0016155085759237409 , validation_loss : 0.0019108891719952226 , Best Valid Loss : 0.0018809334142133594 \n",
            " epoch : 705, validation loss did not decrease \n",
            " Training loss : 0.0016195917269214988 , validation_loss : 0.0020103976130485535 , Best Valid Loss : 0.0018809334142133594 \n",
            " epoch : 706, validation loss did not decrease \n",
            " Training loss : 0.0016988808056339622 , validation_loss : 0.0020208884961903095 , Best Valid Loss : 0.0018809334142133594 \n",
            " epoch : 707, validation loss did not decrease \n",
            " Training loss : 0.0017200011061504483 , validation_loss : 0.0019523564260452986 , Best Valid Loss : 0.0018809334142133594 \n",
            " epoch : 708, Validation loss decreased : 0.0018809334142133594 --> 0.0018808238673955202 \n",
            " Training loss : 0.0016470421105623245 , validation_loss : 0.0018808238673955202 , Best Valid Loss : 0.0018808238673955202 \n",
            " epoch : 709, validation loss did not decrease \n",
            " Training loss : 0.0015903067542240024 , validation_loss : 0.0018937303684651852 , Best Valid Loss : 0.0018808238673955202 \n",
            " epoch : 710, validation loss did not decrease \n",
            " Training loss : 0.0016083272639662027 , validation_loss : 0.0019751221407204866 , Best Valid Loss : 0.0018808238673955202 \n",
            " epoch : 711, validation loss did not decrease \n",
            " Training loss : 0.0016652279300615191 , validation_loss : 0.002000967040657997 , Best Valid Loss : 0.0018808238673955202 \n",
            " epoch : 712, validation loss did not decrease \n",
            " Training loss : 0.0017135933740064502 , validation_loss : 0.002044344088062644 , Best Valid Loss : 0.0018808238673955202 \n",
            " epoch : 713, validation loss did not decrease \n",
            " Training loss : 0.0017229946097359061 , validation_loss : 0.0019988170824944973 , Best Valid Loss : 0.0018808238673955202 \n",
            " epoch : 714, validation loss did not decrease \n",
            " Training loss : 0.0016942786751314998 , validation_loss : 0.0019480560440570116 , Best Valid Loss : 0.0018808238673955202 \n",
            " epoch : 715, validation loss did not decrease \n",
            " Training loss : 0.0016357654239982367 , validation_loss : 0.0018960004672408104 , Best Valid Loss : 0.0018808238673955202 \n",
            " epoch : 716, validation loss did not decrease \n",
            " Training loss : 0.0015906892949715257 , validation_loss : 0.001885971869342029 , Best Valid Loss : 0.0018808238673955202 \n",
            " epoch : 717, validation loss did not decrease \n",
            " Training loss : 0.0015833491925150156 , validation_loss : 0.0019207329023629427 , Best Valid Loss : 0.0018808238673955202 \n",
            " epoch : 718, validation loss did not decrease \n",
            " Training loss : 0.0016111971344798803 , validation_loss : 0.0019393503898754716 , Best Valid Loss : 0.0018808238673955202 \n",
            " epoch : 719, validation loss did not decrease \n",
            " Training loss : 0.0016528911655768752 , validation_loss : 0.00200868328101933 , Best Valid Loss : 0.0018808238673955202 \n",
            " epoch : 720, validation loss did not decrease \n",
            " Training loss : 0.0016872306587174535 , validation_loss : 0.0019971001893281937 , Best Valid Loss : 0.0018808238673955202 \n",
            " epoch : 721, validation loss did not decrease \n",
            " Training loss : 0.0017050737515091896 , validation_loss : 0.002023377688601613 , Best Valid Loss : 0.0018808238673955202 \n",
            " epoch : 722, validation loss did not decrease \n",
            " Training loss : 0.001697281375527382 , validation_loss : 0.0019781130831688643 , Best Valid Loss : 0.0018808238673955202 \n",
            " epoch : 723, validation loss did not decrease \n",
            " Training loss : 0.0016676179366186261 , validation_loss : 0.0019402661127969623 , Best Valid Loss : 0.0018808238673955202 \n",
            " epoch : 724, validation loss did not decrease \n",
            " Training loss : 0.001622794079594314 , validation_loss : 0.0018932534148916602 , Best Valid Loss : 0.0018808238673955202 \n",
            " epoch : 725, Validation loss decreased : 0.0018808238673955202 --> 0.0018781482940539718 \n",
            " Training loss : 0.0015852589858695865 , validation_loss : 0.0018781482940539718 , Best Valid Loss : 0.0018781482940539718 \n",
            " epoch : 726, validation loss did not decrease \n",
            " Training loss : 0.0015739601803943515 , validation_loss : 0.0018970391247421503 , Best Valid Loss : 0.0018781482940539718 \n",
            " epoch : 727, validation loss did not decrease \n",
            " Training loss : 0.0015900039579719305 , validation_loss : 0.0019116662442684174 , Best Valid Loss : 0.0018781482940539718 \n",
            " epoch : 728, validation loss did not decrease \n",
            " Training loss : 0.001621830160729587 , validation_loss : 0.001977229258045554 , Best Valid Loss : 0.0018781482940539718 \n",
            " epoch : 729, validation loss did not decrease \n",
            " Training loss : 0.0016579023795202374 , validation_loss : 0.001998153980821371 , Best Valid Loss : 0.0018781482940539718 \n",
            " epoch : 730, validation loss did not decrease \n",
            " Training loss : 0.0016984924441203475 , validation_loss : 0.002057332079857588 , Best Valid Loss : 0.0018781482940539718 \n",
            " epoch : 731, validation loss did not decrease \n",
            " Training loss : 0.0017291880212724209 , validation_loss : 0.0020581064745783806 , Best Valid Loss : 0.0018781482940539718 \n",
            " epoch : 732, validation loss did not decrease \n",
            " Training loss : 0.0017401600489392877 , validation_loss : 0.0020305158104747534 , Best Valid Loss : 0.0018781482940539718 \n",
            " epoch : 733, validation loss did not decrease \n",
            " Training loss : 0.0017063247505575418 , validation_loss : 0.001955839106813073 , Best Valid Loss : 0.0018781482940539718 \n",
            " epoch : 734, validation loss did not decrease \n",
            " Training loss : 0.0016450569964945316 , validation_loss : 0.0019025261281058192 , Best Valid Loss : 0.0018781482940539718 \n",
            " epoch : 735, Validation loss decreased : 0.0018781482940539718 --> 0.0018703780369833112 \n",
            " Training loss : 0.0015905770706012845 , validation_loss : 0.0018703780369833112 , Best Valid Loss : 0.0018703780369833112 \n",
            " epoch : 736, validation loss did not decrease \n",
            " Training loss : 0.0015700497897341847 , validation_loss : 0.0018748572329059243 , Best Valid Loss : 0.0018703780369833112 \n",
            " epoch : 737, validation loss did not decrease \n",
            " Training loss : 0.001582570024766028 , validation_loss : 0.0019272881327196956 , Best Valid Loss : 0.0018703780369833112 \n",
            " epoch : 738, validation loss did not decrease \n",
            " Training loss : 0.00161464954726398 , validation_loss : 0.0019505821401253343 , Best Valid Loss : 0.0018703780369833112 \n",
            " epoch : 739, validation loss did not decrease \n",
            " Training loss : 0.0016557486960664392 , validation_loss : 0.0020143494475632906 , Best Valid Loss : 0.0018703780369833112 \n",
            " epoch : 740, validation loss did not decrease \n",
            " Training loss : 0.001686976058408618 , validation_loss : 0.002005009213462472 , Best Valid Loss : 0.0018703780369833112 \n",
            " epoch : 741, validation loss did not decrease \n",
            " Training loss : 0.001691408222541213 , validation_loss : 0.00197972496971488 , Best Valid Loss : 0.0018703780369833112 \n",
            " epoch : 742, validation loss did not decrease \n",
            " Training loss : 0.0016566483536735177 , validation_loss : 0.001915589440613985 , Best Valid Loss : 0.0018703780369833112 \n",
            " epoch : 743, validation loss did not decrease \n",
            " Training loss : 0.0016053670551627874 , validation_loss : 0.0018812855705618858 , Best Valid Loss : 0.0018703780369833112 \n",
            " epoch : 744, validation loss did not decrease \n",
            " Training loss : 0.0015710762236267328 , validation_loss : 0.0018734439508989453 , Best Valid Loss : 0.0018703780369833112 \n",
            " epoch : 745, validation loss did not decrease \n",
            " Training loss : 0.001567981205880642 , validation_loss : 0.0018827990861609578 , Best Valid Loss : 0.0018703780369833112 \n",
            " epoch : 746, validation loss did not decrease \n",
            " Training loss : 0.0015887889312580228 , validation_loss : 0.001938984147273004 , Best Valid Loss : 0.0018703780369833112 \n",
            " epoch : 747, validation loss did not decrease \n",
            " Training loss : 0.0016209924360737205 , validation_loss : 0.001961005385965109 , Best Valid Loss : 0.0018703780369833112 \n",
            " epoch : 748, validation loss did not decrease \n",
            " Training loss : 0.0016609099693596363 , validation_loss : 0.002030520234256983 , Best Valid Loss : 0.0018703780369833112 \n",
            " epoch : 749, validation loss did not decrease \n",
            " Training loss : 0.0016999016515910625 , validation_loss : 0.0020351267885416746 , Best Valid Loss : 0.0018703780369833112 \n",
            " epoch : 750, validation loss did not decrease \n",
            " Training loss : 0.001715656602755189 , validation_loss : 0.0020214112009853125 , Best Valid Loss : 0.0018703780369833112 \n",
            " epoch : 751, validation loss did not decrease \n",
            " Training loss : 0.0016930457204580307 , validation_loss : 0.0019568069837987423 , Best Valid Loss : 0.0018703780369833112 \n",
            " epoch : 752, validation loss did not decrease \n",
            " Training loss : 0.0016418698942288756 , validation_loss : 0.001909344457089901 , Best Valid Loss : 0.0018703780369833112 \n",
            " epoch : 753, Validation loss decreased : 0.0018703780369833112 --> 0.0018694906029850245 \n",
            " Training loss : 0.0015914372634142637 , validation_loss : 0.0018694906029850245 , Best Valid Loss : 0.0018694906029850245 \n",
            " epoch : 754, Validation loss decreased : 0.0018694906029850245 --> 0.001865990343503654 \n",
            " Training loss : 0.001566306920722127 , validation_loss : 0.001865990343503654 , Best Valid Loss : 0.001865990343503654 \n",
            " epoch : 755, validation loss did not decrease \n",
            " Training loss : 0.0015657020267099142 , validation_loss : 0.0018933974206447601 , Best Valid Loss : 0.001865990343503654 \n",
            " epoch : 756, validation loss did not decrease \n",
            " Training loss : 0.0015814974904060364 , validation_loss : 0.0019102462101727724 , Best Valid Loss : 0.001865990343503654 \n",
            " epoch : 757, validation loss did not decrease \n",
            " Training loss : 0.0016095730243250728 , validation_loss : 0.0019702971912920475 , Best Valid Loss : 0.001865990343503654 \n",
            " epoch : 758, validation loss did not decrease \n",
            " Training loss : 0.0016434343997389078 , validation_loss : 0.001989032607525587 , Best Valid Loss : 0.001865990343503654 \n",
            " epoch : 759, validation loss did not decrease \n",
            " Training loss : 0.0016722121508792043 , validation_loss : 0.0020117617677897215 , Best Valid Loss : 0.001865990343503654 \n",
            " epoch : 760, validation loss did not decrease \n",
            " Training loss : 0.001681680791079998 , validation_loss : 0.001983296126127243 , Best Valid Loss : 0.001865990343503654 \n",
            " epoch : 761, validation loss did not decrease \n",
            " Training loss : 0.0016663239803165197 , validation_loss : 0.0019640843383967876 , Best Valid Loss : 0.001865990343503654 \n",
            " epoch : 762, validation loss did not decrease \n",
            " Training loss : 0.0016374260885640979 , validation_loss : 0.0019163471879437566 , Best Valid Loss : 0.001865990343503654 \n",
            " epoch : 763, validation loss did not decrease \n",
            " Training loss : 0.0016118971398100257 , validation_loss : 0.001911696745082736 , Best Valid Loss : 0.001865990343503654 \n",
            " epoch : 764, validation loss did not decrease \n",
            " Training loss : 0.0015930080553516746 , validation_loss : 0.0018820927944034338 , Best Valid Loss : 0.001865990343503654 \n",
            " epoch : 765, validation loss did not decrease \n",
            " Training loss : 0.0015799636021256447 , validation_loss : 0.0018859634874388576 , Best Valid Loss : 0.001865990343503654 \n",
            " epoch : 766, validation loss did not decrease \n",
            " Training loss : 0.0015705792466178536 , validation_loss : 0.0018741240492090583 , Best Valid Loss : 0.001865990343503654 \n",
            " epoch : 767, validation loss did not decrease \n",
            " Training loss : 0.001564153702929616 , validation_loss : 0.001876107999123633 , Best Valid Loss : 0.001865990343503654 \n",
            " epoch : 768, validation loss did not decrease \n",
            " Training loss : 0.0015601192135363817 , validation_loss : 0.0018712026067078114 , Best Valid Loss : 0.001865990343503654 \n",
            " epoch : 769, validation loss did not decrease \n",
            " Training loss : 0.0015571539988741279 , validation_loss : 0.0018693464808166027 , Best Valid Loss : 0.001865990343503654 \n",
            " epoch : 770, validation loss did not decrease \n",
            " Training loss : 0.0015554511919617653 , validation_loss : 0.0018692105077207088 , Best Valid Loss : 0.001865990343503654 \n",
            " epoch : 771, validation loss did not decrease \n",
            " Training loss : 0.0015555359423160553 , validation_loss : 0.001866715494543314 , Best Valid Loss : 0.001865990343503654 \n",
            " epoch : 772, validation loss did not decrease \n",
            " Training loss : 0.0015572308329865336 , validation_loss : 0.0018752809846773744 , Best Valid Loss : 0.001865990343503654 \n",
            " epoch : 773, validation loss did not decrease \n",
            " Training loss : 0.001560143311508 , validation_loss : 0.0018743195105344057 , Best Valid Loss : 0.001865990343503654 \n",
            " epoch : 774, validation loss did not decrease \n",
            " Training loss : 0.0015649425331503153 , validation_loss : 0.001896518748253584 , Best Valid Loss : 0.001865990343503654 \n",
            " epoch : 775, validation loss did not decrease \n",
            " Training loss : 0.0015749059384688735 , validation_loss : 0.001905658864416182 , Best Valid Loss : 0.001865990343503654 \n",
            " epoch : 776, validation loss did not decrease \n",
            " Training loss : 0.0015913748648017645 , validation_loss : 0.001952400547452271 , Best Valid Loss : 0.001865990343503654 \n",
            " epoch : 777, validation loss did not decrease \n",
            " Training loss : 0.0016225300496444106 , validation_loss : 0.0019896395970135927 , Best Valid Loss : 0.001865990343503654 \n",
            " epoch : 778, validation loss did not decrease \n",
            " Training loss : 0.001671312260441482 , validation_loss : 0.002086061518639326 , Best Valid Loss : 0.001865990343503654 \n",
            " epoch : 779, validation loss did not decrease \n",
            " Training loss : 0.00174160476308316 , validation_loss : 0.002173143206164241 , Best Valid Loss : 0.001865990343503654 \n",
            " epoch : 780, validation loss did not decrease \n",
            " Training loss : 0.0018501154845580459 , validation_loss : 0.0023665137123316526 , Best Valid Loss : 0.001865990343503654 \n",
            " epoch : 781, validation loss did not decrease \n",
            " Training loss : 0.0019965870305895805 , validation_loss : 0.0025875531136989594 , Best Valid Loss : 0.001865990343503654 \n",
            " epoch : 782, validation loss did not decrease \n",
            " Training loss : 0.002235504100099206 , validation_loss : 0.0027950257062911987 , Best Valid Loss : 0.001865990343503654 \n",
            " epoch : 783, validation loss did not decrease \n",
            " Training loss : 0.002401504432782531 , validation_loss : 0.002935437485575676 , Best Valid Loss : 0.001865990343503654 \n",
            " epoch : 784, validation loss did not decrease \n",
            " Training loss : 0.002536968793720007 , validation_loss : 0.002598959719762206 , Best Valid Loss : 0.001865990343503654 \n",
            " epoch : 785, validation loss did not decrease \n",
            " Training loss : 0.0022299480624496937 , validation_loss : 0.0021745944395661354 , Best Valid Loss : 0.001865990343503654 \n",
            " epoch : 786, validation loss did not decrease \n",
            " Training loss : 0.001828757463954389 , validation_loss : 0.00189409707672894 , Best Valid Loss : 0.001865990343503654 \n",
            " epoch : 787, validation loss did not decrease \n",
            " Training loss : 0.0015734995249658823 , validation_loss : 0.0020436448976397514 , Best Valid Loss : 0.001865990343503654 \n",
            " epoch : 788, validation loss did not decrease \n",
            " Training loss : 0.0017060395330190659 , validation_loss : 0.00231210608035326 , Best Valid Loss : 0.001865990343503654 \n",
            " epoch : 789, validation loss did not decrease \n",
            " Training loss : 0.0020542789716273546 , validation_loss : 0.002658289857208729 , Best Valid Loss : 0.001865990343503654 \n",
            " epoch : 790, validation loss did not decrease \n",
            " Training loss : 0.0022464238572865725 , validation_loss : 0.0025917564053088427 , Best Valid Loss : 0.001865990343503654 \n",
            " epoch : 791, validation loss did not decrease \n",
            " Training loss : 0.0022600858937948942 , validation_loss : 0.002178771886974573 , Best Valid Loss : 0.001865990343503654 \n",
            " epoch : 792, validation loss did not decrease \n",
            " Training loss : 0.001845009159296751 , validation_loss : 0.001920086215250194 , Best Valid Loss : 0.001865990343503654 \n",
            " epoch : 793, validation loss did not decrease \n",
            " Training loss : 0.0016075527528300881 , validation_loss : 0.002048150170594454 , Best Valid Loss : 0.001865990343503654 \n",
            " epoch : 794, validation loss did not decrease \n",
            " Training loss : 0.0017265520291402936 , validation_loss : 0.0022686209995299578 , Best Valid Loss : 0.001865990343503654 \n",
            " epoch : 795, validation loss did not decrease \n",
            " Training loss : 0.0019146227277815342 , validation_loss : 0.002261391608044505 , Best Valid Loss : 0.001865990343503654 \n",
            " epoch : 796, validation loss did not decrease \n",
            " Training loss : 0.0019741978030651808 , validation_loss : 0.0021187441889196634 , Best Valid Loss : 0.001865990343503654 \n",
            " epoch : 797, validation loss did not decrease \n",
            " Training loss : 0.0017733802087605 , validation_loss : 0.001890896586701274 , Best Valid Loss : 0.001865990343503654 \n",
            " epoch : 798, validation loss did not decrease \n",
            " Training loss : 0.0015994752757251263 , validation_loss : 0.0018858453258872032 , Best Valid Loss : 0.001865990343503654 \n",
            " epoch : 799, validation loss did not decrease \n",
            " Training loss : 0.0015814052894711494 , validation_loss : 0.0020195345859974623 , Best Valid Loss : 0.001865990343503654 \n",
            " epoch : 800, validation loss did not decrease \n",
            " Training loss : 0.0016872416017577052 , validation_loss : 0.002075717318803072 , Best Valid Loss : 0.001865990343503654 \n",
            " epoch : 801, validation loss did not decrease \n",
            " Training loss : 0.001749802497215569 , validation_loss : 0.0019883683416992426 , Best Valid Loss : 0.001865990343503654 \n",
            " epoch : 802, validation loss did not decrease \n",
            " Training loss : 0.0016566294943913817 , validation_loss : 0.00187945447396487 , Best Valid Loss : 0.001865990343503654 \n",
            " epoch : 803, validation loss did not decrease \n",
            " Training loss : 0.0015667373081669211 , validation_loss : 0.0018815310904756188 , Best Valid Loss : 0.001865990343503654 \n",
            " epoch : 804, validation loss did not decrease \n",
            " Training loss : 0.0015788271557539701 , validation_loss : 0.001995630096644163 , Best Valid Loss : 0.001865990343503654 \n",
            " epoch : 805, validation loss did not decrease \n",
            " Training loss : 0.001659809029661119 , validation_loss : 0.0020308666862547398 , Best Valid Loss : 0.001865990343503654 \n",
            " epoch : 806, validation loss did not decrease \n",
            " Training loss : 0.0017376625910401344 , validation_loss : 0.002095622243359685 , Best Valid Loss : 0.001865990343503654 \n",
            " epoch : 807, validation loss did not decrease \n",
            " Training loss : 0.001745252520777285 , validation_loss : 0.0020147080067545176 , Best Valid Loss : 0.001865990343503654 \n",
            " epoch : 808, validation loss did not decrease \n",
            " Training loss : 0.0016882979543879628 , validation_loss : 0.0019281842978671193 , Best Valid Loss : 0.001865990343503654 \n",
            " epoch : 809, validation loss did not decrease \n",
            " Training loss : 0.0015993042616173625 , validation_loss : 0.0018784181447699666 , Best Valid Loss : 0.001865990343503654 \n",
            " epoch : 810, validation loss did not decrease \n",
            " Training loss : 0.001554384594783187 , validation_loss : 0.0018977521685883403 , Best Valid Loss : 0.001865990343503654 \n",
            " epoch : 811, validation loss did not decrease \n",
            " Training loss : 0.0015799399698153138 , validation_loss : 0.0019855527207255363 , Best Valid Loss : 0.001865990343503654 \n",
            " epoch : 812, validation loss did not decrease \n",
            " Training loss : 0.0016466871602460742 , validation_loss : 0.0020206100307404995 , Best Valid Loss : 0.001865990343503654 \n",
            " epoch : 813, validation loss did not decrease \n",
            " Training loss : 0.0017220389563590288 , validation_loss : 0.0021333612967282534 , Best Valid Loss : 0.001865990343503654 \n",
            " epoch : 814, validation loss did not decrease \n",
            " Training loss : 0.0017762159695848823 , validation_loss : 0.0021397345699369907 , Best Valid Loss : 0.001865990343503654 \n",
            " epoch : 815, validation loss did not decrease \n",
            " Training loss : 0.0018116412684321404 , validation_loss : 0.002109864726662636 , Best Valid Loss : 0.001865990343503654 \n",
            " epoch : 816, validation loss did not decrease \n",
            " Training loss : 0.0017664178740233183 , validation_loss : 0.002014709636569023 , Best Valid Loss : 0.001865990343503654 \n",
            " epoch : 817, validation loss did not decrease \n",
            " Training loss : 0.0016772453673183918 , validation_loss : 0.0019110277062281966 , Best Valid Loss : 0.001865990343503654 \n",
            " epoch : 818, Validation loss decreased : 0.001865990343503654 --> 0.001862686942331493 \n",
            " Training loss : 0.0015808778116479516 , validation_loss : 0.001862686942331493 , Best Valid Loss : 0.001862686942331493 \n",
            " epoch : 819, validation loss did not decrease \n",
            " Training loss : 0.001542486366815865 , validation_loss : 0.0018768991576507688 , Best Valid Loss : 0.001862686942331493 \n",
            " epoch : 820, validation loss did not decrease \n",
            " Training loss : 0.0015744366683065891 , validation_loss : 0.0019899921026080847 , Best Valid Loss : 0.001862686942331493 \n",
            " epoch : 821, validation loss did not decrease \n",
            " Training loss : 0.0016524018719792366 , validation_loss : 0.002054717857390642 , Best Valid Loss : 0.001862686942331493 \n",
            " epoch : 822, validation loss did not decrease \n",
            " Training loss : 0.0017545843729749322 , validation_loss : 0.002189724240452051 , Best Valid Loss : 0.001862686942331493 \n",
            " epoch : 823, validation loss did not decrease \n",
            " Training loss : 0.0018338217632845044 , validation_loss : 0.0022247731685638428 , Best Valid Loss : 0.001862686942331493 \n",
            " epoch : 824, validation loss did not decrease \n",
            " Training loss : 0.0018777366494759917 , validation_loss : 0.0021210480481386185 , Best Valid Loss : 0.001862686942331493 \n",
            " epoch : 825, validation loss did not decrease \n",
            " Training loss : 0.0017856198828667402 , validation_loss : 0.0019788765348494053 , Best Valid Loss : 0.001862686942331493 \n",
            " epoch : 826, validation loss did not decrease \n",
            " Training loss : 0.0016460433835163713 , validation_loss : 0.0018743405817076564 , Best Valid Loss : 0.001862686942331493 \n",
            " epoch : 827, validation loss did not decrease \n",
            " Training loss : 0.0015503551112487912 , validation_loss : 0.0018770848400890827 , Best Valid Loss : 0.001862686942331493 \n",
            " epoch : 828, validation loss did not decrease \n",
            " Training loss : 0.001557186827994883 , validation_loss : 0.001927833305671811 , Best Valid Loss : 0.001862686942331493 \n",
            " epoch : 829, validation loss did not decrease \n",
            " Training loss : 0.0016393656842410564 , validation_loss : 0.0021001084242016077 , Best Valid Loss : 0.001862686942331493 \n",
            " epoch : 830, validation loss did not decrease \n",
            " Training loss : 0.0017469959566369653 , validation_loss : 0.0021811900660395622 , Best Valid Loss : 0.001862686942331493 \n",
            " epoch : 831, validation loss did not decrease \n",
            " Training loss : 0.0018610762199386954 , validation_loss : 0.0022255454678088427 , Best Valid Loss : 0.001862686942331493 \n",
            " epoch : 832, validation loss did not decrease \n",
            " Training loss : 0.001876249210909009 , validation_loss : 0.002149131614714861 , Best Valid Loss : 0.001862686942331493 \n",
            " epoch : 833, validation loss did not decrease \n",
            " Training loss : 0.0017974799266085029 , validation_loss : 0.001962074311450124 , Best Valid Loss : 0.001862686942331493 \n",
            " epoch : 834, validation loss did not decrease \n",
            " Training loss : 0.001632002298720181 , validation_loss : 0.001866136328317225 , Best Valid Loss : 0.001862686942331493 \n",
            " epoch : 835, validation loss did not decrease \n",
            " Training loss : 0.0015423621516674757 , validation_loss : 0.001898928196169436 , Best Valid Loss : 0.001862686942331493 \n",
            " epoch : 836, validation loss did not decrease \n",
            " Training loss : 0.001595579320564866 , validation_loss : 0.0020784020889550447 , Best Valid Loss : 0.001862686942331493 \n",
            " epoch : 837, validation loss did not decrease \n",
            " Training loss : 0.0017263904446735978 , validation_loss : 0.0021523742470890284 , Best Valid Loss : 0.001862686942331493 \n",
            " epoch : 838, validation loss did not decrease \n",
            " Training loss : 0.0018603679491207004 , validation_loss : 0.002268788404762745 , Best Valid Loss : 0.001862686942331493 \n",
            " epoch : 839, validation loss did not decrease \n",
            " Training loss : 0.0019012168049812317 , validation_loss : 0.00221982691437006 , Best Valid Loss : 0.001862686942331493 \n",
            " epoch : 840, validation loss did not decrease \n",
            " Training loss : 0.0018689329735934734 , validation_loss : 0.0020220214501023293 , Best Valid Loss : 0.001862686942331493 \n",
            " epoch : 841, validation loss did not decrease \n",
            " Training loss : 0.0016927195247262716 , validation_loss : 0.0018887476762756705 , Best Valid Loss : 0.001862686942331493 \n",
            " epoch : 842, validation loss did not decrease \n",
            " Training loss : 0.001560008735395968 , validation_loss : 0.0019087479449808598 , Best Valid Loss : 0.001862686942331493 \n",
            " epoch : 843, validation loss did not decrease \n",
            " Training loss : 0.001589582534506917 , validation_loss : 0.002087988192215562 , Best Valid Loss : 0.001862686942331493 \n",
            " epoch : 844, validation loss did not decrease \n",
            " Training loss : 0.001733127748593688 , validation_loss : 0.002149800769984722 , Best Valid Loss : 0.001862686942331493 \n",
            " epoch : 845, validation loss did not decrease \n",
            " Training loss : 0.001869379309937358 , validation_loss : 0.002255757339298725 , Best Valid Loss : 0.001862686942331493 \n",
            " epoch : 846, validation loss did not decrease \n",
            " Training loss : 0.0018820076948031783 , validation_loss : 0.002156709088012576 , Best Valid Loss : 0.001862686942331493 \n",
            " epoch : 847, validation loss did not decrease \n",
            " Training loss : 0.0018232824513688684 , validation_loss : 0.0019920922350138426 , Best Valid Loss : 0.001862686942331493 \n",
            " epoch : 848, validation loss did not decrease \n",
            " Training loss : 0.0016602849354967475 , validation_loss : 0.0018891526851803064 , Best Valid Loss : 0.001862686942331493 \n",
            " epoch : 849, validation loss did not decrease \n",
            " Training loss : 0.0015606153756380081 , validation_loss : 0.0019292929209768772 , Best Valid Loss : 0.001862686942331493 \n",
            " epoch : 850, validation loss did not decrease \n",
            " Training loss : 0.0016025573713704944 , validation_loss : 0.0020617994014173746 , Best Valid Loss : 0.001862686942331493 \n",
            " epoch : 851, validation loss did not decrease \n",
            " Training loss : 0.0017106186132878065 , validation_loss : 0.0020749750547111034 , Best Valid Loss : 0.001862686942331493 \n",
            " epoch : 852, validation loss did not decrease \n",
            " Training loss : 0.0017874568002298474 , validation_loss : 0.002112207468599081 , Best Valid Loss : 0.001862686942331493 \n",
            " epoch : 853, validation loss did not decrease \n",
            " Training loss : 0.0017537664389237761 , validation_loss : 0.0019799412693828344 , Best Valid Loss : 0.001862686942331493 \n",
            " epoch : 854, validation loss did not decrease \n",
            " Training loss : 0.0016660053515806794 , validation_loss : 0.0019057587487623096 , Best Valid Loss : 0.001862686942331493 \n",
            " epoch : 855, validation loss did not decrease \n",
            " Training loss : 0.0015752235194668174 , validation_loss : 0.0018757355865091085 , Best Valid Loss : 0.001862686942331493 \n",
            " epoch : 856, validation loss did not decrease \n",
            " Training loss : 0.00154835544526577 , validation_loss : 0.0019065679516643286 , Best Valid Loss : 0.001862686942331493 \n",
            " epoch : 857, validation loss did not decrease \n",
            " Training loss : 0.0015793967759236693 , validation_loss : 0.0019621385727077723 , Best Valid Loss : 0.001862686942331493 \n",
            " epoch : 858, validation loss did not decrease \n",
            " Training loss : 0.0016232319176197052 , validation_loss : 0.001953122322447598 , Best Valid Loss : 0.001862686942331493 \n",
            " epoch : 859, validation loss did not decrease \n",
            " Training loss : 0.0016482601640745997 , validation_loss : 0.0019743575248867273 , Best Valid Loss : 0.001862686942331493 \n",
            " epoch : 860, validation loss did not decrease \n",
            " Training loss : 0.0016330031212419271 , validation_loss : 0.0019112752052024007 , Best Valid Loss : 0.001862686942331493 \n",
            " epoch : 861, validation loss did not decrease \n",
            " Training loss : 0.001599297160282731 , validation_loss : 0.001891092280857265 , Best Valid Loss : 0.001862686942331493 \n",
            " epoch : 862, validation loss did not decrease \n",
            " Training loss : 0.0015601931372657418 , validation_loss : 0.001865633763372898 , Best Valid Loss : 0.001862686942331493 \n",
            " epoch : 863, validation loss did not decrease \n",
            " Training loss : 0.00153870799113065 , validation_loss : 0.0018671954749152064 , Best Valid Loss : 0.001862686942331493 \n",
            " epoch : 864, validation loss did not decrease \n",
            " Training loss : 0.001539916847832501 , validation_loss : 0.00188914081081748 , Best Valid Loss : 0.001862686942331493 \n",
            " epoch : 865, validation loss did not decrease \n",
            " Training loss : 0.0015572278061881661 , validation_loss : 0.0018976505380123854 , Best Valid Loss : 0.001862686942331493 \n",
            " epoch : 866, validation loss did not decrease \n",
            " Training loss : 0.0015812140190973878 , validation_loss : 0.0019377648131921887 , Best Valid Loss : 0.001862686942331493 \n",
            " epoch : 867, validation loss did not decrease \n",
            " Training loss : 0.0015989079838618636 , validation_loss : 0.0019235657528042793 , Best Valid Loss : 0.001862686942331493 \n",
            " epoch : 868, validation loss did not decrease \n",
            " Training loss : 0.0016091768629848957 , validation_loss : 0.0019480406772345304 , Best Valid Loss : 0.001862686942331493 \n",
            " epoch : 869, validation loss did not decrease \n",
            " Training loss : 0.0016077321488410234 , validation_loss : 0.0019265018636360765 , Best Valid Loss : 0.001862686942331493 \n",
            " epoch : 870, validation loss did not decrease \n",
            " Training loss : 0.0015971051761880517 , validation_loss : 0.001910573453642428 , Best Valid Loss : 0.001862686942331493 \n",
            " epoch : 871, validation loss did not decrease \n",
            " Training loss : 0.001575147034600377 , validation_loss : 0.001878066686913371 , Best Valid Loss : 0.001862686942331493 \n",
            " epoch : 872, validation loss did not decrease \n",
            " Training loss : 0.0015496332198381424 , validation_loss : 0.001862879958935082 , Best Valid Loss : 0.001862686942331493 \n",
            " epoch : 873, Validation loss decreased : 0.001862686942331493 --> 0.0018534441478550434 \n",
            " Training loss : 0.001533151720650494 , validation_loss : 0.0018534441478550434 , Best Valid Loss : 0.0018534441478550434 \n",
            " epoch : 874, validation loss did not decrease \n",
            " Training loss : 0.0015294402837753296 , validation_loss : 0.0018536178395152092 , Best Valid Loss : 0.0018534441478550434 \n",
            " epoch : 875, validation loss did not decrease \n",
            " Training loss : 0.0015328193549066782 , validation_loss : 0.0018705290276557207 , Best Valid Loss : 0.0018534441478550434 \n",
            " epoch : 876, validation loss did not decrease \n",
            " Training loss : 0.0015403288416564465 , validation_loss : 0.0018789456225931644 , Best Valid Loss : 0.0018534441478550434 \n",
            " epoch : 877, validation loss did not decrease \n",
            " Training loss : 0.0015538062434643507 , validation_loss : 0.0019097127951681614 , Best Valid Loss : 0.0018534441478550434 \n",
            " epoch : 878, validation loss did not decrease \n",
            " Training loss : 0.0015751904575154185 , validation_loss : 0.0019229053286835551 , Best Valid Loss : 0.0018534441478550434 \n",
            " epoch : 879, validation loss did not decrease \n",
            " Training loss : 0.0015925654442980886 , validation_loss : 0.0019401570316404104 , Best Valid Loss : 0.0018534441478550434 \n",
            " epoch : 880, validation loss did not decrease \n",
            " Training loss : 0.0016023344360291958 , validation_loss : 0.0019319745479151607 , Best Valid Loss : 0.0018534441478550434 \n",
            " epoch : 881, validation loss did not decrease \n",
            " Training loss : 0.0016082916408777237 , validation_loss : 0.0019557438790798187 , Best Valid Loss : 0.0018534441478550434 \n",
            " epoch : 882, validation loss did not decrease \n",
            " Training loss : 0.0016139745712280273 , validation_loss : 0.0019401384051889181 , Best Valid Loss : 0.0018534441478550434 \n",
            " epoch : 883, validation loss did not decrease \n",
            " Training loss : 0.001620447845198214 , validation_loss : 0.0019647348672151566 , Best Valid Loss : 0.0018534441478550434 \n",
            " epoch : 884, validation loss did not decrease \n",
            " Training loss : 0.0016219160752370954 , validation_loss : 0.001946564414538443 , Best Valid Loss : 0.0018534441478550434 \n",
            " epoch : 885, validation loss did not decrease \n",
            " Training loss : 0.0016200020909309387 , validation_loss : 0.0019497629255056381 , Best Valid Loss : 0.0018534441478550434 \n",
            " epoch : 886, validation loss did not decrease \n",
            " Training loss : 0.001609206199645996 , validation_loss : 0.001917892717756331 , Best Valid Loss : 0.0018534441478550434 \n",
            " epoch : 887, validation loss did not decrease \n",
            " Training loss : 0.0015905547188594937 , validation_loss : 0.0019063249928876758 , Best Valid Loss : 0.0018534441478550434 \n",
            " epoch : 888, validation loss did not decrease \n",
            " Training loss : 0.0015697168419137597 , validation_loss : 0.0018725752597674727 , Best Valid Loss : 0.0018534441478550434 \n",
            " epoch : 889, validation loss did not decrease \n",
            " Training loss : 0.00155043532140553 , validation_loss : 0.0018689442658796906 , Best Valid Loss : 0.0018534441478550434 \n",
            " epoch : 890, Validation loss decreased : 0.0018534441478550434 --> 0.0018534250557422638 \n",
            " Training loss : 0.0015383216086775064 , validation_loss : 0.0018534250557422638 , Best Valid Loss : 0.0018534250557422638 \n",
            " epoch : 891, Validation loss decreased : 0.0018534250557422638 --> 0.0018532166723161936 \n",
            " Training loss : 0.001530310488305986 , validation_loss : 0.0018532166723161936 , Best Valid Loss : 0.0018532166723161936 \n",
            " epoch : 892, Validation loss decreased : 0.0018532166723161936 --> 0.001851136446930468 \n",
            " Training loss : 0.0015258288476616144 , validation_loss : 0.001851136446930468 , Best Valid Loss : 0.001851136446930468 \n",
            " epoch : 893, validation loss did not decrease \n",
            " Training loss : 0.001524370163679123 , validation_loss : 0.001851731212809682 , Best Valid Loss : 0.001851136446930468 \n",
            " epoch : 894, validation loss did not decrease \n",
            " Training loss : 0.0015250471187755466 , validation_loss : 0.0018561965553089976 , Best Valid Loss : 0.001851136446930468 \n",
            " epoch : 895, validation loss did not decrease \n",
            " Training loss : 0.001527059474028647 , validation_loss : 0.0018560528988018632 , Best Valid Loss : 0.001851136446930468 \n",
            " epoch : 896, validation loss did not decrease \n",
            " Training loss : 0.0015306022251024842 , validation_loss : 0.0018671243451535702 , Best Valid Loss : 0.001851136446930468 \n",
            " epoch : 897, validation loss did not decrease \n",
            " Training loss : 0.001535432180389762 , validation_loss : 0.0018657369073480368 , Best Valid Loss : 0.001851136446930468 \n",
            " epoch : 898, validation loss did not decrease \n",
            " Training loss : 0.0015419984702020884 , validation_loss : 0.0018877837574109435 , Best Valid Loss : 0.001851136446930468 \n",
            " epoch : 899, validation loss did not decrease \n",
            " Training loss : 0.001552157336845994 , validation_loss : 0.0018910181242972612 , Best Valid Loss : 0.001851136446930468 \n",
            " epoch : 900, validation loss did not decrease \n",
            " Training loss : 0.001565274316817522 , validation_loss : 0.0019222217379137874 , Best Valid Loss : 0.001851136446930468 \n",
            " epoch : 901, validation loss did not decrease \n",
            " Training loss : 0.001582503318786621 , validation_loss : 0.0019272499484941363 , Best Valid Loss : 0.001851136446930468 \n",
            " epoch : 902, validation loss did not decrease \n",
            " Training loss : 0.0015992941334843636 , validation_loss : 0.00196080282330513 , Best Valid Loss : 0.001851136446930468 \n",
            " epoch : 903, validation loss did not decrease \n",
            " Training loss : 0.0016172833275049925 , validation_loss : 0.0019625218119472265 , Best Valid Loss : 0.001851136446930468 \n",
            " epoch : 904, validation loss did not decrease \n",
            " Training loss : 0.0016361206071451306 , validation_loss : 0.0019955490715801716 , Best Valid Loss : 0.001851136446930468 \n",
            " epoch : 905, validation loss did not decrease \n",
            " Training loss : 0.0016482425853610039 , validation_loss : 0.001991031691431999 , Best Valid Loss : 0.001851136446930468 \n",
            " epoch : 906, validation loss did not decrease \n",
            " Training loss : 0.0016655728686600924 , validation_loss : 0.0020208978094160557 , Best Valid Loss : 0.001851136446930468 \n",
            " epoch : 907, validation loss did not decrease \n",
            " Training loss : 0.0016719107516109943 , validation_loss : 0.0020077091176062822 , Best Valid Loss : 0.001851136446930468 \n",
            " epoch : 908, validation loss did not decrease \n",
            " Training loss : 0.0016789243090897799 , validation_loss : 0.0020151385106146336 , Best Valid Loss : 0.001851136446930468 \n",
            " epoch : 909, validation loss did not decrease \n",
            " Training loss : 0.0016677473904564977 , validation_loss : 0.001979282358661294 , Best Valid Loss : 0.001851136446930468 \n",
            " epoch : 910, validation loss did not decrease \n",
            " Training loss : 0.0016509562265127897 , validation_loss : 0.001968402648344636 , Best Valid Loss : 0.001851136446930468 \n",
            " epoch : 911, validation loss did not decrease \n",
            " Training loss : 0.0016246456652879715 , validation_loss : 0.001923336531035602 , Best Valid Loss : 0.001851136446930468 \n",
            " epoch : 912, validation loss did not decrease \n",
            " Training loss : 0.0015993800479918718 , validation_loss : 0.0019163950346410275 , Best Valid Loss : 0.001851136446930468 \n",
            " epoch : 913, validation loss did not decrease \n",
            " Training loss : 0.001577724702656269 , validation_loss : 0.0018816188676282763 , Best Valid Loss : 0.001851136446930468 \n",
            " epoch : 914, validation loss did not decrease \n",
            " Training loss : 0.0015589187387377024 , validation_loss : 0.0018776294309645891 , Best Valid Loss : 0.001851136446930468 \n",
            " epoch : 915, validation loss did not decrease \n",
            " Training loss : 0.001544134458526969 , validation_loss : 0.0018578817835077643 , Best Valid Loss : 0.001851136446930468 \n",
            " epoch : 916, validation loss did not decrease \n",
            " Training loss : 0.0015338731463998556 , validation_loss : 0.0018570763058960438 , Best Valid Loss : 0.001851136446930468 \n",
            " epoch : 917, Validation loss decreased : 0.001851136446930468 --> 0.0018483902094885707 \n",
            " Training loss : 0.001526883919723332 , validation_loss : 0.0018483902094885707 , Best Valid Loss : 0.0018483902094885707 \n",
            " epoch : 918, Validation loss decreased : 0.0018483902094885707 --> 0.0018483831081539392 \n",
            " Training loss : 0.0015224782982841134 , validation_loss : 0.0018483831081539392 , Best Valid Loss : 0.0018483831081539392 \n",
            " epoch : 919, Validation loss decreased : 0.0018483831081539392 --> 0.0018470827490091324 \n",
            " Training loss : 0.0015200357884168625 , validation_loss : 0.0018470827490091324 , Best Valid Loss : 0.0018470827490091324 \n",
            " epoch : 920, Validation loss decreased : 0.0018470827490091324 --> 0.001846945844590664 \n",
            " Training loss : 0.0015191928250715137 , validation_loss : 0.001846945844590664 , Best Valid Loss : 0.001846945844590664 \n",
            " epoch : 921, validation loss did not decrease \n",
            " Training loss : 0.0015193752478808165 , validation_loss : 0.001850586268119514 , Best Valid Loss : 0.001846945844590664 \n",
            " epoch : 922, validation loss did not decrease \n",
            " Training loss : 0.0015203463844954967 , validation_loss : 0.0018500842852517962 , Best Valid Loss : 0.001846945844590664 \n",
            " epoch : 923, validation loss did not decrease \n",
            " Training loss : 0.001522569451481104 , validation_loss : 0.0018598787719383836 , Best Valid Loss : 0.001846945844590664 \n",
            " epoch : 924, validation loss did not decrease \n",
            " Training loss : 0.0015266466652974486 , validation_loss : 0.0018606649246066809 , Best Valid Loss : 0.001846945844590664 \n",
            " epoch : 925, validation loss did not decrease \n",
            " Training loss : 0.0015332265757024288 , validation_loss : 0.0018829932669177651 , Best Valid Loss : 0.001846945844590664 \n",
            " epoch : 926, validation loss did not decrease \n",
            " Training loss : 0.0015457585686817765 , validation_loss : 0.0018923890311270952 , Best Valid Loss : 0.001846945844590664 \n",
            " epoch : 927, validation loss did not decrease \n",
            " Training loss : 0.0015647461405023932 , validation_loss : 0.0019371762173250318 , Best Valid Loss : 0.001846945844590664 \n",
            " epoch : 928, validation loss did not decrease \n",
            " Training loss : 0.0015941847814247012 , validation_loss : 0.001968726748600602 , Best Valid Loss : 0.001846945844590664 \n",
            " epoch : 929, validation loss did not decrease \n",
            " Training loss : 0.0016396589344367385 , validation_loss : 0.00204926123842597 , Best Valid Loss : 0.001846945844590664 \n",
            " epoch : 930, validation loss did not decrease \n",
            " Training loss : 0.001697069383226335 , validation_loss : 0.0021233747247606516 , Best Valid Loss : 0.001846945844590664 \n",
            " epoch : 931, validation loss did not decrease \n",
            " Training loss : 0.001788454712368548 , validation_loss : 0.0022517754696309566 , Best Valid Loss : 0.001846945844590664 \n",
            " epoch : 932, validation loss did not decrease \n",
            " Training loss : 0.0018866586033254862 , validation_loss : 0.0023865127004683018 , Best Valid Loss : 0.001846945844590664 \n",
            " epoch : 933, validation loss did not decrease \n",
            " Training loss : 0.0020353118889033794 , validation_loss : 0.0024902252480387688 , Best Valid Loss : 0.001846945844590664 \n",
            " epoch : 934, validation loss did not decrease \n",
            " Training loss : 0.0021149751264601946 , validation_loss : 0.002526666270568967 , Best Valid Loss : 0.001846945844590664 \n",
            " epoch : 935, validation loss did not decrease \n",
            " Training loss : 0.002159600146114826 , validation_loss : 0.002335407305508852 , Best Valid Loss : 0.001846945844590664 \n",
            " epoch : 936, validation loss did not decrease \n",
            " Training loss : 0.001969854813069105 , validation_loss : 0.0020767604000866413 , Best Valid Loss : 0.001846945844590664 \n",
            " epoch : 937, validation loss did not decrease \n",
            " Training loss : 0.0017399482894688845 , validation_loss : 0.0018966805655509233 , Best Valid Loss : 0.001846945844590664 \n",
            " epoch : 938, validation loss did not decrease \n",
            " Training loss : 0.0015588047681376338 , validation_loss : 0.0018641933565959334 , Best Valid Loss : 0.001846945844590664 \n",
            " epoch : 939, validation loss did not decrease \n",
            " Training loss : 0.0015363577986136079 , validation_loss : 0.0019463984062895179 , Best Valid Loss : 0.001846945844590664 \n",
            " epoch : 940, validation loss did not decrease \n",
            " Training loss : 0.001648693811148405 , validation_loss : 0.00216100225225091 , Best Valid Loss : 0.001846945844590664 \n",
            " epoch : 941, validation loss did not decrease \n",
            " Training loss : 0.0017944033024832606 , validation_loss : 0.0022307445760816336 , Best Valid Loss : 0.001846945844590664 \n",
            " epoch : 942, validation loss did not decrease \n",
            " Training loss : 0.0018944664625450969 , validation_loss : 0.002162231132388115 , Best Valid Loss : 0.001846945844590664 \n",
            " epoch : 943, validation loss did not decrease \n",
            " Training loss : 0.0018223074730485678 , validation_loss : 0.0020013211760669947 , Best Valid Loss : 0.001846945844590664 \n",
            " epoch : 944, validation loss did not decrease \n",
            " Training loss : 0.001664974493905902 , validation_loss : 0.001861479366198182 , Best Valid Loss : 0.001846945844590664 \n",
            " epoch : 945, validation loss did not decrease \n",
            " Training loss : 0.0015379084507003427 , validation_loss : 0.0018873648950830102 , Best Valid Loss : 0.001846945844590664 \n",
            " epoch : 946, validation loss did not decrease \n",
            " Training loss : 0.0015560956671833992 , validation_loss : 0.001985109644010663 , Best Valid Loss : 0.001846945844590664 \n",
            " epoch : 947, validation loss did not decrease \n",
            " Training loss : 0.0016880125040188432 , validation_loss : 0.002191578969359398 , Best Valid Loss : 0.001846945844590664 \n",
            " epoch : 948, validation loss did not decrease \n",
            " Training loss : 0.0018175146542489529 , validation_loss : 0.0022128920536488295 , Best Valid Loss : 0.001846945844590664 \n",
            " epoch : 949, validation loss did not decrease \n",
            " Training loss : 0.0018868730403482914 , validation_loss : 0.0021372458431869745 , Best Valid Loss : 0.001846945844590664 \n",
            " epoch : 950, validation loss did not decrease \n",
            " Training loss : 0.0017883627442643046 , validation_loss : 0.0019790534861385822 , Best Valid Loss : 0.001846945844590664 \n",
            " epoch : 951, validation loss did not decrease \n",
            " Training loss : 0.0016328486381098628 , validation_loss : 0.0018676326144486666 , Best Valid Loss : 0.001846945844590664 \n",
            " epoch : 952, validation loss did not decrease \n",
            " Training loss : 0.001532228197902441 , validation_loss : 0.0019422739278525114 , Best Valid Loss : 0.001846945844590664 \n",
            " epoch : 953, validation loss did not decrease \n",
            " Training loss : 0.0015970354434102774 , validation_loss : 0.002044537803158164 , Best Valid Loss : 0.001846945844590664 \n",
            " epoch : 954, validation loss did not decrease \n",
            " Training loss : 0.0017632980598136783 , validation_loss : 0.0022656219080090523 , Best Valid Loss : 0.001846945844590664 \n",
            " epoch : 955, validation loss did not decrease \n",
            " Training loss : 0.0018794434145092964 , validation_loss : 0.0022521258797496557 , Best Valid Loss : 0.001846945844590664 \n",
            " epoch : 956, validation loss did not decrease \n",
            " Training loss : 0.001920245704241097 , validation_loss : 0.0021395713556557894 , Best Valid Loss : 0.001846945844590664 \n",
            " epoch : 957, validation loss did not decrease \n",
            " Training loss : 0.0017955641960725188 , validation_loss : 0.0019712180364876986 , Best Valid Loss : 0.001846945844590664 \n",
            " epoch : 958, validation loss did not decrease \n",
            " Training loss : 0.0016250757034868002 , validation_loss : 0.0018602550262585282 , Best Valid Loss : 0.001846945844590664 \n",
            " epoch : 959, validation loss did not decrease \n",
            " Training loss : 0.0015274060424417257 , validation_loss : 0.0019445784855633974 , Best Valid Loss : 0.001846945844590664 \n",
            " epoch : 960, validation loss did not decrease \n",
            " Training loss : 0.0015993287088349462 , validation_loss : 0.002069437177851796 , Best Valid Loss : 0.001846945844590664 \n",
            " epoch : 961, validation loss did not decrease \n",
            " Training loss : 0.0017814692109823227 , validation_loss : 0.0023301830515265465 , Best Valid Loss : 0.001846945844590664 \n",
            " epoch : 962, validation loss did not decrease \n",
            " Training loss : 0.0019375787815079093 , validation_loss : 0.002374977106228471 , Best Valid Loss : 0.001846945844590664 \n",
            " epoch : 963, validation loss did not decrease \n",
            " Training loss : 0.0020343519281595945 , validation_loss : 0.002236186061054468 , Best Valid Loss : 0.001846945844590664 \n",
            " epoch : 964, validation loss did not decrease \n",
            " Training loss : 0.00189236702863127 , validation_loss : 0.0020248140208423138 , Best Valid Loss : 0.001846945844590664 \n",
            " epoch : 965, validation loss did not decrease \n",
            " Training loss : 0.0016693990910425782 , validation_loss : 0.0018698708154261112 , Best Valid Loss : 0.001846945844590664 \n",
            " epoch : 966, validation loss did not decrease \n",
            " Training loss : 0.0015336230862885714 , validation_loss : 0.0019959094934165478 , Best Valid Loss : 0.001846945844590664 \n",
            " epoch : 967, validation loss did not decrease \n",
            " Training loss : 0.001643884927034378 , validation_loss : 0.0021582001354545355 , Best Valid Loss : 0.001846945844590664 \n",
            " epoch : 968, validation loss did not decrease \n",
            " Training loss : 0.0018914705142378807 , validation_loss : 0.002449179533869028 , Best Valid Loss : 0.001846945844590664 \n",
            " epoch : 969, validation loss did not decrease \n",
            " Training loss : 0.0020430271979421377 , validation_loss : 0.0024232969153672457 , Best Valid Loss : 0.001846945844590664 \n",
            " epoch : 970, validation loss did not decrease \n",
            " Training loss : 0.002079849364235997 , validation_loss : 0.0021583756897598505 , Best Valid Loss : 0.001846945844590664 \n",
            " epoch : 971, validation loss did not decrease \n",
            " Training loss : 0.0018231852445751429 , validation_loss : 0.0019252275815233588 , Best Valid Loss : 0.001846945844590664 \n",
            " epoch : 972, validation loss did not decrease \n",
            " Training loss : 0.0015861432766541839 , validation_loss : 0.0019377140561118722 , Best Valid Loss : 0.001846945844590664 \n",
            " epoch : 973, validation loss did not decrease \n",
            " Training loss : 0.0015983860939741135 , validation_loss : 0.002169988816604018 , Best Valid Loss : 0.001846945844590664 \n",
            " epoch : 974, validation loss did not decrease \n",
            " Training loss : 0.0017994274385273457 , validation_loss : 0.00225085043348372 , Best Valid Loss : 0.001846945844590664 \n",
            " epoch : 975, validation loss did not decrease \n",
            " Training loss : 0.0019804229959845543 , validation_loss : 0.002305661328136921 , Best Valid Loss : 0.001846945844590664 \n",
            " epoch : 976, validation loss did not decrease \n",
            " Training loss : 0.0019164648838341236 , validation_loss : 0.0020775310695171356 , Best Valid Loss : 0.001846945844590664 \n",
            " epoch : 977, validation loss did not decrease \n",
            " Training loss : 0.0017452638130635023 , validation_loss : 0.0018972691614180803 , Best Valid Loss : 0.001846945844590664 \n",
            " epoch : 978, validation loss did not decrease \n",
            " Training loss : 0.0015673727029934525 , validation_loss : 0.001900054863654077 , Best Valid Loss : 0.001846945844590664 \n",
            " epoch : 979, validation loss did not decrease \n",
            " Training loss : 0.0015707167331129313 , validation_loss : 0.0020259602461010218 , Best Valid Loss : 0.001846945844590664 \n",
            " epoch : 980, validation loss did not decrease \n",
            " Training loss : 0.001688774791546166 , validation_loss : 0.0021013268269598484 , Best Valid Loss : 0.001846945844590664 \n",
            " epoch : 981, validation loss did not decrease \n",
            " Training loss : 0.001737596932798624 , validation_loss : 0.0019808204378932714 , Best Valid Loss : 0.001846945844590664 \n",
            " epoch : 982, validation loss did not decrease \n",
            " Training loss : 0.0016879589529708028 , validation_loss : 0.0019118505297228694 , Best Valid Loss : 0.001846945844590664 \n",
            " epoch : 983, Validation loss decreased : 0.001846945844590664 --> 0.001843160716816783 \n",
            " Training loss : 0.0015725202392786741 , validation_loss : 0.001843160716816783 , Best Valid Loss : 0.001843160716816783 \n",
            " epoch : 984, validation loss did not decrease \n",
            " Training loss : 0.0015149167738854885 , validation_loss : 0.0018823175923898816 , Best Valid Loss : 0.001843160716816783 \n",
            " epoch : 985, validation loss did not decrease \n",
            " Training loss : 0.0015494184335693717 , validation_loss : 0.001932689337991178 , Best Valid Loss : 0.001843160716816783 \n",
            " epoch : 986, validation loss did not decrease \n",
            " Training loss : 0.001596528454683721 , validation_loss : 0.001926420722156763 , Best Valid Loss : 0.001843160716816783 \n",
            " epoch : 987, validation loss did not decrease \n",
            " Training loss : 0.0015943696489557624 , validation_loss : 0.0018919120775535703 , Best Valid Loss : 0.001843160716816783 \n",
            " epoch : 988, Validation loss decreased : 0.001843160716816783 --> 0.00184166943654418 \n",
            " Training loss : 0.0015536616556346416 , validation_loss : 0.00184166943654418 , Best Valid Loss : 0.00184166943654418 \n",
            " epoch : 989, Validation loss decreased : 0.00184166943654418 --> 0.0018375565996393561 \n",
            " Training loss : 0.0015212431317195296 , validation_loss : 0.0018375565996393561 , Best Valid Loss : 0.0018375565996393561 \n",
            " epoch : 990, validation loss did not decrease \n",
            " Training loss : 0.0015146787045523524 , validation_loss : 0.0018662752117961645 , Best Valid Loss : 0.0018375565996393561 \n",
            " epoch : 991, validation loss did not decrease \n",
            " Training loss : 0.0015308352885767817 , validation_loss : 0.0018863951554521918 , Best Valid Loss : 0.0018375565996393561 \n",
            " epoch : 992, validation loss did not decrease \n",
            " Training loss : 0.0015559536404907703 , validation_loss : 0.0019037866732105613 , Best Valid Loss : 0.0018375565996393561 \n",
            " epoch : 993, validation loss did not decrease \n",
            " Training loss : 0.0015656695468351245 , validation_loss : 0.0018802237464115024 , Best Valid Loss : 0.0018375565996393561 \n",
            " epoch : 994, validation loss did not decrease \n",
            " Training loss : 0.0015461677685379982 , validation_loss : 0.0018537946743890643 , Best Valid Loss : 0.0018375565996393561 \n",
            " epoch : 995, Validation loss decreased : 0.0018375565996393561 --> 0.001835992094129324 \n",
            " Training loss : 0.0015186143573373556 , validation_loss : 0.001835992094129324 , Best Valid Loss : 0.001835992094129324 \n",
            " epoch : 996, validation loss did not decrease \n",
            " Training loss : 0.001507923356257379 , validation_loss : 0.0018366356380283833 , Best Valid Loss : 0.001835992094129324 \n",
            " epoch : 997, validation loss did not decrease \n",
            " Training loss : 0.001512305112555623 , validation_loss : 0.001858643488958478 , Best Valid Loss : 0.001835992094129324 \n",
            " epoch : 998, validation loss did not decrease \n",
            " Training loss : 0.0015233277808874846 , validation_loss : 0.001867710379883647 , Best Valid Loss : 0.001835992094129324 \n",
            " epoch : 999, validation loss did not decrease \n",
            " Training loss : 0.0015382029814645648 , validation_loss : 0.0018903349991887808 , Best Valid Loss : 0.001835992094129324 \n",
            " epoch : 1000, validation loss did not decrease \n",
            " Training loss : 0.0015518992440775037 , validation_loss : 0.0018857225077226758 , Best Valid Loss : 0.001835992094129324 \n",
            " epoch : 1001, validation loss did not decrease \n",
            " Training loss : 0.0015508165815845132 , validation_loss : 0.0018743163673207164 , Best Valid Loss : 0.001835992094129324 \n",
            " epoch : 1002, validation loss did not decrease \n",
            " Training loss : 0.0015368836466223001 , validation_loss : 0.001849962049163878 , Best Valid Loss : 0.001835992094129324 \n",
            " epoch : 1003, validation loss did not decrease \n",
            " Training loss : 0.0015220226487144828 , validation_loss : 0.001844491227529943 , Best Valid Loss : 0.001835992094129324 \n",
            " epoch : 1004, Validation loss decreased : 0.001835992094129324 --> 0.001834768452681601 \n",
            " Training loss : 0.0015120655298233032 , validation_loss : 0.001834768452681601 , Best Valid Loss : 0.001834768452681601 \n",
            " epoch : 1005, validation loss did not decrease \n",
            " Training loss : 0.0015066486084833741 , validation_loss : 0.0018356033833697438 , Best Valid Loss : 0.001834768452681601 \n",
            " epoch : 1006, validation loss did not decrease \n",
            " Training loss : 0.0015050641959533095 , validation_loss : 0.0018418990075588226 , Best Valid Loss : 0.001834768452681601 \n",
            " epoch : 1007, validation loss did not decrease \n",
            " Training loss : 0.0015078542055562139 , validation_loss : 0.0018447886686772108 , Best Valid Loss : 0.001834768452681601 \n",
            " epoch : 1008, validation loss did not decrease \n",
            " Training loss : 0.0015121500473469496 , validation_loss : 0.0018509438959881663 , Best Valid Loss : 0.001834768452681601 \n",
            " epoch : 1009, validation loss did not decrease \n",
            " Training loss : 0.0015153795247897506 , validation_loss : 0.0018463481683284044 , Best Valid Loss : 0.001834768452681601 \n",
            " epoch : 1010, validation loss did not decrease \n",
            " Training loss : 0.0015170247061178088 , validation_loss : 0.0018534875707700849 , Best Valid Loss : 0.001834768452681601 \n",
            " epoch : 1011, validation loss did not decrease \n",
            " Training loss : 0.0015181113267317414 , validation_loss : 0.0018447641050443053 , Best Valid Loss : 0.001834768452681601 \n",
            " epoch : 1012, validation loss did not decrease \n",
            " Training loss : 0.0015178961912170053 , validation_loss : 0.0018521938472986221 , Best Valid Loss : 0.001834768452681601 \n",
            " epoch : 1013, validation loss did not decrease \n",
            " Training loss : 0.0015166000230237842 , validation_loss : 0.0018456398975104094 , Best Valid Loss : 0.001834768452681601 \n",
            " epoch : 1014, validation loss did not decrease \n",
            " Training loss : 0.0015147750964388251 , validation_loss : 0.0018478896236047149 , Best Valid Loss : 0.001834768452681601 \n",
            " epoch : 1015, validation loss did not decrease \n",
            " Training loss : 0.001512504881247878 , validation_loss : 0.0018404758302494884 , Best Valid Loss : 0.001834768452681601 \n",
            " epoch : 1016, validation loss did not decrease \n",
            " Training loss : 0.0015089965891093016 , validation_loss : 0.0018398337997496128 , Best Valid Loss : 0.001834768452681601 \n",
            " epoch : 1017, Validation loss decreased : 0.001834768452681601 --> 0.0018337229266762733 \n",
            " Training loss : 0.001506139407865703 , validation_loss : 0.0018337229266762733 , Best Valid Loss : 0.0018337229266762733 \n",
            " epoch : 1018, validation loss did not decrease \n",
            " Training loss : 0.0015041943406686187 , validation_loss : 0.0018343136180192232 , Best Valid Loss : 0.0018337229266762733 \n",
            " epoch : 1019, Validation loss decreased : 0.0018337229266762733 --> 0.0018329336307942867 \n",
            " Training loss : 0.001502913306467235 , validation_loss : 0.0018329336307942867 , Best Valid Loss : 0.0018329336307942867 \n",
            " epoch : 1020, validation loss did not decrease \n",
            " Training loss : 0.0015019901329651475 , validation_loss : 0.0018335826462134719 , Best Valid Loss : 0.0018329336307942867 \n",
            " epoch : 1021, validation loss did not decrease \n",
            " Training loss : 0.0015017888508737087 , validation_loss : 0.0018350336467847228 , Best Valid Loss : 0.0018329336307942867 \n",
            " epoch : 1022, validation loss did not decrease \n",
            " Training loss : 0.001502115512266755 , validation_loss : 0.0018340395763516426 , Best Valid Loss : 0.0018329336307942867 \n",
            " epoch : 1023, validation loss did not decrease \n",
            " Training loss : 0.0015024488093331456 , validation_loss : 0.0018356562359258533 , Best Valid Loss : 0.0018329336307942867 \n",
            " epoch : 1024, validation loss did not decrease \n",
            " Training loss : 0.0015027839690446854 , validation_loss : 0.0018329982412979007 , Best Valid Loss : 0.0018329336307942867 \n",
            " epoch : 1025, validation loss did not decrease \n",
            " Training loss : 0.0015033938689157367 , validation_loss : 0.0018369801109656692 , Best Valid Loss : 0.0018329336307942867 \n",
            " epoch : 1026, validation loss did not decrease \n",
            " Training loss : 0.0015041062142699957 , validation_loss : 0.0018342953408136964 , Best Valid Loss : 0.0018329336307942867 \n",
            " epoch : 1027, validation loss did not decrease \n",
            " Training loss : 0.001504789455793798 , validation_loss : 0.0018393624341115355 , Best Valid Loss : 0.0018329336307942867 \n",
            " epoch : 1028, validation loss did not decrease \n",
            " Training loss : 0.001505360589362681 , validation_loss : 0.0018366776639595628 , Best Valid Loss : 0.0018329336307942867 \n",
            " epoch : 1029, validation loss did not decrease \n",
            " Training loss : 0.0015059527941048145 , validation_loss : 0.001841108431108296 , Best Valid Loss : 0.0018329336307942867 \n",
            " epoch : 1030, validation loss did not decrease \n",
            " Training loss : 0.0015065680490806699 , validation_loss : 0.0018370874458923936 , Best Valid Loss : 0.0018329336307942867 \n",
            " epoch : 1031, validation loss did not decrease \n",
            " Training loss : 0.0015073114773258567 , validation_loss : 0.0018423491856083274 , Best Valid Loss : 0.0018329336307942867 \n",
            " epoch : 1032, validation loss did not decrease \n",
            " Training loss : 0.0015078112483024597 , validation_loss : 0.0018370626494288445 , Best Valid Loss : 0.0018329336307942867 \n",
            " epoch : 1033, validation loss did not decrease \n",
            " Training loss : 0.0015084160258993506 , validation_loss : 0.0018437146209180355 , Best Valid Loss : 0.0018329336307942867 \n",
            " epoch : 1034, validation loss did not decrease \n",
            " Training loss : 0.0015087880892679095 , validation_loss : 0.001839085598476231 , Best Valid Loss : 0.0018329336307942867 \n",
            " epoch : 1035, validation loss did not decrease \n",
            " Training loss : 0.0015092764515429735 , validation_loss : 0.001844259793870151 , Best Valid Loss : 0.0018329336307942867 \n",
            " epoch : 1036, validation loss did not decrease \n",
            " Training loss : 0.0015090052038431168 , validation_loss : 0.0018387653399258852 , Best Valid Loss : 0.0018329336307942867 \n",
            " epoch : 1037, validation loss did not decrease \n",
            " Training loss : 0.0015086493222042918 , validation_loss : 0.0018426001770421863 , Best Valid Loss : 0.0018329336307942867 \n",
            " epoch : 1038, validation loss did not decrease \n",
            " Training loss : 0.0015076522249728441 , validation_loss : 0.001836244249716401 , Best Valid Loss : 0.0018329336307942867 \n",
            " epoch : 1039, validation loss did not decrease \n",
            " Training loss : 0.0015070497756823897 , validation_loss : 0.001841215300373733 , Best Valid Loss : 0.0018329336307942867 \n",
            " epoch : 1040, validation loss did not decrease \n",
            " Training loss : 0.0015065405750647187 , validation_loss : 0.001836038543842733 , Best Valid Loss : 0.0018329336307942867 \n",
            " epoch : 1041, validation loss did not decrease \n",
            " Training loss : 0.0015065106563270092 , validation_loss : 0.0018412942299619317 , Best Valid Loss : 0.0018329336307942867 \n",
            " epoch : 1042, validation loss did not decrease \n",
            " Training loss : 0.0015063503524288535 , validation_loss : 0.0018368964083492756 , Best Valid Loss : 0.0018329336307942867 \n",
            " epoch : 1043, validation loss did not decrease \n",
            " Training loss : 0.0015067115891724825 , validation_loss : 0.0018422757275402546 , Best Valid Loss : 0.0018329336307942867 \n",
            " epoch : 1044, validation loss did not decrease \n",
            " Training loss : 0.0015070615336298943 , validation_loss : 0.0018372309859842062 , Best Valid Loss : 0.0018329336307942867 \n",
            " epoch : 1045, validation loss did not decrease \n",
            " Training loss : 0.0015075578121468425 , validation_loss : 0.0018433657241985202 , Best Valid Loss : 0.0018329336307942867 \n",
            " epoch : 1046, validation loss did not decrease \n",
            " Training loss : 0.0015079905278980732 , validation_loss : 0.0018383563729003072 , Best Valid Loss : 0.0018329336307942867 \n",
            " epoch : 1047, validation loss did not decrease \n",
            " Training loss : 0.0015092173125594854 , validation_loss : 0.0018475493416190147 , Best Valid Loss : 0.0018329336307942867 \n",
            " epoch : 1048, validation loss did not decrease \n",
            " Training loss : 0.0015114289708435535 , validation_loss : 0.0018444773741066456 , Best Valid Loss : 0.0018329336307942867 \n",
            " epoch : 1049, validation loss did not decrease \n",
            " Training loss : 0.0015149523969739676 , validation_loss : 0.0018564880592748523 , Best Valid Loss : 0.0018329336307942867 \n",
            " epoch : 1050, validation loss did not decrease \n",
            " Training loss : 0.001519112498499453 , validation_loss : 0.0018543337937444448 , Best Valid Loss : 0.0018329336307942867 \n",
            " epoch : 1051, validation loss did not decrease \n",
            " Training loss : 0.0015250144060701132 , validation_loss : 0.0018702284432947636 , Best Valid Loss : 0.0018329336307942867 \n",
            " epoch : 1052, validation loss did not decrease \n",
            " Training loss : 0.001531176152639091 , validation_loss : 0.0018682230729609728 , Best Valid Loss : 0.0018329336307942867 \n",
            " epoch : 1053, validation loss did not decrease \n",
            " Training loss : 0.0015396670205518603 , validation_loss : 0.0018893907545134425 , Best Valid Loss : 0.0018329336307942867 \n",
            " epoch : 1054, validation loss did not decrease \n",
            " Training loss : 0.0015482344897463918 , validation_loss : 0.001888525323010981 , Best Valid Loss : 0.0018329336307942867 \n",
            " epoch : 1055, validation loss did not decrease \n",
            " Training loss : 0.0015592239797115326 , validation_loss : 0.0019107279367744923 , Best Valid Loss : 0.0018329336307942867 \n",
            " epoch : 1056, validation loss did not decrease \n",
            " Training loss : 0.0015676519833505154 , validation_loss : 0.0019086392130702734 , Best Valid Loss : 0.0018329336307942867 \n",
            " epoch : 1057, validation loss did not decrease \n",
            " Training loss : 0.0015784415882080793 , validation_loss : 0.0019316863035783172 , Best Valid Loss : 0.0018329336307942867 \n",
            " epoch : 1058, validation loss did not decrease \n",
            " Training loss : 0.0015867940383031964 , validation_loss : 0.0019238843815401196 , Best Valid Loss : 0.0018329336307942867 \n",
            " epoch : 1059, validation loss did not decrease \n",
            " Training loss : 0.0015934795374050736 , validation_loss : 0.0019399637822061777 , Best Valid Loss : 0.0018329336307942867 \n",
            " epoch : 1060, validation loss did not decrease \n",
            " Training loss : 0.0015943152830004692 , validation_loss : 0.0019233039347454906 , Best Valid Loss : 0.0018329336307942867 \n",
            " epoch : 1061, validation loss did not decrease \n",
            " Training loss : 0.001593399210833013 , validation_loss : 0.0019316152902320027 , Best Valid Loss : 0.0018329336307942867 \n",
            " epoch : 1062, validation loss did not decrease \n",
            " Training loss : 0.0015867146430537105 , validation_loss : 0.0019076982280239463 , Best Valid Loss : 0.0018329336307942867 \n",
            " epoch : 1063, validation loss did not decrease \n",
            " Training loss : 0.0015783365815877914 , validation_loss : 0.001910258550196886 , Best Valid Loss : 0.0018329336307942867 \n",
            " epoch : 1064, validation loss did not decrease \n",
            " Training loss : 0.0015674588503316045 , validation_loss : 0.0018844736041501164 , Best Valid Loss : 0.0018329336307942867 \n",
            " epoch : 1065, validation loss did not decrease \n",
            " Training loss : 0.0015558951999992132 , validation_loss : 0.001881600241176784 , Best Valid Loss : 0.0018329336307942867 \n",
            " epoch : 1066, validation loss did not decrease \n",
            " Training loss : 0.001541640842333436 , validation_loss : 0.0018584183417260647 , Best Valid Loss : 0.0018329336307942867 \n",
            " epoch : 1067, validation loss did not decrease \n",
            " Training loss : 0.0015311012975871563 , validation_loss : 0.0018590446561574936 , Best Valid Loss : 0.0018329336307942867 \n",
            " epoch : 1068, validation loss did not decrease \n",
            " Training loss : 0.00152172043453902 , validation_loss : 0.0018430312629789114 , Best Valid Loss : 0.0018329336307942867 \n",
            " epoch : 1069, validation loss did not decrease \n",
            " Training loss : 0.0015151556581258774 , validation_loss : 0.0018452373333275318 , Best Valid Loss : 0.0018329336307942867 \n",
            " epoch : 1070, validation loss did not decrease \n",
            " Training loss : 0.0015097296563908458 , validation_loss : 0.0018349887104704976 , Best Valid Loss : 0.0018329336307942867 \n",
            " epoch : 1071, validation loss did not decrease \n",
            " Training loss : 0.001506239757873118 , validation_loss : 0.0018374257488176227 , Best Valid Loss : 0.0018329336307942867 \n",
            " epoch : 1072, Validation loss decreased : 0.0018329336307942867 --> 0.0018302982207387686 \n",
            " Training loss : 0.001502953702583909 , validation_loss : 0.0018302982207387686 , Best Valid Loss : 0.0018302982207387686 \n",
            " epoch : 1073, validation loss did not decrease \n",
            " Training loss : 0.001501408638432622 , validation_loss : 0.00183387182187289 , Best Valid Loss : 0.0018302982207387686 \n",
            " epoch : 1074, Validation loss decreased : 0.0018302982207387686 --> 0.0018286426784470677 \n",
            " Training loss : 0.0014998187543824315 , validation_loss : 0.0018286426784470677 , Best Valid Loss : 0.0018286426784470677 \n",
            " epoch : 1075, validation loss did not decrease \n",
            " Training loss : 0.001499385922215879 , validation_loss : 0.0018340583192184567 , Best Valid Loss : 0.0018286426784470677 \n",
            " epoch : 1076, validation loss did not decrease \n",
            " Training loss : 0.0014996066456660628 , validation_loss : 0.0018308993894606829 , Best Valid Loss : 0.0018286426784470677 \n",
            " epoch : 1077, validation loss did not decrease \n",
            " Training loss : 0.001501197461038828 , validation_loss : 0.0018384354189038277 , Best Valid Loss : 0.0018286426784470677 \n",
            " epoch : 1078, validation loss did not decrease \n",
            " Training loss : 0.00150296778883785 , validation_loss : 0.0018366879085078835 , Best Valid Loss : 0.0018286426784470677 \n",
            " epoch : 1079, validation loss did not decrease \n",
            " Training loss : 0.001507486216723919 , validation_loss : 0.0018498876597732306 , Best Valid Loss : 0.0018286426784470677 \n",
            " epoch : 1080, validation loss did not decrease \n",
            " Training loss : 0.00151265028398484 , validation_loss : 0.001849930384196341 , Best Valid Loss : 0.0018286426784470677 \n",
            " epoch : 1081, validation loss did not decrease \n",
            " Training loss : 0.0015211326535791159 , validation_loss : 0.0018714753678068519 , Best Valid Loss : 0.0018286426784470677 \n",
            " epoch : 1082, validation loss did not decrease \n",
            " Training loss : 0.0015316499629989266 , validation_loss : 0.0018782783299684525 , Best Valid Loss : 0.0018286426784470677 \n",
            " epoch : 1083, validation loss did not decrease \n",
            " Training loss : 0.001548756379634142 , validation_loss : 0.0019110525026917458 , Best Valid Loss : 0.0018286426784470677 \n",
            " epoch : 1084, validation loss did not decrease \n",
            " Training loss : 0.0015673113521188498 , validation_loss : 0.0019281774293631315 , Best Valid Loss : 0.0018286426784470677 \n",
            " epoch : 1085, validation loss did not decrease \n",
            " Training loss : 0.0015982207842171192 , validation_loss : 0.001985647017136216 , Best Valid Loss : 0.0018286426784470677 \n",
            " epoch : 1086, validation loss did not decrease \n",
            " Training loss : 0.0016359769506379962 , validation_loss : 0.0020268382504582405 , Best Valid Loss : 0.0018286426784470677 \n",
            " epoch : 1087, validation loss did not decrease \n",
            " Training loss : 0.0016923235962167382 , validation_loss : 0.002103369915857911 , Best Valid Loss : 0.0018286426784470677 \n",
            " epoch : 1088, validation loss did not decrease \n",
            " Training loss : 0.001746876398101449 , validation_loss : 0.0021590052638202906 , Best Valid Loss : 0.0018286426784470677 \n",
            " epoch : 1089, validation loss did not decrease \n",
            " Training loss : 0.0018170226830989122 , validation_loss : 0.00221136212348938 , Best Valid Loss : 0.0018286426784470677 \n",
            " epoch : 1090, validation loss did not decrease \n",
            " Training loss : 0.0018493568059056997 , validation_loss : 0.0022201533429324627 , Best Valid Loss : 0.0018286426784470677 \n",
            " epoch : 1091, validation loss did not decrease \n",
            " Training loss : 0.0018746390705928206 , validation_loss : 0.0021757506765425205 , Best Valid Loss : 0.0018286426784470677 \n",
            " epoch : 1092, validation loss did not decrease \n",
            " Training loss : 0.0018146820366382599 , validation_loss : 0.002065650187432766 , Best Valid Loss : 0.0018286426784470677 \n",
            " epoch : 1093, validation loss did not decrease \n",
            " Training loss : 0.0017305011861026287 , validation_loss : 0.001963781425729394 , Best Valid Loss : 0.0018286426784470677 \n",
            " epoch : 1094, validation loss did not decrease \n",
            " Training loss : 0.0016151292948052287 , validation_loss : 0.001854392932727933 , Best Valid Loss : 0.0018286426784470677 \n",
            " epoch : 1095, Validation loss decreased : 0.0018286426784470677 --> 0.0018229648703709245 \n",
            " Training loss : 0.0015300993109121919 , validation_loss : 0.0018229648703709245 , Best Valid Loss : 0.0018229648703709245 \n",
            " epoch : 1096, validation loss did not decrease \n",
            " Training loss : 0.0014933348866179585 , validation_loss : 0.0018324570264667273 , Best Valid Loss : 0.0018229648703709245 \n",
            " epoch : 1097, validation loss did not decrease \n",
            " Training loss : 0.0015007035108283162 , validation_loss : 0.0018617899622768164 , Best Valid Loss : 0.0018229648703709245 \n",
            " epoch : 1098, validation loss did not decrease \n",
            " Training loss : 0.0015387570019811392 , validation_loss : 0.0019256684463471174 , Best Valid Loss : 0.0018229648703709245 \n",
            " epoch : 1099, validation loss did not decrease \n",
            " Training loss : 0.0015847113681957126 , validation_loss : 0.001956165535375476 , Best Valid Loss : 0.0018229648703709245 \n",
            " epoch : 1100, validation loss did not decrease \n",
            " Training loss : 0.0016252555651590228 , validation_loss : 0.001974906539544463 , Best Valid Loss : 0.0018229648703709245 \n",
            " epoch : 1101, validation loss did not decrease \n",
            " Training loss : 0.001632388331927359 , validation_loss : 0.0019483569776639342 , Best Valid Loss : 0.0018229648703709245 \n",
            " epoch : 1102, validation loss did not decrease \n",
            " Training loss : 0.0016173733165487647 , validation_loss : 0.0019203205592930317 , Best Valid Loss : 0.0018229648703709245 \n",
            " epoch : 1103, validation loss did not decrease \n",
            " Training loss : 0.0015771748730912805 , validation_loss : 0.001862036413513124 , Best Valid Loss : 0.0018229648703709245 \n",
            " epoch : 1104, validation loss did not decrease \n",
            " Training loss : 0.0015375080984085798 , validation_loss : 0.0018422957509756088 , Best Valid Loss : 0.0018229648703709245 \n",
            " epoch : 1105, Validation loss decreased : 0.0018229648703709245 --> 0.0018194655422121286 \n",
            " Training loss : 0.0015065353363752365 , validation_loss : 0.0018194655422121286 , Best Valid Loss : 0.0018194655422121286 \n",
            " epoch : 1106, Validation loss decreased : 0.0018194655422121286 --> 0.0018187288660556078 \n",
            " Training loss : 0.0014912011101841927 , validation_loss : 0.0018187288660556078 , Best Valid Loss : 0.0018187288660556078 \n",
            " epoch : 1107, validation loss did not decrease \n",
            " Training loss : 0.0014885421842336655 , validation_loss : 0.0018286725971847773 , Best Valid Loss : 0.0018187288660556078 \n",
            " epoch : 1108, validation loss did not decrease \n",
            " Training loss : 0.0014942664420232177 , validation_loss : 0.0018331328174099326 , Best Valid Loss : 0.0018187288660556078 \n",
            " epoch : 1109, validation loss did not decrease \n",
            " Training loss : 0.0015050473157316446 , validation_loss : 0.0018547320505604148 , Best Valid Loss : 0.0018187288660556078 \n",
            " epoch : 1110, validation loss did not decrease \n",
            " Training loss : 0.0015163409989327192 , validation_loss : 0.0018573116976767778 , Best Valid Loss : 0.0018187288660556078 \n",
            " epoch : 1111, validation loss did not decrease \n",
            " Training loss : 0.001528875669464469 , validation_loss : 0.0018811126938089728 , Best Valid Loss : 0.0018187288660556078 \n",
            " epoch : 1112, validation loss did not decrease \n",
            " Training loss : 0.0015406592283397913 , validation_loss : 0.0018844022415578365 , Best Valid Loss : 0.0018187288660556078 \n",
            " epoch : 1113, validation loss did not decrease \n",
            " Training loss : 0.0015537708532065153 , validation_loss : 0.0019017958547919989 , Best Valid Loss : 0.0018187288660556078 \n",
            " epoch : 1114, validation loss did not decrease \n",
            " Training loss : 0.0015597222372889519 , validation_loss : 0.0018990794196724892 , Best Valid Loss : 0.0018187288660556078 \n",
            " epoch : 1115, validation loss did not decrease \n",
            " Training loss : 0.0015687469858676195 , validation_loss : 0.0019260579720139503 , Best Valid Loss : 0.0018187288660556078 \n",
            " epoch : 1116, validation loss did not decrease \n",
            " Training loss : 0.0015811464982107282 , validation_loss : 0.0019300791900604963 , Best Valid Loss : 0.0018187288660556078 \n",
            " epoch : 1117, validation loss did not decrease \n",
            " Training loss : 0.0015991412801668048 , validation_loss : 0.001965666888281703 , Best Valid Loss : 0.0018187288660556078 \n",
            " epoch : 1118, validation loss did not decrease \n",
            " Training loss : 0.0016172770410776138 , validation_loss : 0.0019678757525980473 , Best Valid Loss : 0.0018187288660556078 \n",
            " epoch : 1119, validation loss did not decrease \n",
            " Training loss : 0.0016358778811991215 , validation_loss : 0.0019942899234592915 , Best Valid Loss : 0.0018187288660556078 \n",
            " epoch : 1120, validation loss did not decrease \n",
            " Training loss : 0.001643539173528552 , validation_loss : 0.0019786832854151726 , Best Valid Loss : 0.0018187288660556078 \n",
            " epoch : 1121, validation loss did not decrease \n",
            " Training loss : 0.0016473997384309769 , validation_loss : 0.0019856346771121025 , Best Valid Loss : 0.0018187288660556078 \n",
            " epoch : 1122, validation loss did not decrease \n",
            " Training loss : 0.001635614549741149 , validation_loss : 0.0019506128737702966 , Best Valid Loss : 0.0018187288660556078 \n",
            " epoch : 1123, validation loss did not decrease \n",
            " Training loss : 0.0016206222353503108 , validation_loss : 0.0019463186617940664 , Best Valid Loss : 0.0018187288660556078 \n",
            " epoch : 1124, validation loss did not decrease \n",
            " Training loss : 0.0016002003103494644 , validation_loss : 0.0019074251176789403 , Best Valid Loss : 0.0018187288660556078 \n",
            " epoch : 1125, validation loss did not decrease \n",
            " Training loss : 0.0015783136477693915 , validation_loss : 0.0018891188083216548 , Best Valid Loss : 0.0018187288660556078 \n",
            " epoch : 1126, validation loss did not decrease \n",
            " Training loss : 0.0015483438037335873 , validation_loss : 0.0018516227137297392 , Best Valid Loss : 0.0018187288660556078 \n",
            " epoch : 1127, validation loss did not decrease \n",
            " Training loss : 0.001525208237580955 , validation_loss : 0.0018411176279187202 , Best Valid Loss : 0.0018187288660556078 \n",
            " epoch : 1128, validation loss did not decrease \n",
            " Training loss : 0.0015058001736178994 , validation_loss : 0.0018218086333945394 , Best Valid Loss : 0.0018187288660556078 \n",
            " epoch : 1129, Validation loss decreased : 0.0018187288660556078 --> 0.0018179951002821326 \n",
            " Training loss : 0.001494495547376573 , validation_loss : 0.0018179951002821326 , Best Valid Loss : 0.0018179951002821326 \n",
            " epoch : 1130, Validation loss decreased : 0.0018179951002821326 --> 0.0018116433639079332 \n",
            " Training loss : 0.0014861432136967778 , validation_loss : 0.0018116433639079332 , Best Valid Loss : 0.0018116433639079332 \n",
            " epoch : 1131, Validation loss decreased : 0.0018116433639079332 --> 0.001811461872421205 \n",
            " Training loss : 0.001482107094489038 , validation_loss : 0.001811461872421205 , Best Valid Loss : 0.001811461872421205 \n",
            " epoch : 1132, validation loss did not decrease \n",
            " Training loss : 0.0014814793830737472 , validation_loss : 0.001815339201129973 , Best Valid Loss : 0.001811461872421205 \n",
            " epoch : 1133, validation loss did not decrease \n",
            " Training loss : 0.0014833988389000297 , validation_loss : 0.0018159531755372882 , Best Valid Loss : 0.001811461872421205 \n",
            " epoch : 1134, validation loss did not decrease \n",
            " Training loss : 0.0014872649917379022 , validation_loss : 0.001825261046178639 , Best Valid Loss : 0.001811461872421205 \n",
            " epoch : 1135, validation loss did not decrease \n",
            " Training loss : 0.0014909686287865043 , validation_loss : 0.0018240432254970074 , Best Valid Loss : 0.001811461872421205 \n",
            " epoch : 1136, validation loss did not decrease \n",
            " Training loss : 0.001495872624218464 , validation_loss : 0.00183429557364434 , Best Valid Loss : 0.001811461872421205 \n",
            " epoch : 1137, validation loss did not decrease \n",
            " Training loss : 0.0014982313150539994 , validation_loss : 0.0018305351259186864 , Best Valid Loss : 0.001811461872421205 \n",
            " epoch : 1138, validation loss did not decrease \n",
            " Training loss : 0.0015022698789834976 , validation_loss : 0.0018402886344119906 , Best Valid Loss : 0.001811461872421205 \n",
            " epoch : 1139, validation loss did not decrease \n",
            " Training loss : 0.001503125298768282 , validation_loss : 0.0018345947610214353 , Best Valid Loss : 0.001811461872421205 \n",
            " epoch : 1140, validation loss did not decrease \n",
            " Training loss : 0.0015061056474223733 , validation_loss : 0.001843474106863141 , Best Valid Loss : 0.001811461872421205 \n",
            " epoch : 1141, validation loss did not decrease \n",
            " Training loss : 0.0015057891141623259 , validation_loss : 0.0018360457615926862 , Best Valid Loss : 0.001811461872421205 \n",
            " epoch : 1142, validation loss did not decrease \n",
            " Training loss : 0.0015073445392772555 , validation_loss : 0.001843276317231357 , Best Valid Loss : 0.001811461872421205 \n",
            " epoch : 1143, validation loss did not decrease \n",
            " Training loss : 0.00150562624912709 , validation_loss : 0.0018353831255808473 , Best Valid Loss : 0.001811461872421205 \n",
            " epoch : 1144, validation loss did not decrease \n",
            " Training loss : 0.0015064639737829566 , validation_loss : 0.0018428630428388715 , Best Valid Loss : 0.001811461872421205 \n",
            " epoch : 1145, validation loss did not decrease \n",
            " Training loss : 0.0015053224051371217 , validation_loss : 0.0018361038528382778 , Best Valid Loss : 0.001811461872421205 \n",
            " epoch : 1146, validation loss did not decrease \n",
            " Training loss : 0.0015070931985974312 , validation_loss : 0.0018452040385454893 , Best Valid Loss : 0.001811461872421205 \n",
            " epoch : 1147, validation loss did not decrease \n",
            " Training loss : 0.001507402746938169 , validation_loss : 0.0018388907192274928 , Best Valid Loss : 0.001811461872421205 \n",
            " epoch : 1148, validation loss did not decrease \n",
            " Training loss : 0.0015099847223609686 , validation_loss : 0.001851243432611227 , Best Valid Loss : 0.001811461872421205 \n",
            " epoch : 1149, validation loss did not decrease \n",
            " Training loss : 0.0015127197839319706 , validation_loss : 0.0018469628412276506 , Best Valid Loss : 0.001811461872421205 \n",
            " epoch : 1150, validation loss did not decrease \n",
            " Training loss : 0.001518154051154852 , validation_loss : 0.001867098966613412 , Best Valid Loss : 0.001811461872421205 \n",
            " epoch : 1151, validation loss did not decrease \n",
            " Training loss : 0.001527120009995997 , validation_loss : 0.0018705878173932433 , Best Valid Loss : 0.001811461872421205 \n",
            " epoch : 1152, validation loss did not decrease \n",
            " Training loss : 0.0015411198837682605 , validation_loss : 0.0019010166870430112 , Best Valid Loss : 0.001811461872421205 \n",
            " epoch : 1153, validation loss did not decrease \n",
            " Training loss : 0.001558347255922854 , validation_loss : 0.001915307017043233 , Best Valid Loss : 0.001811461872421205 \n",
            " epoch : 1154, validation loss did not decrease \n",
            " Training loss : 0.0015852799406275153 , validation_loss : 0.0019688077736645937 , Best Valid Loss : 0.001811461872421205 \n",
            " epoch : 1155, validation loss did not decrease \n",
            " Training loss : 0.00162122689653188 , validation_loss : 0.002005574759095907 , Best Valid Loss : 0.001811461872421205 \n",
            " epoch : 1156, validation loss did not decrease \n",
            " Training loss : 0.0016719915438443422 , validation_loss : 0.002069869078695774 , Best Valid Loss : 0.001811461872421205 \n",
            " epoch : 1157, validation loss did not decrease \n",
            " Training loss : 0.0017161648720502853 , validation_loss : 0.0021118922159075737 , Best Valid Loss : 0.001811461872421205 \n",
            " epoch : 1158, validation loss did not decrease \n",
            " Training loss : 0.0017723487690091133 , validation_loss : 0.0021436228416860104 , Best Valid Loss : 0.001811461872421205 \n",
            " epoch : 1159, validation loss did not decrease \n",
            " Training loss : 0.0017859031213447452 , validation_loss : 0.0021317284554243088 , Best Valid Loss : 0.001811461872421205 \n",
            " epoch : 1160, validation loss did not decrease \n",
            " Training loss : 0.0017908478621393442 , validation_loss : 0.0020885884296149015 , Best Valid Loss : 0.001811461872421205 \n",
            " epoch : 1161, validation loss did not decrease \n",
            " Training loss : 0.0017327971290796995 , validation_loss : 0.0019942002836614847 , Best Valid Loss : 0.001811461872421205 \n",
            " epoch : 1162, validation loss did not decrease \n",
            " Training loss : 0.0016631163889542222 , validation_loss : 0.0019175219349563122 , Best Valid Loss : 0.001811461872421205 \n",
            " epoch : 1163, validation loss did not decrease \n",
            " Training loss : 0.0015727104619145393 , validation_loss : 0.0018312789034098387 , Best Valid Loss : 0.001811461872421205 \n",
            " epoch : 1164, Validation loss decreased : 0.001811461872421205 --> 0.001807736000046134 \n",
            " Training loss : 0.001507650944404304 , validation_loss : 0.001807736000046134 , Best Valid Loss : 0.001807736000046134 \n",
            " epoch : 1165, validation loss did not decrease \n",
            " Training loss : 0.0014783554943278432 , validation_loss : 0.0018118518637493253 , Best Valid Loss : 0.001807736000046134 \n",
            " epoch : 1166, validation loss did not decrease \n",
            " Training loss : 0.0014814356109127402 , validation_loss : 0.0018325968412682414 , Best Valid Loss : 0.001807736000046134 \n",
            " epoch : 1167, validation loss did not decrease \n",
            " Training loss : 0.0015077393036335707 , validation_loss : 0.0018792935879901052 , Best Valid Loss : 0.001807736000046134 \n",
            " epoch : 1168, validation loss did not decrease \n",
            " Training loss : 0.0015417842660099268 , validation_loss : 0.0019048521062359214 , Best Valid Loss : 0.001807736000046134 \n",
            " epoch : 1169, validation loss did not decrease \n",
            " Training loss : 0.0015760352835059166 , validation_loss : 0.0019295311067253351 , Best Valid Loss : 0.001807736000046134 \n",
            " epoch : 1170, validation loss did not decrease \n",
            " Training loss : 0.0015873321099206805 , validation_loss : 0.0019146892009302974 , Best Valid Loss : 0.001807736000046134 \n",
            " epoch : 1171, validation loss did not decrease \n",
            " Training loss : 0.001586209051311016 , validation_loss : 0.0019110372522845864 , Best Valid Loss : 0.001807736000046134 \n",
            " epoch : 1172, validation loss did not decrease \n",
            " Training loss : 0.001567718107253313 , validation_loss : 0.0018693944439291954 , Best Valid Loss : 0.001807736000046134 \n",
            " epoch : 1173, validation loss did not decrease \n",
            " Training loss : 0.0015423668082803488 , validation_loss : 0.0018519224831834435 , Best Valid Loss : 0.001807736000046134 \n",
            " epoch : 1174, validation loss did not decrease \n",
            " Training loss : 0.0015132167609408498 , validation_loss : 0.0018168301321566105 , Best Valid Loss : 0.001807736000046134 \n",
            " epoch : 1175, validation loss did not decrease \n",
            " Training loss : 0.0014900995884090662 , validation_loss : 0.001807973487302661 , Best Valid Loss : 0.001807736000046134 \n",
            " epoch : 1176, Validation loss decreased : 0.001807736000046134 --> 0.0018019722774624825 \n",
            " Training loss : 0.0014760025078430772 , validation_loss : 0.0018019722774624825 , Best Valid Loss : 0.0018019722774624825 \n",
            " epoch : 1177, validation loss did not decrease \n",
            " Training loss : 0.001472171861678362 , validation_loss : 0.0018037542467936873 , Best Valid Loss : 0.0018019722774624825 \n",
            " epoch : 1178, validation loss did not decrease \n",
            " Training loss : 0.0014761253260076046 , validation_loss : 0.0018182155909016728 , Best Valid Loss : 0.0018019722774624825 \n",
            " epoch : 1179, validation loss did not decrease \n",
            " Training loss : 0.0014838404022157192 , validation_loss : 0.0018216206226497889 , Best Valid Loss : 0.0018019722774624825 \n",
            " epoch : 1180, validation loss did not decrease \n",
            " Training loss : 0.0014931205660104752 , validation_loss : 0.0018358266679570079 , Best Valid Loss : 0.0018019722774624825 \n",
            " epoch : 1181, validation loss did not decrease \n",
            " Training loss : 0.001499383943155408 , validation_loss : 0.0018368915189057589 , Best Valid Loss : 0.0018019722774624825 \n",
            " epoch : 1182, validation loss did not decrease \n",
            " Training loss : 0.0015078223077580333 , validation_loss : 0.0018490450456738472 , Best Valid Loss : 0.0018019722774624825 \n",
            " epoch : 1183, validation loss did not decrease \n",
            " Training loss : 0.0015109574887901545 , validation_loss : 0.0018451664363965392 , Best Valid Loss : 0.0018019722774624825 \n",
            " epoch : 1184, validation loss did not decrease \n",
            " Training loss : 0.0015174095751717687 , validation_loss : 0.001865670084953308 , Best Valid Loss : 0.0018019722774624825 \n",
            " epoch : 1185, validation loss did not decrease \n",
            " Training loss : 0.001525805564597249 , validation_loss : 0.001869180123321712 , Best Valid Loss : 0.0018019722774624825 \n",
            " epoch : 1186, validation loss did not decrease \n",
            " Training loss : 0.0015392224304378033 , validation_loss : 0.0018968215445056558 , Best Valid Loss : 0.0018019722774624825 \n",
            " epoch : 1187, validation loss did not decrease \n",
            " Training loss : 0.001554669812321663 , validation_loss : 0.0019062241772189736 , Best Valid Loss : 0.0018019722774624825 \n",
            " epoch : 1188, validation loss did not decrease \n",
            " Training loss : 0.0015756621723994613 , validation_loss : 0.0019462882773950696 , Best Valid Loss : 0.0018019722774624825 \n",
            " epoch : 1189, validation loss did not decrease \n",
            " Training loss : 0.0015996757429093122 , validation_loss : 0.001959514571353793 , Best Valid Loss : 0.0018019722774624825 \n",
            " epoch : 1190, validation loss did not decrease \n",
            " Training loss : 0.0016293241642415524 , validation_loss : 0.0020026632118970156 , Best Valid Loss : 0.0018019722774624825 \n",
            " epoch : 1191, validation loss did not decrease \n",
            " Training loss : 0.0016523016383871436 , validation_loss : 0.0020140218548476696 , Best Valid Loss : 0.0018019722774624825 \n",
            " epoch : 1192, validation loss did not decrease \n",
            " Training loss : 0.0016796902054920793 , validation_loss : 0.002030847128480673 , Best Valid Loss : 0.0018019722774624825 \n",
            " epoch : 1193, validation loss did not decrease \n",
            " Training loss : 0.001680087181739509 , validation_loss : 0.002011545468121767 , Best Valid Loss : 0.0018019722774624825 \n",
            " epoch : 1194, validation loss did not decrease \n",
            " Training loss : 0.001676935120485723 , validation_loss : 0.001994138117879629 , Best Valid Loss : 0.0018019722774624825 \n",
            " epoch : 1195, validation loss did not decrease \n",
            " Training loss : 0.0016453267307952046 , validation_loss : 0.0019386446801945567 , Best Valid Loss : 0.0018019722774624825 \n",
            " epoch : 1196, validation loss did not decrease \n",
            " Training loss : 0.0016095737228170037 , validation_loss : 0.0019059960031881928 , Best Valid Loss : 0.0018019722774624825 \n",
            " epoch : 1197, validation loss did not decrease \n",
            " Training loss : 0.0015634439187124372 , validation_loss : 0.0018478932324796915 , Best Valid Loss : 0.0018019722774624825 \n",
            " epoch : 1198, validation loss did not decrease \n",
            " Training loss : 0.0015222496585920453 , validation_loss : 0.0018212847644463181 , Best Valid Loss : 0.0018019722774624825 \n",
            " epoch : 1199, Validation loss decreased : 0.0018019722774624825 --> 0.0017969292821362615 \n",
            " Training loss : 0.0014876911882311106 , validation_loss : 0.0017969292821362615 , Best Valid Loss : 0.0017969292821362615 \n",
            " epoch : 1200, Validation loss decreased : 0.0017969292821362615 --> 0.0017943624407052994 \n",
            " Training loss : 0.001470717485062778 , validation_loss : 0.0017943624407052994 , Best Valid Loss : 0.0017943624407052994 \n",
            " epoch : 1201, validation loss did not decrease \n",
            " Training loss : 0.0014667018549516797 , validation_loss : 0.0018041064031422138 , Best Valid Loss : 0.0017943624407052994 \n",
            " epoch : 1202, validation loss did not decrease \n",
            " Training loss : 0.0014731413684785366 , validation_loss : 0.0018128028605133295 , Best Valid Loss : 0.0017943624407052994 \n",
            " epoch : 1203, validation loss did not decrease \n",
            " Training loss : 0.0014858576469123363 , validation_loss : 0.0018322229152545333 , Best Valid Loss : 0.0017943624407052994 \n",
            " epoch : 1204, validation loss did not decrease \n",
            " Training loss : 0.0014972545905038714 , validation_loss : 0.0018360369140282273 , Best Valid Loss : 0.0017943624407052994 \n",
            " epoch : 1205, validation loss did not decrease \n",
            " Training loss : 0.0015094619011506438 , validation_loss : 0.0018517787102609873 , Best Valid Loss : 0.0017943624407052994 \n",
            " epoch : 1206, validation loss did not decrease \n",
            " Training loss : 0.001513620954938233 , validation_loss : 0.001844220096245408 , Best Valid Loss : 0.0017943624407052994 \n",
            " epoch : 1207, validation loss did not decrease \n",
            " Training loss : 0.0015184764051809907 , validation_loss : 0.001856790273450315 , Best Valid Loss : 0.0017943624407052994 \n",
            " epoch : 1208, validation loss did not decrease \n",
            " Training loss : 0.0015176957240328193 , validation_loss : 0.0018438836559653282 , Best Valid Loss : 0.0017943624407052994 \n",
            " epoch : 1209, validation loss did not decrease \n",
            " Training loss : 0.0015154354041442275 , validation_loss : 0.001846028957515955 , Best Valid Loss : 0.0017943624407052994 \n",
            " epoch : 1210, validation loss did not decrease \n",
            " Training loss : 0.0015080188168212771 , validation_loss : 0.0018278307979926467 , Best Valid Loss : 0.0017943624407052994 \n",
            " epoch : 1211, validation loss did not decrease \n",
            " Training loss : 0.001500166137702763 , validation_loss : 0.0018256526673212647 , Best Valid Loss : 0.0017943624407052994 \n",
            " epoch : 1212, validation loss did not decrease \n",
            " Training loss : 0.001489794347435236 , validation_loss : 0.0018079954897984862 , Best Valid Loss : 0.0017943624407052994 \n",
            " epoch : 1213, validation loss did not decrease \n",
            " Training loss : 0.001481398125179112 , validation_loss : 0.0018055136315524578 , Best Valid Loss : 0.0017943624407052994 \n",
            " epoch : 1214, validation loss did not decrease \n",
            " Training loss : 0.0014726882800459862 , validation_loss : 0.0017949221655726433 , Best Valid Loss : 0.0017943624407052994 \n",
            " epoch : 1215, Validation loss decreased : 0.0017943624407052994 --> 0.0017932017799466848 \n",
            " Training loss : 0.0014666005736216903 , validation_loss : 0.0017932017799466848 , Best Valid Loss : 0.0017932017799466848 \n",
            " epoch : 1216, Validation loss decreased : 0.0017932017799466848 --> 0.0017918481025844812 \n",
            " Training loss : 0.0014626603806391358 , validation_loss : 0.0017918481025844812 , Best Valid Loss : 0.0017918481025844812 \n",
            " epoch : 1217, validation loss did not decrease \n",
            " Training loss : 0.001461734063923359 , validation_loss : 0.0017919734818860888 , Best Valid Loss : 0.0017918481025844812 \n",
            " epoch : 1218, validation loss did not decrease \n",
            " Training loss : 0.0014631522353738546 , validation_loss : 0.0017971377819776535 , Best Valid Loss : 0.0017918481025844812 \n",
            " epoch : 1219, validation loss did not decrease \n",
            " Training loss : 0.0014656569110229611 , validation_loss : 0.001796532655134797 , Best Valid Loss : 0.0017918481025844812 \n",
            " epoch : 1220, validation loss did not decrease \n",
            " Training loss : 0.0014689149102196097 , validation_loss : 0.0018037626286968589 , Best Valid Loss : 0.0017918481025844812 \n",
            " epoch : 1221, validation loss did not decrease \n",
            " Training loss : 0.0014711017720401287 , validation_loss : 0.0018012643558904529 , Best Valid Loss : 0.0017918481025844812 \n",
            " epoch : 1222, validation loss did not decrease \n",
            " Training loss : 0.001473748590797186 , validation_loss : 0.0018084432231262326 , Best Valid Loss : 0.0017918481025844812 \n",
            " epoch : 1223, validation loss did not decrease \n",
            " Training loss : 0.0014749015681445599 , validation_loss : 0.0018056974513456225 , Best Valid Loss : 0.0017918481025844812 \n",
            " epoch : 1224, validation loss did not decrease \n",
            " Training loss : 0.001478111371397972 , validation_loss : 0.0018139317398890853 , Best Valid Loss : 0.0017918481025844812 \n",
            " epoch : 1225, validation loss did not decrease \n",
            " Training loss : 0.0014795316383242607 , validation_loss : 0.0018117284635081887 , Best Valid Loss : 0.0017918481025844812 \n",
            " epoch : 1226, validation loss did not decrease \n",
            " Training loss : 0.001484585925936699 , validation_loss : 0.001825004699639976 , Best Valid Loss : 0.0017918481025844812 \n",
            " epoch : 1227, validation loss did not decrease \n",
            " Training loss : 0.0014891722239553928 , validation_loss : 0.0018268520943820477 , Best Valid Loss : 0.0017918481025844812 \n",
            " epoch : 1228, validation loss did not decrease \n",
            " Training loss : 0.0014992584474384785 , validation_loss : 0.0018490352667868137 , Best Valid Loss : 0.0017918481025844812 \n",
            " epoch : 1229, validation loss did not decrease \n",
            " Training loss : 0.0015107812359929085 , validation_loss : 0.0018587111262604594 , Best Valid Loss : 0.0017918481025844812 \n",
            " epoch : 1230, validation loss did not decrease \n",
            " Training loss : 0.0015300066443160176 , validation_loss : 0.001903277705423534 , Best Valid Loss : 0.0017918481025844812 \n",
            " epoch : 1231, validation loss did not decrease \n",
            " Training loss : 0.0015608207322657108 , validation_loss : 0.0019391430541872978 , Best Valid Loss : 0.0017918481025844812 \n",
            " epoch : 1232, validation loss did not decrease \n",
            " Training loss : 0.0016070877900347114 , validation_loss : 0.0020095135550945997 , Best Valid Loss : 0.0017918481025844812 \n",
            " epoch : 1233, validation loss did not decrease \n",
            " Training loss : 0.0016595564084127545 , validation_loss : 0.002070758258923888 , Best Valid Loss : 0.0017918481025844812 \n",
            " epoch : 1234, validation loss did not decrease \n",
            " Training loss : 0.0017339071491733193 , validation_loss : 0.0021424940787255764 , Best Valid Loss : 0.0017918481025844812 \n",
            " epoch : 1235, validation loss did not decrease \n",
            " Training loss : 0.0017846447881311178 , validation_loss : 0.002190485130995512 , Best Valid Loss : 0.0017918481025844812 \n",
            " epoch : 1236, validation loss did not decrease \n",
            " Training loss : 0.0018448999617248774 , validation_loss : 0.002166200429201126 , Best Valid Loss : 0.0017918481025844812 \n",
            " epoch : 1237, validation loss did not decrease \n",
            " Training loss : 0.0018080025911331177 , validation_loss : 0.0020907113794237375 , Best Valid Loss : 0.0017918481025844812 \n",
            " epoch : 1238, validation loss did not decrease \n",
            " Training loss : 0.0017511129844933748 , validation_loss : 0.001986294286325574 , Best Valid Loss : 0.0017918481025844812 \n",
            " epoch : 1239, validation loss did not decrease \n",
            " Training loss : 0.0016363807953894138 , validation_loss : 0.0018601391930133104 , Best Valid Loss : 0.0017918481025844812 \n",
            " epoch : 1240, validation loss did not decrease \n",
            " Training loss : 0.0015369087923318148 , validation_loss : 0.0018046064069494605 , Best Valid Loss : 0.0017918481025844812 \n",
            " epoch : 1241, Validation loss decreased : 0.0017918481025844812 --> 0.0017874350305646658 \n",
            " Training loss : 0.001473069074563682 , validation_loss : 0.0017874350305646658 , Best Valid Loss : 0.0017874350305646658 \n",
            " epoch : 1242, validation loss did not decrease \n",
            " Training loss : 0.0014602495357394218 , validation_loss : 0.0018148919334635139 , Best Valid Loss : 0.0017874350305646658 \n",
            " epoch : 1243, validation loss did not decrease \n",
            " Training loss : 0.0014931728364899755 , validation_loss : 0.0018917662091553211 , Best Valid Loss : 0.0017874350305646658 \n",
            " epoch : 1244, validation loss did not decrease \n",
            " Training loss : 0.001552690053358674 , validation_loss : 0.0019476383458822966 , Best Valid Loss : 0.0017874350305646658 \n",
            " epoch : 1245, validation loss did not decrease \n",
            " Training loss : 0.001616025110706687 , validation_loss : 0.0019715388771146536 , Best Valid Loss : 0.0017874350305646658 \n",
            " epoch : 1246, validation loss did not decrease \n",
            " Training loss : 0.0016301210271194577 , validation_loss : 0.0019479935290291905 , Best Valid Loss : 0.0017874350305646658 \n",
            " epoch : 1247, validation loss did not decrease \n",
            " Training loss : 0.0016162348911166191 , validation_loss : 0.001898462069220841 , Best Valid Loss : 0.0017874350305646658 \n",
            " epoch : 1248, validation loss did not decrease \n",
            " Training loss : 0.0015577132580801845 , validation_loss : 0.0018271728185936809 , Best Valid Loss : 0.0017874350305646658 \n",
            " epoch : 1249, validation loss did not decrease \n",
            " Training loss : 0.001504564075730741 , validation_loss : 0.001799563760869205 , Best Valid Loss : 0.0017874350305646658 \n",
            " epoch : 1250, Validation loss decreased : 0.0017874350305646658 --> 0.0017822722438722849 \n",
            " Training loss : 0.0014683379558846354 , validation_loss : 0.0017822722438722849 , Best Valid Loss : 0.0017822722438722849 \n",
            " epoch : 1251, validation loss did not decrease \n",
            " Training loss : 0.001455491641536355 , validation_loss : 0.0017895183991640806 , Best Valid Loss : 0.0017822722438722849 \n",
            " epoch : 1252, validation loss did not decrease \n",
            " Training loss : 0.0014653692487627268 , validation_loss : 0.0018268827116116881 , Best Valid Loss : 0.0017822722438722849 \n",
            " epoch : 1253, validation loss did not decrease \n",
            " Training loss : 0.0014909154269844294 , validation_loss : 0.0018454896053299308 , Best Valid Loss : 0.0017822722438722849 \n",
            " epoch : 1254, validation loss did not decrease \n",
            " Training loss : 0.0015197660541161895 , validation_loss : 0.001879237242974341 , Best Valid Loss : 0.0017822722438722849 \n",
            " epoch : 1255, validation loss did not decrease \n",
            " Training loss : 0.0015388901811093092 , validation_loss : 0.0018763274420052767 , Best Valid Loss : 0.0017822722438722849 \n",
            " epoch : 1256, validation loss did not decrease \n",
            " Training loss : 0.001548205385915935 , validation_loss : 0.001883788383565843 , Best Valid Loss : 0.0017822722438722849 \n",
            " epoch : 1257, validation loss did not decrease \n",
            " Training loss : 0.001543972990475595 , validation_loss : 0.0018622722709551454 , Best Valid Loss : 0.0017822722438722849 \n",
            " epoch : 1258, validation loss did not decrease \n",
            " Training loss : 0.0015345930587500334 , validation_loss : 0.0018608899554237723 , Best Valid Loss : 0.0017822722438722849 \n",
            " epoch : 1259, validation loss did not decrease \n",
            " Training loss : 0.0015231809811666608 , validation_loss : 0.0018395031802356243 , Best Valid Loss : 0.0017822722438722849 \n",
            " epoch : 1260, validation loss did not decrease \n",
            " Training loss : 0.0015121836913749576 , validation_loss : 0.0018320881063118577 , Best Valid Loss : 0.0017822722438722849 \n",
            " epoch : 1261, validation loss did not decrease \n",
            " Training loss : 0.0014961662236601114 , validation_loss : 0.0018094968982040882 , Best Valid Loss : 0.0017822722438722849 \n",
            " epoch : 1262, validation loss did not decrease \n",
            " Training loss : 0.0014842874370515347 , validation_loss : 0.0018036909168586135 , Best Valid Loss : 0.0017822722438722849 \n",
            " epoch : 1263, validation loss did not decrease \n",
            " Training loss : 0.0014705689391121268 , validation_loss : 0.0017856681952252984 , Best Valid Loss : 0.0017822722438722849 \n",
            " epoch : 1264, Validation loss decreased : 0.0017822722438722849 --> 0.0017816723557189107 \n",
            " Training loss : 0.0014597431290894747 , validation_loss : 0.0017816723557189107 , Best Valid Loss : 0.0017816723557189107 \n",
            " epoch : 1265, Validation loss decreased : 0.0017816723557189107 --> 0.001777390018105507 \n",
            " Training loss : 0.0014519004616886377 , validation_loss : 0.001777390018105507 , Best Valid Loss : 0.001777390018105507 \n",
            " epoch : 1266, validation loss did not decrease \n",
            " Training loss : 0.0014491626061499119 , validation_loss : 0.0017775129526853561 , Best Valid Loss : 0.001777390018105507 \n",
            " epoch : 1267, validation loss did not decrease \n",
            " Training loss : 0.0014501846162602305 , validation_loss : 0.0017837841296568513 , Best Valid Loss : 0.001777390018105507 \n",
            " epoch : 1268, validation loss did not decrease \n",
            " Training loss : 0.0014533995417878032 , validation_loss : 0.001783715677447617 , Best Valid Loss : 0.001777390018105507 \n",
            " epoch : 1269, validation loss did not decrease \n",
            " Training loss : 0.0014568852493539453 , validation_loss : 0.001791264396160841 , Best Valid Loss : 0.001777390018105507 \n",
            " epoch : 1270, validation loss did not decrease \n",
            " Training loss : 0.001459482591599226 , validation_loss : 0.0017886279383674264 , Best Valid Loss : 0.001777390018105507 \n",
            " epoch : 1271, validation loss did not decrease \n",
            " Training loss : 0.0014612857485190034 , validation_loss : 0.0017938156379386783 , Best Valid Loss : 0.001777390018105507 \n",
            " epoch : 1272, validation loss did not decrease \n",
            " Training loss : 0.0014616678236052394 , validation_loss : 0.001787923858501017 , Best Valid Loss : 0.001777390018105507 \n",
            " epoch : 1273, validation loss did not decrease \n",
            " Training loss : 0.0014609857462346554 , validation_loss : 0.0017908777808770537 , Best Valid Loss : 0.001777390018105507 \n",
            " epoch : 1274, validation loss did not decrease \n",
            " Training loss : 0.00145905336830765 , validation_loss : 0.0017832996090874076 , Best Valid Loss : 0.001777390018105507 \n",
            " epoch : 1275, validation loss did not decrease \n",
            " Training loss : 0.0014566576573997736 , validation_loss : 0.0017846606206148863 , Best Valid Loss : 0.001777390018105507 \n",
            " epoch : 1276, validation loss did not decrease \n",
            " Training loss : 0.0014537024544551969 , validation_loss : 0.001778340432792902 , Best Valid Loss : 0.001777390018105507 \n",
            " epoch : 1277, validation loss did not decrease \n",
            " Training loss : 0.001451607677154243 , validation_loss : 0.0017791858408600092 , Best Valid Loss : 0.001777390018105507 \n",
            " epoch : 1278, Validation loss decreased : 0.001777390018105507 --> 0.0017745740478858352 \n",
            " Training loss : 0.0014492355985566974 , validation_loss : 0.0017745740478858352 , Best Valid Loss : 0.0017745740478858352 \n",
            " epoch : 1279, validation loss did not decrease \n",
            " Training loss : 0.0014474980998784304 , validation_loss : 0.0017750003607943654 , Best Valid Loss : 0.0017745740478858352 \n",
            " epoch : 1280, Validation loss decreased : 0.0017745740478858352 --> 0.0017729864921420813 \n",
            " Training loss : 0.0014459637459367514 , validation_loss : 0.0017729864921420813 , Best Valid Loss : 0.0017729864921420813 \n",
            " epoch : 1281, Validation loss decreased : 0.0017729864921420813 --> 0.0017728161765262485 \n",
            " Training loss : 0.0014449512818828225 , validation_loss : 0.0017728161765262485 , Best Valid Loss : 0.0017728161765262485 \n",
            " epoch : 1282, validation loss did not decrease \n",
            " Training loss : 0.0014444799162447453 , validation_loss : 0.0017731896368786693 , Best Valid Loss : 0.0017728161765262485 \n",
            " epoch : 1283, Validation loss decreased : 0.0017728161765262485 --> 0.0017723023192957044 \n",
            " Training loss : 0.001444434397853911 , validation_loss : 0.0017723023192957044 , Best Valid Loss : 0.0017723023192957044 \n",
            " epoch : 1284, validation loss did not decrease \n",
            " Training loss : 0.0014446481363847852 , validation_loss : 0.0017739534378051758 , Best Valid Loss : 0.0017723023192957044 \n",
            " epoch : 1285, validation loss did not decrease \n",
            " Training loss : 0.0014447756111621857 , validation_loss : 0.0017723096534609795 , Best Valid Loss : 0.0017723023192957044 \n",
            " epoch : 1286, validation loss did not decrease \n",
            " Training loss : 0.0014448584988713264 , validation_loss : 0.0017742653144523501 , Best Valid Loss : 0.0017723023192957044 \n",
            " epoch : 1287, Validation loss decreased : 0.0017723023192957044 --> 0.0017721678595989943 \n",
            " Training loss : 0.0014447190333157778 , validation_loss : 0.0017721678595989943 , Best Valid Loss : 0.0017721678595989943 \n",
            " epoch : 1288, validation loss did not decrease \n",
            " Training loss : 0.0014445363776758313 , validation_loss : 0.0017737066373229027 , Best Valid Loss : 0.0017721678595989943 \n",
            " epoch : 1289, Validation loss decreased : 0.0017721678595989943 --> 0.0017712204717099667 \n",
            " Training loss : 0.0014441024977713823 , validation_loss : 0.0017712204717099667 , Best Valid Loss : 0.0017712204717099667 \n",
            " epoch : 1290, validation loss did not decrease \n",
            " Training loss : 0.0014438159996643662 , validation_loss : 0.0017735520377755165 , Best Valid Loss : 0.0017712204717099667 \n",
            " epoch : 1291, validation loss did not decrease \n",
            " Training loss : 0.001443785266019404 , validation_loss : 0.0017716186121106148 , Best Valid Loss : 0.0017712204717099667 \n",
            " epoch : 1292, validation loss did not decrease \n",
            " Training loss : 0.0014441008679568768 , validation_loss : 0.00177489360794425 , Best Valid Loss : 0.0017712204717099667 \n",
            " epoch : 1293, validation loss did not decrease \n",
            " Training loss : 0.0014448403380811214 , validation_loss : 0.0017729068640619516 , Best Valid Loss : 0.0017712204717099667 \n",
            " epoch : 1294, validation loss did not decrease \n",
            " Training loss : 0.0014460766687989235 , validation_loss : 0.0017781724454835057 , Best Valid Loss : 0.0017712204717099667 \n",
            " epoch : 1295, validation loss did not decrease \n",
            " Training loss : 0.0014478156808763742 , validation_loss : 0.0017771164420992136 , Best Valid Loss : 0.0017712204717099667 \n",
            " epoch : 1296, validation loss did not decrease \n",
            " Training loss : 0.0014511524932458997 , validation_loss : 0.001788330264389515 , Best Valid Loss : 0.0017712204717099667 \n",
            " epoch : 1297, validation loss did not decrease \n",
            " Training loss : 0.0014567864127457142 , validation_loss : 0.0017920086393132806 , Best Valid Loss : 0.0017712204717099667 \n",
            " epoch : 1298, validation loss did not decrease \n",
            " Training loss : 0.0014660388696938753 , validation_loss : 0.0018131326651200652 , Best Valid Loss : 0.0017712204717099667 \n",
            " epoch : 1299, validation loss did not decrease \n",
            " Training loss : 0.0014790750574320555 , validation_loss : 0.0018309003207832575 , Best Valid Loss : 0.0017712204717099667 \n",
            " epoch : 1300, validation loss did not decrease \n",
            " Training loss : 0.0015056721167638898 , validation_loss : 0.001884457771666348 , Best Valid Loss : 0.0017712204717099667 \n",
            " epoch : 1301, validation loss did not decrease \n",
            " Training loss : 0.0015437053516507149 , validation_loss : 0.0019310227362439036 , Best Valid Loss : 0.0017712204717099667 \n",
            " epoch : 1302, validation loss did not decrease \n",
            " Training loss : 0.0016010151011869311 , validation_loss : 0.0020281397737562656 , Best Valid Loss : 0.0017712204717099667 \n",
            " epoch : 1303, validation loss did not decrease \n",
            " Training loss : 0.0016791409580036998 , validation_loss : 0.002129106316715479 , Best Valid Loss : 0.0017712204717099667 \n",
            " epoch : 1304, validation loss did not decrease \n",
            " Training loss : 0.0017839797073975205 , validation_loss : 0.0022021648474037647 , Best Valid Loss : 0.0017712204717099667 \n",
            " epoch : 1305, validation loss did not decrease \n",
            " Training loss : 0.001844033831730485 , validation_loss : 0.0022604833357036114 , Best Valid Loss : 0.0017712204717099667 \n",
            " epoch : 1306, validation loss did not decrease \n",
            " Training loss : 0.0019085620297119021 , validation_loss : 0.00220503774471581 , Best Valid Loss : 0.0017712204717099667 \n",
            " epoch : 1307, validation loss did not decrease \n",
            " Training loss : 0.0018446515314280987 , validation_loss : 0.0021022038999944925 , Best Valid Loss : 0.0017712204717099667 \n",
            " epoch : 1308, validation loss did not decrease \n",
            " Training loss : 0.0017616043332964182 , validation_loss : 0.001966221025213599 , Best Valid Loss : 0.0017712204717099667 \n",
            " epoch : 1309, validation loss did not decrease \n",
            " Training loss : 0.0016189232701435685 , validation_loss : 0.0018275839975103736 , Best Valid Loss : 0.0017712204717099667 \n",
            " epoch : 1310, validation loss did not decrease \n",
            " Training loss : 0.0015057885320857167 , validation_loss : 0.0017723324708640575 , Best Valid Loss : 0.0017712204717099667 \n",
            " epoch : 1311, validation loss did not decrease \n",
            " Training loss : 0.0014456890057772398 , validation_loss : 0.001777052995748818 , Best Valid Loss : 0.0017712204717099667 \n",
            " epoch : 1312, validation loss did not decrease \n",
            " Training loss : 0.0014496793737635016 , validation_loss : 0.0018228504341095686 , Best Valid Loss : 0.0017712204717099667 \n",
            " epoch : 1313, validation loss did not decrease \n",
            " Training loss : 0.0015033305389806628 , validation_loss : 0.0019135958282276988 , Best Valid Loss : 0.0017712204717099667 \n",
            " epoch : 1314, validation loss did not decrease \n",
            " Training loss : 0.001574064022861421 , validation_loss : 0.0019714601803570986 , Best Valid Loss : 0.0017712204717099667 \n",
            " epoch : 1315, validation loss did not decrease \n",
            " Training loss : 0.0016370255034416914 , validation_loss : 0.0019590267911553383 , Best Valid Loss : 0.0017712204717099667 \n",
            " epoch : 1316, validation loss did not decrease \n",
            " Training loss : 0.0016183905536308885 , validation_loss : 0.0018984036287292838 , Best Valid Loss : 0.0017712204717099667 \n",
            " epoch : 1317, validation loss did not decrease \n",
            " Training loss : 0.0015710480511188507 , validation_loss : 0.0018373287748545408 , Best Valid Loss : 0.0017712204717099667 \n",
            " epoch : 1318, validation loss did not decrease \n",
            " Training loss : 0.0015012461226433516 , validation_loss : 0.0017741866176947951 , Best Valid Loss : 0.0017712204717099667 \n",
            " epoch : 1319, Validation loss decreased : 0.0017712204717099667 --> 0.0017615195829421282 \n",
            " Training loss : 0.0014555316884070635 , validation_loss : 0.0017615195829421282 , Best Valid Loss : 0.0017615195829421282 \n",
            " epoch : 1320, validation loss did not decrease \n",
            " Training loss : 0.0014379691565409303 , validation_loss : 0.0017744263168424368 , Best Valid Loss : 0.0017615195829421282 \n",
            " epoch : 1321, validation loss did not decrease \n",
            " Training loss : 0.0014460691018030047 , validation_loss : 0.0017912110779434443 , Best Valid Loss : 0.0017615195829421282 \n",
            " epoch : 1322, validation loss did not decrease \n",
            " Training loss : 0.0014680934837087989 , validation_loss : 0.001822263584472239 , Best Valid Loss : 0.0017615195829421282 \n",
            " epoch : 1323, validation loss did not decrease \n",
            " Training loss : 0.0014869013102725148 , validation_loss : 0.001824488048441708 , Best Valid Loss : 0.0017615195829421282 \n",
            " epoch : 1324, validation loss did not decrease \n",
            " Training loss : 0.0015020278515294194 , validation_loss : 0.0018397204112261534 , Best Valid Loss : 0.0017615195829421282 \n",
            " epoch : 1325, validation loss did not decrease \n",
            " Training loss : 0.0015025552129372954 , validation_loss : 0.0018240059725940228 , Best Valid Loss : 0.0017615195829421282 \n",
            " epoch : 1326, validation loss did not decrease \n",
            " Training loss : 0.001501181279309094 , validation_loss : 0.0018257417250424623 , Best Valid Loss : 0.0017615195829421282 \n",
            " epoch : 1327, validation loss did not decrease \n",
            " Training loss : 0.0014909317251294851 , validation_loss : 0.001805637963116169 , Best Valid Loss : 0.0017615195829421282 \n",
            " epoch : 1328, validation loss did not decrease \n",
            " Training loss : 0.0014799936907365918 , validation_loss : 0.0017965929582715034 , Best Valid Loss : 0.0017615195829421282 \n",
            " epoch : 1329, validation loss did not decrease \n",
            " Training loss : 0.0014643464237451553 , validation_loss : 0.0017755799926817417 , Best Valid Loss : 0.0017615195829421282 \n",
            " epoch : 1330, validation loss did not decrease \n",
            " Training loss : 0.001452327473089099 , validation_loss : 0.0017699880991131067 , Best Valid Loss : 0.0017615195829421282 \n",
            " epoch : 1331, Validation loss decreased : 0.0017615195829421282 --> 0.001757699646987021 \n",
            " Training loss : 0.0014408037532120943 , validation_loss : 0.001757699646987021 , Best Valid Loss : 0.001757699646987021 \n",
            " epoch : 1332, Validation loss decreased : 0.001757699646987021 --> 0.001756800920702517 \n",
            " Training loss : 0.0014332975260913372 , validation_loss : 0.001756800920702517 , Best Valid Loss : 0.001756800920702517 \n",
            " epoch : 1333, validation loss did not decrease \n",
            " Training loss : 0.0014300256734713912 , validation_loss : 0.0017587996553629637 , Best Valid Loss : 0.001756800920702517 \n",
            " epoch : 1334, validation loss did not decrease \n",
            " Training loss : 0.0014309004181995988 , validation_loss : 0.0017598519334569573 , Best Valid Loss : 0.001756800920702517 \n",
            " epoch : 1335, validation loss did not decrease \n",
            " Training loss : 0.0014343000948429108 , validation_loss : 0.0017670553643256426 , Best Valid Loss : 0.001756800920702517 \n",
            " epoch : 1336, validation loss did not decrease \n",
            " Training loss : 0.00143818324431777 , validation_loss : 0.0017667398788034916 , Best Valid Loss : 0.001756800920702517 \n",
            " epoch : 1337, validation loss did not decrease \n",
            " Training loss : 0.0014435566263273358 , validation_loss : 0.0017778405454009771 , Best Valid Loss : 0.001756800920702517 \n",
            " epoch : 1338, validation loss did not decrease \n",
            " Training loss : 0.0014478934463113546 , validation_loss : 0.0017778025940060616 , Best Valid Loss : 0.001756800920702517 \n",
            " epoch : 1339, validation loss did not decrease \n",
            " Training loss : 0.0014534577494487166 , validation_loss : 0.001791431219317019 , Best Valid Loss : 0.001756800920702517 \n",
            " epoch : 1340, validation loss did not decrease \n",
            " Training loss : 0.0014604204334318638 , validation_loss : 0.0017979582771658897 , Best Valid Loss : 0.001756800920702517 \n",
            " epoch : 1341, validation loss did not decrease \n",
            " Training loss : 0.0014724934007972479 , validation_loss : 0.0018200454069301486 , Best Valid Loss : 0.001756800920702517 \n",
            " epoch : 1342, validation loss did not decrease \n",
            " Training loss : 0.0014859295915812254 , validation_loss : 0.0018313033506274223 , Best Valid Loss : 0.001756800920702517 \n",
            " epoch : 1343, validation loss did not decrease \n",
            " Training loss : 0.0015080496668815613 , validation_loss : 0.0018747203284874558 , Best Valid Loss : 0.001756800920702517 \n",
            " epoch : 1344, validation loss did not decrease \n",
            " Training loss : 0.0015355170471593738 , validation_loss : 0.0018989045638591051 , Best Valid Loss : 0.001756800920702517 \n",
            " epoch : 1345, validation loss did not decrease \n",
            " Training loss : 0.0015697641065344214 , validation_loss : 0.0019432149128988385 , Best Valid Loss : 0.001756800920702517 \n",
            " epoch : 1346, validation loss did not decrease \n",
            " Training loss : 0.001600926392711699 , validation_loss : 0.001968079013749957 , Best Valid Loss : 0.001756800920702517 \n",
            " epoch : 1347, validation loss did not decrease \n",
            " Training loss : 0.0016342803137376904 , validation_loss : 0.0019918715115636587 , Best Valid Loss : 0.001756800920702517 \n",
            " epoch : 1348, validation loss did not decrease \n",
            " Training loss : 0.0016449603717774153 , validation_loss : 0.0019808760844171047 , Best Valid Loss : 0.001756800920702517 \n",
            " epoch : 1349, validation loss did not decrease \n",
            " Training loss : 0.0016499682096764445 , validation_loss : 0.001970740035176277 , Best Valid Loss : 0.001756800920702517 \n",
            " epoch : 1350, validation loss did not decrease \n",
            " Training loss : 0.001624956727027893 , validation_loss : 0.001922549563460052 , Best Valid Loss : 0.001756800920702517 \n",
            " epoch : 1351, validation loss did not decrease \n",
            " Training loss : 0.0015930546214804053 , validation_loss : 0.0018689613789319992 , Best Valid Loss : 0.001756800920702517 \n",
            " epoch : 1352, validation loss did not decrease \n",
            " Training loss : 0.001531044254079461 , validation_loss : 0.0017999152187258005 , Best Valid Loss : 0.001756800920702517 \n",
            " epoch : 1353, validation loss did not decrease \n",
            " Training loss : 0.0014777658507227898 , validation_loss : 0.0017674471018835902 , Best Valid Loss : 0.001756800920702517 \n",
            " epoch : 1354, Validation loss decreased : 0.001756800920702517 --> 0.0017467780271545053 \n",
            " Training loss : 0.0014399235369637609 , validation_loss : 0.0017467780271545053 , Best Valid Loss : 0.0017467780271545053 \n",
            " epoch : 1355, validation loss did not decrease \n",
            " Training loss : 0.0014246777864173055 , validation_loss : 0.0017502151895314455 , Best Valid Loss : 0.0017467780271545053 \n",
            " epoch : 1356, validation loss did not decrease \n",
            " Training loss : 0.0014288517413660884 , validation_loss : 0.0017756278393790126 , Best Valid Loss : 0.0017467780271545053 \n",
            " epoch : 1357, validation loss did not decrease \n",
            " Training loss : 0.0014474018244072795 , validation_loss : 0.0017950405599549413 , Best Valid Loss : 0.0017467780271545053 \n",
            " epoch : 1358, validation loss did not decrease \n",
            " Training loss : 0.0014718789607286453 , validation_loss : 0.00182546756695956 , Best Valid Loss : 0.0017467780271545053 \n",
            " epoch : 1359, validation loss did not decrease \n",
            " Training loss : 0.0014921613037586212 , validation_loss : 0.0018285490805283189 , Best Valid Loss : 0.0017467780271545053 \n",
            " epoch : 1360, validation loss did not decrease \n",
            " Training loss : 0.0015053426614031196 , validation_loss : 0.0018374035134911537 , Best Valid Loss : 0.0017467780271545053 \n",
            " epoch : 1361, validation loss did not decrease \n",
            " Training loss : 0.001501824357546866 , validation_loss : 0.0018145251087844372 , Best Valid Loss : 0.0017467780271545053 \n",
            " epoch : 1362, validation loss did not decrease \n",
            " Training loss : 0.001493174466304481 , validation_loss : 0.001807125168852508 , Best Valid Loss : 0.0017467780271545053 \n",
            " epoch : 1363, validation loss did not decrease \n",
            " Training loss : 0.0014740020269528031 , validation_loss : 0.0017786818789318204 , Best Valid Loss : 0.0017467780271545053 \n",
            " epoch : 1364, validation loss did not decrease \n",
            " Training loss : 0.0014569135382771492 , validation_loss : 0.0017657377757132053 , Best Valid Loss : 0.0017467780271545053 \n",
            " epoch : 1365, validation loss did not decrease \n",
            " Training loss : 0.001437195809558034 , validation_loss : 0.0017472110921517015 , Best Valid Loss : 0.0017467780271545053 \n",
            " epoch : 1366, Validation loss decreased : 0.0017467780271545053 --> 0.0017439504154026508 \n",
            " Training loss : 0.0014251621905714273 , validation_loss : 0.0017439504154026508 , Best Valid Loss : 0.0017439504154026508 \n",
            " epoch : 1367, validation loss did not decrease \n",
            " Training loss : 0.0014197297859936953 , validation_loss : 0.0017469926970079541 , Best Valid Loss : 0.0017439504154026508 \n",
            " epoch : 1368, validation loss did not decrease \n",
            " Training loss : 0.0014212623937055469 , validation_loss : 0.0017526255687698722 , Best Valid Loss : 0.0017439504154026508 \n",
            " epoch : 1369, validation loss did not decrease \n",
            " Training loss : 0.0014293487183749676 , validation_loss : 0.0017676069401204586 , Best Valid Loss : 0.0017439504154026508 \n",
            " epoch : 1370, validation loss did not decrease \n",
            " Training loss : 0.0014390507712960243 , validation_loss : 0.0017730871913954616 , Best Valid Loss : 0.0017439504154026508 \n",
            " epoch : 1371, validation loss did not decrease \n",
            " Training loss : 0.0014509677421301603 , validation_loss : 0.0017911405302584171 , Best Valid Loss : 0.0017439504154026508 \n",
            " epoch : 1372, validation loss did not decrease \n",
            " Training loss : 0.0014599529094994068 , validation_loss : 0.001793057657778263 , Best Valid Loss : 0.0017439504154026508 \n",
            " epoch : 1373, validation loss did not decrease \n",
            " Training loss : 0.001470192801207304 , validation_loss : 0.0018098276341333985 , Best Valid Loss : 0.0017439504154026508 \n",
            " epoch : 1374, validation loss did not decrease \n",
            " Training loss : 0.0014769734116271138 , validation_loss : 0.0018124869093298912 , Best Valid Loss : 0.0017439504154026508 \n",
            " epoch : 1375, validation loss did not decrease \n",
            " Training loss : 0.0014885517302900553 , validation_loss : 0.0018294522305950522 , Best Valid Loss : 0.0017439504154026508 \n",
            " epoch : 1376, validation loss did not decrease \n",
            " Training loss : 0.0014943748246878386 , validation_loss : 0.0018255062168464065 , Best Valid Loss : 0.0017439504154026508 \n",
            " epoch : 1377, validation loss did not decrease \n",
            " Training loss : 0.0015029394999146461 , validation_loss : 0.0018466898472979665 , Best Valid Loss : 0.0017439504154026508 \n",
            " epoch : 1378, validation loss did not decrease \n",
            " Training loss : 0.0015101224416866899 , validation_loss : 0.0018456348916515708 , Best Valid Loss : 0.0017439504154026508 \n",
            " epoch : 1379, validation loss did not decrease \n",
            " Training loss : 0.0015208396362140775 , validation_loss : 0.0018654520390555263 , Best Valid Loss : 0.0017439504154026508 \n",
            " epoch : 1380, validation loss did not decrease \n",
            " Training loss : 0.0015280881198123097 , validation_loss : 0.0018633140716701746 , Best Valid Loss : 0.0017439504154026508 \n",
            " epoch : 1381, validation loss did not decrease \n",
            " Training loss : 0.0015376213705167174 , validation_loss : 0.0018786389846354723 , Best Valid Loss : 0.0017439504154026508 \n",
            " epoch : 1382, validation loss did not decrease \n",
            " Training loss : 0.001540023717097938 , validation_loss : 0.0018677165498957038 , Best Valid Loss : 0.0017439504154026508 \n",
            " epoch : 1383, validation loss did not decrease \n",
            " Training loss : 0.001542944461107254 , validation_loss : 0.0018738101935014129 , Best Valid Loss : 0.0017439504154026508 \n",
            " epoch : 1384, validation loss did not decrease \n",
            " Training loss : 0.0015356705989688635 , validation_loss : 0.0018530042143538594 , Best Valid Loss : 0.0017439504154026508 \n",
            " epoch : 1385, validation loss did not decrease \n",
            " Training loss : 0.0015281925443559885 , validation_loss : 0.0018424636218696833 , Best Valid Loss : 0.0017439504154026508 \n",
            " epoch : 1386, validation loss did not decrease \n",
            " Training loss : 0.0015068819047883153 , validation_loss : 0.0018077298300340772 , Best Valid Loss : 0.0017439504154026508 \n",
            " epoch : 1387, validation loss did not decrease \n",
            " Training loss : 0.0014855924528092146 , validation_loss : 0.0017925514839589596 , Best Valid Loss : 0.0017439504154026508 \n",
            " epoch : 1388, validation loss did not decrease \n",
            " Training loss : 0.0014612746890634298 , validation_loss : 0.0017619936261326075 , Best Valid Loss : 0.0017439504154026508 \n",
            " epoch : 1389, validation loss did not decrease \n",
            " Training loss : 0.001441389787942171 , validation_loss : 0.0017495715292170644 , Best Valid Loss : 0.0017439504154026508 \n",
            " epoch : 1390, Validation loss decreased : 0.0017439504154026508 --> 0.0017359463963657618 \n",
            " Training loss : 0.00142337114084512 , validation_loss : 0.0017359463963657618 , Best Valid Loss : 0.0017359463963657618 \n",
            " epoch : 1391, Validation loss decreased : 0.0017359463963657618 --> 0.0017343397485092282 \n",
            " Training loss : 0.001414345228113234 , validation_loss : 0.0017343397485092282 , Best Valid Loss : 0.0017343397485092282 \n",
            " epoch : 1392, validation loss did not decrease \n",
            " Training loss : 0.001411530887708068 , validation_loss : 0.0017381017096340656 , Best Valid Loss : 0.0017343397485092282 \n",
            " epoch : 1393, validation loss did not decrease \n",
            " Training loss : 0.0014136983081698418 , validation_loss : 0.0017410662258043885 , Best Valid Loss : 0.0017343397485092282 \n",
            " epoch : 1394, validation loss did not decrease \n",
            " Training loss : 0.0014194744871929288 , validation_loss : 0.0017511899350211024 , Best Valid Loss : 0.0017343397485092282 \n",
            " epoch : 1395, validation loss did not decrease \n",
            " Training loss : 0.0014246950158849359 , validation_loss : 0.001750847790390253 , Best Valid Loss : 0.0017343397485092282 \n",
            " epoch : 1396, validation loss did not decrease \n",
            " Training loss : 0.0014307479141280055 , validation_loss : 0.0017601485596969724 , Best Valid Loss : 0.0017343397485092282 \n",
            " epoch : 1397, validation loss did not decrease \n",
            " Training loss : 0.001432335819117725 , validation_loss : 0.001754803117364645 , Best Valid Loss : 0.0017343397485092282 \n",
            " epoch : 1398, validation loss did not decrease \n",
            " Training loss : 0.001433812314644456 , validation_loss : 0.0017581750871613622 , Best Valid Loss : 0.0017343397485092282 \n",
            " epoch : 1399, validation loss did not decrease \n",
            " Training loss : 0.0014304779469966888 , validation_loss : 0.001748615875840187 , Best Valid Loss : 0.0017343397485092282 \n",
            " epoch : 1400, validation loss did not decrease \n",
            " Training loss : 0.001427460229024291 , validation_loss : 0.0017475384520366788 , Best Valid Loss : 0.0017343397485092282 \n",
            " epoch : 1401, validation loss did not decrease \n",
            " Training loss : 0.001421100925654173 , validation_loss : 0.0017372574657201767 , Best Valid Loss : 0.0017343397485092282 \n",
            " epoch : 1402, validation loss did not decrease \n",
            " Training loss : 0.0014163129962980747 , validation_loss : 0.0017361000645905733 , Best Valid Loss : 0.0017343397485092282 \n",
            " epoch : 1403, Validation loss decreased : 0.0017343397485092282 --> 0.0017308968817815185 \n",
            " Training loss : 0.0014113321667537093 , validation_loss : 0.0017308968817815185 , Best Valid Loss : 0.0017308968817815185 \n",
            " epoch : 1404, Validation loss decreased : 0.0017308968817815185 --> 0.001730149844661355 \n",
            " Training loss : 0.0014082178240641952 , validation_loss : 0.001730149844661355 , Best Valid Loss : 0.001730149844661355 \n",
            " epoch : 1405, validation loss did not decrease \n",
            " Training loss : 0.0014065903378650546 , validation_loss : 0.0017306088702753186 , Best Valid Loss : 0.001730149844661355 \n",
            " epoch : 1406, validation loss did not decrease \n",
            " Training loss : 0.0014067484298720956 , validation_loss : 0.0017304380889981985 , Best Valid Loss : 0.001730149844661355 \n",
            " epoch : 1407, validation loss did not decrease \n",
            " Training loss : 0.0014084355207160115 , validation_loss : 0.00173462787643075 , Best Valid Loss : 0.001730149844661355 \n",
            " epoch : 1408, validation loss did not decrease \n",
            " Training loss : 0.0014100682456046343 , validation_loss : 0.0017333035357296467 , Best Valid Loss : 0.001730149844661355 \n",
            " epoch : 1409, validation loss did not decrease \n",
            " Training loss : 0.0014118801336735487 , validation_loss : 0.0017378443153575063 , Best Valid Loss : 0.001730149844661355 \n",
            " epoch : 1410, validation loss did not decrease \n",
            " Training loss : 0.0014125787420198321 , validation_loss : 0.00173505290877074 , Best Valid Loss : 0.001730149844661355 \n",
            " epoch : 1411, validation loss did not decrease \n",
            " Training loss : 0.0014131898060441017 , validation_loss : 0.0017380190547555685 , Best Valid Loss : 0.001730149844661355 \n",
            " epoch : 1412, validation loss did not decrease \n",
            " Training loss : 0.0014126155292615294 , validation_loss : 0.001733591197989881 , Best Valid Loss : 0.001730149844661355 \n",
            " epoch : 1413, validation loss did not decrease \n",
            " Training loss : 0.001412274083122611 , validation_loss : 0.0017379343044012785 , Best Valid Loss : 0.001730149844661355 \n",
            " epoch : 1414, validation loss did not decrease \n",
            " Training loss : 0.0014124438166618347 , validation_loss : 0.0017344504594802856 , Best Valid Loss : 0.001730149844661355 \n",
            " epoch : 1415, validation loss did not decrease \n",
            " Training loss : 0.001412690500728786 , validation_loss : 0.0017388749402016401 , Best Valid Loss : 0.001730149844661355 \n",
            " epoch : 1416, validation loss did not decrease \n",
            " Training loss : 0.0014131313655525446 , validation_loss : 0.001735243946313858 , Best Valid Loss : 0.001730149844661355 \n",
            " epoch : 1417, validation loss did not decrease \n",
            " Training loss : 0.0014135706005617976 , validation_loss : 0.001740235136821866 , Best Valid Loss : 0.001730149844661355 \n",
            " epoch : 1418, validation loss did not decrease \n",
            " Training loss : 0.001414322992786765 , validation_loss : 0.0017361994832754135 , Best Valid Loss : 0.001730149844661355 \n",
            " epoch : 1419, validation loss did not decrease \n",
            " Training loss : 0.0014147923793643713 , validation_loss : 0.0017412794986739755 , Best Valid Loss : 0.001730149844661355 \n",
            " epoch : 1420, validation loss did not decrease \n",
            " Training loss : 0.0014152361545711756 , validation_loss : 0.0017377635231241584 , Best Valid Loss : 0.001730149844661355 \n",
            " epoch : 1421, validation loss did not decrease \n",
            " Training loss : 0.0014164538588374853 , validation_loss : 0.0017441872041672468 , Best Valid Loss : 0.001730149844661355 \n",
            " epoch : 1422, validation loss did not decrease \n",
            " Training loss : 0.0014178614364936948 , validation_loss : 0.0017413025489076972 , Best Valid Loss : 0.001730149844661355 \n",
            " epoch : 1423, validation loss did not decrease \n",
            " Training loss : 0.0014202941674739122 , validation_loss : 0.0017501177499070764 , Best Valid Loss : 0.001730149844661355 \n",
            " epoch : 1424, validation loss did not decrease \n",
            " Training loss : 0.0014232334215193987 , validation_loss : 0.001749980729073286 , Best Valid Loss : 0.001730149844661355 \n",
            " epoch : 1425, validation loss did not decrease \n",
            " Training loss : 0.0014291666448116302 , validation_loss : 0.001764485496096313 , Best Valid Loss : 0.001730149844661355 \n",
            " epoch : 1426, validation loss did not decrease \n",
            " Training loss : 0.0014362994115799665 , validation_loss : 0.001769647584296763 , Best Valid Loss : 0.001730149844661355 \n",
            " epoch : 1427, validation loss did not decrease \n",
            " Training loss : 0.0014483969425782561 , validation_loss : 0.0017953243805095553 , Best Valid Loss : 0.001730149844661355 \n",
            " epoch : 1428, validation loss did not decrease \n",
            " Training loss : 0.0014646274503320456 , validation_loss : 0.0018157492158934474 , Best Valid Loss : 0.001730149844661355 \n",
            " epoch : 1429, validation loss did not decrease \n",
            " Training loss : 0.0014929231256246567 , validation_loss : 0.0018633764702826738 , Best Valid Loss : 0.001730149844661355 \n",
            " epoch : 1430, validation loss did not decrease \n",
            " Training loss : 0.0015273370081558824 , validation_loss : 0.0019081281498074532 , Best Valid Loss : 0.001730149844661355 \n",
            " epoch : 1431, validation loss did not decrease \n",
            " Training loss : 0.0015805477742105722 , validation_loss : 0.0019777293782681227 , Best Valid Loss : 0.001730149844661355 \n",
            " epoch : 1432, validation loss did not decrease \n",
            " Training loss : 0.0016344848554581404 , validation_loss : 0.0020461229141801596 , Best Valid Loss : 0.001730149844661355 \n",
            " epoch : 1433, validation loss did not decrease \n",
            " Training loss : 0.0017075685318559408 , validation_loss : 0.002071948256343603 , Best Valid Loss : 0.001730149844661355 \n",
            " epoch : 1434, validation loss did not decrease \n",
            " Training loss : 0.0017237849533557892 , validation_loss : 0.0020788961555808783 , Best Valid Loss : 0.001730149844661355 \n",
            " epoch : 1435, validation loss did not decrease \n",
            " Training loss : 0.0017384322127327323 , validation_loss : 0.0020141019485890865 , Best Valid Loss : 0.001730149844661355 \n",
            " epoch : 1436, validation loss did not decrease \n",
            " Training loss : 0.001668127253651619 , validation_loss : 0.001921771909110248 , Best Valid Loss : 0.001730149844661355 \n",
            " epoch : 1437, validation loss did not decrease \n",
            " Training loss : 0.0015941171441227198 , validation_loss : 0.00182306335773319 , Best Valid Loss : 0.001730149844661355 \n",
            " epoch : 1438, validation loss did not decrease \n",
            " Training loss : 0.001489842077717185 , validation_loss : 0.0017416883492842317 , Best Valid Loss : 0.001730149844661355 \n",
            " epoch : 1439, Validation loss decreased : 0.001730149844661355 --> 0.0017187366029247642 \n",
            " Training loss : 0.0014261296018958092 , validation_loss : 0.0017187366029247642 , Best Valid Loss : 0.0017187366029247642 \n",
            " epoch : 1440, validation loss did not decrease \n",
            " Training loss : 0.001398744061589241 , validation_loss : 0.001723832217976451 , Best Valid Loss : 0.0017187366029247642 \n",
            " epoch : 1441, validation loss did not decrease \n",
            " Training loss : 0.0014026343123987317 , validation_loss : 0.0017471415922045708 , Best Valid Loss : 0.0017187366029247642 \n",
            " epoch : 1442, validation loss did not decrease \n",
            " Training loss : 0.0014286632649600506 , validation_loss : 0.0017909742891788483 , Best Valid Loss : 0.0017187366029247642 \n",
            " epoch : 1443, validation loss did not decrease \n",
            " Training loss : 0.0014628113713115454 , validation_loss : 0.0018145334906876087 , Best Valid Loss : 0.0017187366029247642 \n",
            " epoch : 1444, validation loss did not decrease \n",
            " Training loss : 0.0014942894922569394 , validation_loss : 0.0018330991733819246 , Best Valid Loss : 0.0017187366029247642 \n",
            " epoch : 1445, validation loss did not decrease \n",
            " Training loss : 0.0014997089747339487 , validation_loss : 0.00181730673648417 , Best Valid Loss : 0.0017187366029247642 \n",
            " epoch : 1446, validation loss did not decrease \n",
            " Training loss : 0.0014973519137129188 , validation_loss : 0.0018027570331469178 , Best Valid Loss : 0.0017187366029247642 \n",
            " epoch : 1447, validation loss did not decrease \n",
            " Training loss : 0.0014713683631271124 , validation_loss : 0.0017632122617214918 , Best Valid Loss : 0.0017187366029247642 \n",
            " epoch : 1448, validation loss did not decrease \n",
            " Training loss : 0.0014449330046772957 , validation_loss : 0.0017451632302254438 , Best Valid Loss : 0.0017187366029247642 \n",
            " epoch : 1449, Validation loss decreased : 0.0017187366029247642 --> 0.0017182283336296678 \n",
            " Training loss : 0.0014193905517458916 , validation_loss : 0.0017182283336296678 , Best Valid Loss : 0.0017182283336296678 \n",
            " epoch : 1450, Validation loss decreased : 0.0017182283336296678 --> 0.0017117138486355543 \n",
            " Training loss : 0.00140049634501338 , validation_loss : 0.0017117138486355543 , Best Valid Loss : 0.0017117138486355543 \n",
            " epoch : 1451, validation loss did not decrease \n",
            " Training loss : 0.0013918650802224874 , validation_loss : 0.0017154288943856955 , Best Valid Loss : 0.0017117138486355543 \n",
            " epoch : 1452, validation loss did not decrease \n",
            " Training loss : 0.0013941851211711764 , validation_loss : 0.0017221467569470406 , Best Valid Loss : 0.0017117138486355543 \n",
            " epoch : 1453, validation loss did not decrease \n",
            " Training loss : 0.0014034414198249578 , validation_loss : 0.001737952115945518 , Best Valid Loss : 0.0017117138486355543 \n",
            " epoch : 1454, validation loss did not decrease \n",
            " Training loss : 0.0014137281104922295 , validation_loss : 0.0017439224757254124 , Best Valid Loss : 0.0017117138486355543 \n",
            " epoch : 1455, validation loss did not decrease \n",
            " Training loss : 0.001424826798029244 , validation_loss : 0.0017615347169339657 , Best Valid Loss : 0.0017117138486355543 \n",
            " epoch : 1456, validation loss did not decrease \n",
            " Training loss : 0.0014349364209920168 , validation_loss : 0.0017649244982749224 , Best Valid Loss : 0.0017117138486355543 \n",
            " epoch : 1457, validation loss did not decrease \n",
            " Training loss : 0.0014454096090048552 , validation_loss : 0.0017805545357987285 , Best Valid Loss : 0.0017117138486355543 \n",
            " epoch : 1458, validation loss did not decrease \n",
            " Training loss : 0.0014519323594868183 , validation_loss : 0.0017791840946301818 , Best Valid Loss : 0.0017117138486355543 \n",
            " epoch : 1459, validation loss did not decrease \n",
            " Training loss : 0.0014590967912226915 , validation_loss : 0.0017943569691851735 , Best Valid Loss : 0.0017117138486355543 \n",
            " epoch : 1460, validation loss did not decrease \n",
            " Training loss : 0.0014643522445112467 , validation_loss : 0.0017922217957675457 , Best Valid Loss : 0.0017117138486355543 \n",
            " epoch : 1461, validation loss did not decrease \n",
            " Training loss : 0.0014725158689543605 , validation_loss : 0.0018077142303809524 , Best Valid Loss : 0.0017117138486355543 \n",
            " epoch : 1462, validation loss did not decrease \n",
            " Training loss : 0.0014765234664082527 , validation_loss : 0.0018032601801678538 , Best Valid Loss : 0.0017117138486355543 \n",
            " epoch : 1463, validation loss did not decrease \n",
            " Training loss : 0.0014826375991106033 , validation_loss : 0.0018130808603018522 , Best Valid Loss : 0.0017117138486355543 \n",
            " epoch : 1464, validation loss did not decrease \n",
            " Training loss : 0.0014822038356214762 , validation_loss : 0.0018065026961266994 , Best Valid Loss : 0.0017117138486355543 \n",
            " epoch : 1465, validation loss did not decrease \n",
            " Training loss : 0.0014846136327832937 , validation_loss : 0.0018126927316188812 , Best Valid Loss : 0.0017117138486355543 \n",
            " epoch : 1466, validation loss did not decrease \n",
            " Training loss : 0.0014822918456047773 , validation_loss : 0.0018044449388980865 , Best Valid Loss : 0.0017117138486355543 \n",
            " epoch : 1467, validation loss did not decrease \n",
            " Training loss : 0.0014831084990873933 , validation_loss : 0.0018091154051944613 , Best Valid Loss : 0.0017117138486355543 \n",
            " epoch : 1468, validation loss did not decrease \n",
            " Training loss : 0.0014788828557357192 , validation_loss : 0.001796605414710939 , Best Valid Loss : 0.0017117138486355543 \n",
            " epoch : 1469, validation loss did not decrease \n",
            " Training loss : 0.0014756637392565608 , validation_loss : 0.0017941653495654464 , Best Valid Loss : 0.0017117138486355543 \n",
            " epoch : 1470, validation loss did not decrease \n",
            " Training loss : 0.00146488135214895 , validation_loss : 0.0017753279535099864 , Best Valid Loss : 0.0017117138486355543 \n",
            " epoch : 1471, validation loss did not decrease \n",
            " Training loss : 0.0014562653377652168 , validation_loss : 0.001766976318322122 , Best Valid Loss : 0.0017117138486355543 \n",
            " epoch : 1472, validation loss did not decrease \n",
            " Training loss : 0.0014396486803889275 , validation_loss : 0.0017419180367141962 , Best Valid Loss : 0.0017117138486355543 \n",
            " epoch : 1473, validation loss did not decrease \n",
            " Training loss : 0.0014242550823837519 , validation_loss : 0.001730209100060165 , Best Valid Loss : 0.0017117138486355543 \n",
            " epoch : 1474, Validation loss decreased : 0.0017117138486355543 --> 0.0017106562154367566 \n",
            " Training loss : 0.0014067069860175252 , validation_loss : 0.0017106562154367566 , Best Valid Loss : 0.0017106562154367566 \n",
            " epoch : 1475, Validation loss decreased : 0.0017106562154367566 --> 0.001704252092167735 \n",
            " Training loss : 0.0013930134009569883 , validation_loss : 0.001704252092167735 , Best Valid Loss : 0.001704252092167735 \n",
            " epoch : 1476, Validation loss decreased : 0.001704252092167735 --> 0.0017001121304929256 \n",
            " Training loss : 0.0013842314947396517 , validation_loss : 0.0017001121304929256 , Best Valid Loss : 0.0017001121304929256 \n",
            " epoch : 1477, validation loss did not decrease \n",
            " Training loss : 0.0013815538259223104 , validation_loss : 0.0017007741844281554 , Best Valid Loss : 0.0017001121304929256 \n",
            " epoch : 1478, validation loss did not decrease \n",
            " Training loss : 0.0013831773540005088 , validation_loss : 0.001709034782834351 , Best Valid Loss : 0.0017001121304929256 \n",
            " epoch : 1479, validation loss did not decrease \n",
            " Training loss : 0.0013880361802875996 , validation_loss : 0.0017127128085121512 , Best Valid Loss : 0.0017001121304929256 \n",
            " epoch : 1480, validation loss did not decrease \n",
            " Training loss : 0.0013950924621894956 , validation_loss : 0.0017233220860362053 , Best Valid Loss : 0.0017001121304929256 \n",
            " epoch : 1481, validation loss did not decrease \n",
            " Training loss : 0.0014003881951794028 , validation_loss : 0.0017211224185302854 , Best Valid Loss : 0.0017001121304929256 \n",
            " epoch : 1482, validation loss did not decrease \n",
            " Training loss : 0.0014040410751476884 , validation_loss : 0.0017270370153710246 , Best Valid Loss : 0.0017001121304929256 \n",
            " epoch : 1483, validation loss did not decrease \n",
            " Training loss : 0.0014036385109648108 , validation_loss : 0.0017185331089422107 , Best Valid Loss : 0.0017001121304929256 \n",
            " epoch : 1484, validation loss did not decrease \n",
            " Training loss : 0.0014013024047017097 , validation_loss : 0.001719832420349121 , Best Valid Loss : 0.0017001121304929256 \n",
            " epoch : 1485, validation loss did not decrease \n",
            " Training loss : 0.0013973275199532509 , validation_loss : 0.0017111118650063872 , Best Valid Loss : 0.0017001121304929256 \n",
            " epoch : 1486, validation loss did not decrease \n",
            " Training loss : 0.0013936387840658426 , validation_loss : 0.0017096480587497354 , Best Valid Loss : 0.0017001121304929256 \n",
            " epoch : 1487, validation loss did not decrease \n",
            " Training loss : 0.0013884870568290353 , validation_loss : 0.001701223780401051 , Best Valid Loss : 0.0017001121304929256 \n",
            " epoch : 1488, validation loss did not decrease \n",
            " Training loss : 0.0013842587359249592 , validation_loss : 0.001700258580967784 , Best Valid Loss : 0.0017001121304929256 \n",
            " epoch : 1489, Validation loss decreased : 0.0017001121304929256 --> 0.0016959079075604677 \n",
            " Training loss : 0.0013803767506033182 , validation_loss : 0.0016959079075604677 , Best Valid Loss : 0.0016959079075604677 \n",
            " epoch : 1490, Validation loss decreased : 0.0016959079075604677 --> 0.0016954266466200352 \n",
            " Training loss : 0.0013779879081994295 , validation_loss : 0.0016954266466200352 , Best Valid Loss : 0.0016954266466200352 \n",
            " epoch : 1491, Validation loss decreased : 0.0016954266466200352 --> 0.0016939834458753467 \n",
            " Training loss : 0.0013763371389359236 , validation_loss : 0.0016939834458753467 , Best Valid Loss : 0.0016939834458753467 \n",
            " epoch : 1492, Validation loss decreased : 0.0016939834458753467 --> 0.0016935232561081648 \n",
            " Training loss : 0.0013755450490862131 , validation_loss : 0.0016935232561081648 , Best Valid Loss : 0.0016935232561081648 \n",
            " epoch : 1493, validation loss did not decrease \n",
            " Training loss : 0.001375234336592257 , validation_loss : 0.0016944387461990118 , Best Valid Loss : 0.0016935232561081648 \n",
            " epoch : 1494, validation loss did not decrease \n",
            " Training loss : 0.0013753134990110993 , validation_loss : 0.0016935799503698945 , Best Valid Loss : 0.0016935232561081648 \n",
            " epoch : 1495, validation loss did not decrease \n",
            " Training loss : 0.001375789986923337 , validation_loss : 0.0016961445799097419 , Best Valid Loss : 0.0016935232561081648 \n",
            " epoch : 1496, validation loss did not decrease \n",
            " Training loss : 0.0013763209572061896 , validation_loss : 0.0016948588890954852 , Best Valid Loss : 0.0016935232561081648 \n",
            " epoch : 1497, validation loss did not decrease \n",
            " Training loss : 0.0013772553065791726 , validation_loss : 0.0016977937193587422 , Best Valid Loss : 0.0016935232561081648 \n",
            " epoch : 1498, validation loss did not decrease \n",
            " Training loss : 0.0013777598505839705 , validation_loss : 0.0016965150134637952 , Best Valid Loss : 0.0016935232561081648 \n",
            " epoch : 1499, validation loss did not decrease \n",
            " Training loss : 0.0013800313463434577 , validation_loss : 0.0017042489489540458 , Best Valid Loss : 0.0016935232561081648 \n",
            " epoch : 1500, validation loss did not decrease \n",
            " Training loss : 0.001383179915137589 , validation_loss : 0.0017061590915545821 , Best Valid Loss : 0.0016935232561081648 \n",
            " epoch : 1501, validation loss did not decrease \n",
            " Training loss : 0.0013884365325793624 , validation_loss : 0.001717364531941712 , Best Valid Loss : 0.0016935232561081648 \n",
            " epoch : 1502, validation loss did not decrease \n",
            " Training loss : 0.0013948169071227312 , validation_loss : 0.0017206443008035421 , Best Valid Loss : 0.0016935232561081648 \n",
            " epoch : 1503, validation loss did not decrease \n",
            " Training loss : 0.001403608126565814 , validation_loss : 0.0017396054463461041 , Best Valid Loss : 0.0016935232561081648 \n",
            " epoch : 1504, validation loss did not decrease \n",
            " Training loss : 0.0014147479087114334 , validation_loss : 0.0017503236886113882 , Best Valid Loss : 0.0016935232561081648 \n",
            " epoch : 1505, validation loss did not decrease \n",
            " Training loss : 0.0014332543360069394 , validation_loss : 0.0017838675994426012 , Best Valid Loss : 0.0016935232561081648 \n",
            " epoch : 1506, validation loss did not decrease \n",
            " Training loss : 0.0014557826798409224 , validation_loss : 0.0018128532683476806 , Best Valid Loss : 0.0016935232561081648 \n",
            " epoch : 1507, validation loss did not decrease \n",
            " Training loss : 0.001490364782512188 , validation_loss : 0.0018616183660924435 , Best Valid Loss : 0.0016935232561081648 \n",
            " epoch : 1508, validation loss did not decrease \n",
            " Training loss : 0.0015286736888810992 , validation_loss : 0.0019103592494502664 , Best Valid Loss : 0.0016935232561081648 \n",
            " epoch : 1509, validation loss did not decrease \n",
            " Training loss : 0.0015828886535018682 , validation_loss : 0.001947582932189107 , Best Valid Loss : 0.0016935232561081648 \n",
            " epoch : 1510, validation loss did not decrease \n",
            " Training loss : 0.00160323828458786 , validation_loss : 0.00198605889454484 , Best Valid Loss : 0.0016935232561081648 \n",
            " epoch : 1511, validation loss did not decrease \n",
            " Training loss : 0.001693417434580624 , validation_loss : 0.0021363890264183283 , Best Valid Loss : 0.0016935232561081648 \n",
            " epoch : 1512, validation loss did not decrease \n",
            " Training loss : 0.001816630712710321 , validation_loss : 0.002295822836458683 , Best Valid Loss : 0.0016935232561081648 \n",
            " epoch : 1513, validation loss did not decrease \n",
            " Training loss : 0.001902436139062047 , validation_loss : 0.0020136183593422174 , Best Valid Loss : 0.0016935232561081648 \n",
            " epoch : 1514, validation loss did not decrease \n",
            " Training loss : 0.001674138242378831 , validation_loss : 0.0018379561370238662 , Best Valid Loss : 0.0016935232561081648 \n",
            " epoch : 1515, validation loss did not decrease \n",
            " Training loss : 0.0015532094985246658 , validation_loss : 0.0017694784328341484 , Best Valid Loss : 0.0016935232561081648 \n",
            " epoch : 1516, validation loss did not decrease \n",
            " Training loss : 0.0014423277461901307 , validation_loss : 0.0017106919549405575 , Best Valid Loss : 0.0016935232561081648 \n",
            " epoch : 1517, validation loss did not decrease \n",
            " Training loss : 0.0013916511088609695 , validation_loss : 0.0016960962675511837 , Best Valid Loss : 0.0016935232561081648 \n",
            " epoch : 1518, validation loss did not decrease \n",
            " Training loss : 0.0013796453131362796 , validation_loss : 0.0017069403547793627 , Best Valid Loss : 0.0016935232561081648 \n",
            " epoch : 1519, validation loss did not decrease \n",
            " Training loss : 0.001387390191666782 , validation_loss : 0.0017300188774242997 , Best Valid Loss : 0.0016935232561081648 \n",
            " epoch : 1520, validation loss did not decrease \n",
            " Training loss : 0.0014346870593726635 , validation_loss : 0.0018047729972749949 , Best Valid Loss : 0.0016935232561081648 \n",
            " epoch : 1521, validation loss did not decrease \n",
            " Training loss : 0.0014730269322171807 , validation_loss : 0.0018326458521187305 , Best Valid Loss : 0.0016935232561081648 \n",
            " epoch : 1522, validation loss did not decrease \n",
            " Training loss : 0.0015069219516590238 , validation_loss : 0.0018048265483230352 , Best Valid Loss : 0.0016935232561081648 \n",
            " epoch : 1523, validation loss did not decrease \n",
            " Training loss : 0.0014828973216935992 , validation_loss : 0.001747398404404521 , Best Valid Loss : 0.0016935232561081648 \n",
            " epoch : 1524, validation loss did not decrease \n",
            " Training loss : 0.0014275067951530218 , validation_loss : 0.0016993330791592598 , Best Valid Loss : 0.0016935232561081648 \n",
            " epoch : 1525, Validation loss decreased : 0.0016935232561081648 --> 0.0016788964858278632 \n",
            " Training loss : 0.001382061280310154 , validation_loss : 0.0016788964858278632 , Best Valid Loss : 0.0016788964858278632 \n",
            " epoch : 1526, validation loss did not decrease \n",
            " Training loss : 0.0013699585106223822 , validation_loss : 0.0016873530112206936 , Best Valid Loss : 0.0016788964858278632 \n",
            " epoch : 1527, validation loss did not decrease \n",
            " Training loss : 0.0013737331610172987 , validation_loss : 0.0017155550885945559 , Best Valid Loss : 0.0016788964858278632 \n",
            " epoch : 1528, validation loss did not decrease \n",
            " Training loss : 0.001397612038999796 , validation_loss : 0.0017359231133013964 , Best Valid Loss : 0.0016788964858278632 \n",
            " epoch : 1529, validation loss did not decrease \n",
            " Training loss : 0.0014147271867841482 , validation_loss : 0.0017400227952748537 , Best Valid Loss : 0.0016788964858278632 \n",
            " epoch : 1530, validation loss did not decrease \n",
            " Training loss : 0.0014156841207295656 , validation_loss : 0.001723180990666151 , Best Valid Loss : 0.0016788964858278632 \n",
            " epoch : 1531, validation loss did not decrease \n",
            " Training loss : 0.0014191999798640609 , validation_loss : 0.001731983618810773 , Best Valid Loss : 0.0016788964858278632 \n",
            " epoch : 1532, validation loss did not decrease \n",
            " Training loss : 0.0014081731205806136 , validation_loss : 0.0017221898306161165 , Best Valid Loss : 0.0016788964858278632 \n",
            " epoch : 1533, validation loss did not decrease \n",
            " Training loss : 0.0014023083494976163 , validation_loss : 0.0017067767912521958 , Best Valid Loss : 0.0016788964858278632 \n",
            " epoch : 1534, validation loss did not decrease \n",
            " Training loss : 0.0013864325592294335 , validation_loss : 0.0016848798841238022 , Best Valid Loss : 0.0016788964858278632 \n",
            " epoch : 1535, Validation loss decreased : 0.0016788964858278632 --> 0.0016781132435426116 \n",
            " Training loss : 0.001371077261865139 , validation_loss : 0.0016781132435426116 , Best Valid Loss : 0.0016781132435426116 \n",
            " epoch : 1536, Validation loss decreased : 0.0016781132435426116 --> 0.00167416175827384 \n",
            " Training loss : 0.0013634853530675173 , validation_loss : 0.00167416175827384 , Best Valid Loss : 0.00167416175827384 \n",
            " epoch : 1537, validation loss did not decrease \n",
            " Training loss : 0.0013593793846666813 , validation_loss : 0.0016788579523563385 , Best Valid Loss : 0.00167416175827384 \n",
            " epoch : 1538, validation loss did not decrease \n",
            " Training loss : 0.001361532136797905 , validation_loss : 0.001685810275375843 , Best Valid Loss : 0.00167416175827384 \n",
            " epoch : 1539, validation loss did not decrease \n",
            " Training loss : 0.0013676556991413236 , validation_loss : 0.0016880175098776817 , Best Valid Loss : 0.00167416175827384 \n",
            " epoch : 1540, validation loss did not decrease \n",
            " Training loss : 0.00137228867970407 , validation_loss : 0.0016966682160273194 , Best Valid Loss : 0.00167416175827384 \n",
            " epoch : 1541, validation loss did not decrease \n",
            " Training loss : 0.001377205247990787 , validation_loss : 0.001694786362349987 , Best Valid Loss : 0.00167416175827384 \n",
            " epoch : 1542, validation loss did not decrease \n",
            " Training loss : 0.0013839325401932001 , validation_loss : 0.0017106335144490004 , Best Valid Loss : 0.00167416175827384 \n",
            " epoch : 1543, validation loss did not decrease \n",
            " Training loss : 0.0013901138445362449 , validation_loss : 0.0017167029436677694 , Best Valid Loss : 0.00167416175827384 \n",
            " epoch : 1544, validation loss did not decrease \n",
            " Training loss : 0.0013962751254439354 , validation_loss : 0.0017138043185696006 , Best Valid Loss : 0.00167416175827384 \n",
            " epoch : 1545, validation loss did not decrease \n",
            " Training loss : 0.0013929936103522778 , validation_loss : 0.0017004701076075435 , Best Valid Loss : 0.00167416175827384 \n",
            " epoch : 1546, validation loss did not decrease \n",
            " Training loss : 0.0013893236173316836 , validation_loss : 0.001706896466203034 , Best Valid Loss : 0.00167416175827384 \n",
            " epoch : 1547, validation loss did not decrease \n",
            " Training loss : 0.001386303105391562 , validation_loss : 0.001700995839200914 , Best Valid Loss : 0.00167416175827384 \n",
            " epoch : 1548, validation loss did not decrease \n",
            " Training loss : 0.001385944546200335 , validation_loss : 0.0017034751363098621 , Best Valid Loss : 0.00167416175827384 \n",
            " epoch : 1549, validation loss did not decrease \n",
            " Training loss : 0.0013839950552210212 , validation_loss : 0.0016951056895777583 , Best Valid Loss : 0.00167416175827384 \n",
            " epoch : 1550, validation loss did not decrease \n",
            " Training loss : 0.0013783302856609225 , validation_loss : 0.0016890893457457423 , Best Valid Loss : 0.00167416175827384 \n",
            " epoch : 1551, validation loss did not decrease \n",
            " Training loss : 0.00137048470787704 , validation_loss : 0.0016768168425187469 , Best Valid Loss : 0.00167416175827384 \n",
            " epoch : 1552, validation loss did not decrease \n",
            " Training loss : 0.001364486408419907 , validation_loss : 0.0016759036807343364 , Best Valid Loss : 0.00167416175827384 \n",
            " epoch : 1553, Validation loss decreased : 0.00167416175827384 --> 0.0016712809447199106 \n",
            " Training loss : 0.00135892815887928 , validation_loss : 0.0016712809447199106 , Best Valid Loss : 0.0016712809447199106 \n",
            " epoch : 1554, Validation loss decreased : 0.0016712809447199106 --> 0.0016691643977537751 \n",
            " Training loss : 0.0013553992612287402 , validation_loss : 0.0016691643977537751 , Best Valid Loss : 0.0016691643977537751 \n",
            " epoch : 1555, Validation loss decreased : 0.0016691643977537751 --> 0.0016660614637658 \n",
            " Training loss : 0.0013527579139918089 , validation_loss : 0.0016660614637658 , Best Valid Loss : 0.0016660614637658 \n",
            " epoch : 1556, Validation loss decreased : 0.0016660614637658 --> 0.001665123738348484 \n",
            " Training loss : 0.0013514590682461858 , validation_loss : 0.001665123738348484 , Best Valid Loss : 0.001665123738348484 \n",
            " epoch : 1557, validation loss did not decrease \n",
            " Training loss : 0.001351198647171259 , validation_loss : 0.0016666145529597998 , Best Valid Loss : 0.001665123738348484 \n",
            " epoch : 1558, validation loss did not decrease \n",
            " Training loss : 0.001351165003143251 , validation_loss : 0.001667471369728446 , Best Valid Loss : 0.001665123738348484 \n",
            " epoch : 1559, validation loss did not decrease \n",
            " Training loss : 0.001352173276245594 , validation_loss : 0.0016698858235031366 , Best Valid Loss : 0.001665123738348484 \n",
            " epoch : 1560, validation loss did not decrease \n",
            " Training loss : 0.0013535561738535762 , validation_loss : 0.0016691391356289387 , Best Valid Loss : 0.001665123738348484 \n",
            " epoch : 1561, validation loss did not decrease \n",
            " Training loss : 0.0013563779648393393 , validation_loss : 0.0016764822648838162 , Best Valid Loss : 0.001665123738348484 \n",
            " epoch : 1562, validation loss did not decrease \n",
            " Training loss : 0.0013597308425232768 , validation_loss : 0.001677501481026411 , Best Valid Loss : 0.001665123738348484 \n",
            " epoch : 1563, validation loss did not decrease \n",
            " Training loss : 0.0013638006057590246 , validation_loss : 0.001685911905951798 , Best Valid Loss : 0.001665123738348484 \n",
            " epoch : 1564, validation loss did not decrease \n",
            " Training loss : 0.0013681257842108607 , validation_loss : 0.0016878115711733699 , Best Valid Loss : 0.001665123738348484 \n",
            " epoch : 1565, validation loss did not decrease \n",
            " Training loss : 0.0013738133711740375 , validation_loss : 0.00169880292378366 , Best Valid Loss : 0.001665123738348484 \n",
            " epoch : 1566, validation loss did not decrease \n",
            " Training loss : 0.0013792352983728051 , validation_loss : 0.00169773877132684 , Best Valid Loss : 0.001665123738348484 \n",
            " epoch : 1567, validation loss did not decrease \n",
            " Training loss : 0.0013852356933057308 , validation_loss : 0.0017113802023231983 , Best Valid Loss : 0.001665123738348484 \n",
            " epoch : 1568, validation loss did not decrease \n",
            " Training loss : 0.0013909690314903855 , validation_loss : 0.0017157526453956962 , Best Valid Loss : 0.001665123738348484 \n",
            " epoch : 1569, validation loss did not decrease \n",
            " Training loss : 0.0014005876146256924 , validation_loss : 0.0017280527390539646 , Best Valid Loss : 0.001665123738348484 \n",
            " epoch : 1570, validation loss did not decrease \n",
            " Training loss : 0.0014057968510314822 , validation_loss : 0.0017282929038628936 , Best Valid Loss : 0.001665123738348484 \n",
            " epoch : 1571, validation loss did not decrease \n",
            " Training loss : 0.0014153138035908341 , validation_loss : 0.0017422164091840386 , Best Valid Loss : 0.001665123738348484 \n",
            " epoch : 1572, validation loss did not decrease \n",
            " Training loss : 0.0014185347827151418 , validation_loss : 0.001746422378346324 , Best Valid Loss : 0.001665123738348484 \n",
            " epoch : 1573, validation loss did not decrease \n",
            " Training loss : 0.001430610427632928 , validation_loss : 0.0017542053246870637 , Best Valid Loss : 0.001665123738348484 \n",
            " epoch : 1574, validation loss did not decrease \n",
            " Training loss : 0.0014300113543868065 , validation_loss : 0.0017529288306832314 , Best Valid Loss : 0.001665123738348484 \n",
            " epoch : 1575, validation loss did not decrease \n",
            " Training loss : 0.0014375689206644893 , validation_loss : 0.0017537899548187852 , Best Valid Loss : 0.001665123738348484 \n",
            " epoch : 1576, validation loss did not decrease \n",
            " Training loss : 0.0014292302075773478 , validation_loss : 0.0017421450465917587 , Best Valid Loss : 0.001665123738348484 \n",
            " epoch : 1577, validation loss did not decrease \n",
            " Training loss : 0.0014269041130319238 , validation_loss : 0.0017326298402622342 , Best Valid Loss : 0.001665123738348484 \n",
            " epoch : 1578, validation loss did not decrease \n",
            " Training loss : 0.001410669763572514 , validation_loss : 0.001710980199277401 , Best Valid Loss : 0.001665123738348484 \n",
            " epoch : 1579, validation loss did not decrease \n",
            " Training loss : 0.0013965226244181395 , validation_loss : 0.0016970232827588916 , Best Valid Loss : 0.001665123738348484 \n",
            " epoch : 1580, validation loss did not decrease \n",
            " Training loss : 0.0013783184112980962 , validation_loss : 0.0016743051819503307 , Best Valid Loss : 0.001665123738348484 \n",
            " epoch : 1581, validation loss did not decrease \n",
            " Training loss : 0.0013625400606542826 , validation_loss : 0.0016653559869155288 , Best Valid Loss : 0.001665123738348484 \n",
            " epoch : 1582, Validation loss decreased : 0.001665123738348484 --> 0.0016557470662519336 \n",
            " Training loss : 0.001350369188003242 , validation_loss : 0.0016557470662519336 , Best Valid Loss : 0.0016557470662519336 \n",
            " epoch : 1583, Validation loss decreased : 0.0016557470662519336 --> 0.0016539024654775858 \n",
            " Training loss : 0.001343467622064054 , validation_loss : 0.0016539024654775858 , Best Valid Loss : 0.0016539024654775858 \n",
            " epoch : 1584, validation loss did not decrease \n",
            " Training loss : 0.0013409220846369863 , validation_loss : 0.0016552363522350788 , Best Valid Loss : 0.0016539024654775858 \n",
            " epoch : 1585, validation loss did not decrease \n",
            " Training loss : 0.0013417829759418964 , validation_loss : 0.001656983164139092 , Best Valid Loss : 0.0016539024654775858 \n",
            " epoch : 1586, validation loss did not decrease \n",
            " Training loss : 0.0013453169958665967 , validation_loss : 0.0016659937100484967 , Best Valid Loss : 0.0016539024654775858 \n",
            " epoch : 1587, validation loss did not decrease \n",
            " Training loss : 0.001350789563730359 , validation_loss : 0.001670677331276238 , Best Valid Loss : 0.0016539024654775858 \n",
            " epoch : 1588, validation loss did not decrease \n",
            " Training loss : 0.0013585109263658524 , validation_loss : 0.0016817109426483512 , Best Valid Loss : 0.0016539024654775858 \n",
            " epoch : 1589, validation loss did not decrease \n",
            " Training loss : 0.0013646518345922232 , validation_loss : 0.0016834221314638853 , Best Valid Loss : 0.0016539024654775858 \n",
            " epoch : 1590, validation loss did not decrease \n",
            " Training loss : 0.001371028134599328 , validation_loss : 0.0016938333865255117 , Best Valid Loss : 0.0016539024654775858 \n",
            " epoch : 1591, validation loss did not decrease \n",
            " Training loss : 0.001375480554997921 , validation_loss : 0.0016972919693216681 , Best Valid Loss : 0.0016539024654775858 \n",
            " epoch : 1592, validation loss did not decrease \n",
            " Training loss : 0.0013854226563125849 , validation_loss : 0.0017129172338172793 , Best Valid Loss : 0.0016539024654775858 \n",
            " epoch : 1593, validation loss did not decrease \n",
            " Training loss : 0.0013925860403105617 , validation_loss : 0.0017208375502377748 , Best Valid Loss : 0.0016539024654775858 \n",
            " epoch : 1594, validation loss did not decrease \n",
            " Training loss : 0.0014073018683120608 , validation_loss : 0.0017381332581862807 , Best Valid Loss : 0.0016539024654775858 \n",
            " epoch : 1595, validation loss did not decrease \n",
            " Training loss : 0.0014159573474898934 , validation_loss : 0.0017555615631863475 , Best Valid Loss : 0.0016539024654775858 \n",
            " epoch : 1596, validation loss did not decrease \n",
            " Training loss : 0.0014409072464331985 , validation_loss : 0.0017784669762477279 , Best Valid Loss : 0.0016539024654775858 \n",
            " epoch : 1597, validation loss did not decrease \n",
            " Training loss : 0.0014528488973155618 , validation_loss : 0.001800457132048905 , Best Valid Loss : 0.0016539024654775858 \n",
            " epoch : 1598, validation loss did not decrease \n",
            " Training loss : 0.0014823125675320625 , validation_loss : 0.0018164138309657574 , Best Valid Loss : 0.0016539024654775858 \n",
            " epoch : 1599, validation loss did not decrease \n",
            " Training loss : 0.0014892210019752383 , validation_loss : 0.0018305097473785281 , Best Valid Loss : 0.0016539024654775858 \n",
            " epoch : 1600, validation loss did not decrease \n",
            " Training loss : 0.0015082494355738163 , validation_loss : 0.0018208535620942712 , Best Valid Loss : 0.0016539024654775858 \n",
            " epoch : 1601, validation loss did not decrease \n",
            " Training loss : 0.0014927726006135345 , validation_loss : 0.0018075602129101753 , Best Valid Loss : 0.0016539024654775858 \n",
            " epoch : 1602, validation loss did not decrease \n",
            " Training loss : 0.0014905270654708147 , validation_loss : 0.0017824940150603652 , Best Valid Loss : 0.0016539024654775858 \n",
            " epoch : 1603, validation loss did not decrease \n",
            " Training loss : 0.0014565341407433152 , validation_loss : 0.0017481653485447168 , Best Valid Loss : 0.0016539024654775858 \n",
            " epoch : 1604, validation loss did not decrease \n",
            " Training loss : 0.0014327471144497395 , validation_loss : 0.0017151882639154792 , Best Valid Loss : 0.0016539024654775858 \n",
            " epoch : 1605, validation loss did not decrease \n",
            " Training loss : 0.0013956286711618304 , validation_loss : 0.0016771071823313832 , Best Valid Loss : 0.0016539024654775858 \n",
            " epoch : 1606, validation loss did not decrease \n",
            " Training loss : 0.0013656216906383634 , validation_loss : 0.0016570307780057192 , Best Valid Loss : 0.0016539024654775858 \n",
            " epoch : 1607, Validation loss decreased : 0.0016539024654775858 --> 0.0016436385922133923 \n",
            " Training loss : 0.0013435767032206059 , validation_loss : 0.0016436385922133923 , Best Valid Loss : 0.0016436385922133923 \n",
            " epoch : 1608, validation loss did not decrease \n",
            " Training loss : 0.0013332641683518887 , validation_loss : 0.001644763513468206 , Best Valid Loss : 0.0016436385922133923 \n",
            " epoch : 1609, validation loss did not decrease \n",
            " Training loss : 0.0013342163292691112 , validation_loss : 0.0016580007504671812 , Best Valid Loss : 0.0016436385922133923 \n",
            " epoch : 1610, validation loss did not decrease \n",
            " Training loss : 0.0013443735660985112 , validation_loss : 0.0016700633568689227 , Best Valid Loss : 0.0016436385922133923 \n",
            " epoch : 1611, validation loss did not decrease \n",
            " Training loss : 0.0013587522553279996 , validation_loss : 0.0016897950554266572 , Best Valid Loss : 0.0016436385922133923 \n",
            " epoch : 1612, validation loss did not decrease \n",
            " Training loss : 0.001372799277305603 , validation_loss : 0.0016948095289990306 , Best Valid Loss : 0.0016436385922133923 \n",
            " epoch : 1613, validation loss did not decrease \n",
            " Training loss : 0.001383490627631545 , validation_loss : 0.0017035813070833683 , Best Valid Loss : 0.0016436385922133923 \n",
            " epoch : 1614, validation loss did not decrease \n",
            " Training loss : 0.0013851783005520701 , validation_loss : 0.001699591986835003 , Best Valid Loss : 0.0016436385922133923 \n",
            " epoch : 1615, validation loss did not decrease \n",
            " Training loss : 0.0013886879896745086 , validation_loss : 0.0017006911803036928 , Best Valid Loss : 0.0016436385922133923 \n",
            " epoch : 1616, validation loss did not decrease \n",
            " Training loss : 0.0013822705950587988 , validation_loss : 0.0016897349851205945 , Best Valid Loss : 0.0016436385922133923 \n",
            " epoch : 1617, validation loss did not decrease \n",
            " Training loss : 0.0013793522957712412 , validation_loss : 0.001687806099653244 , Best Valid Loss : 0.0016436385922133923 \n",
            " epoch : 1618, validation loss did not decrease \n",
            " Training loss : 0.0013706778408959508 , validation_loss : 0.001676460262387991 , Best Valid Loss : 0.0016436385922133923 \n",
            " epoch : 1619, validation loss did not decrease \n",
            " Training loss : 0.001365701318718493 , validation_loss : 0.0016730750212445855 , Best Valid Loss : 0.0016436385922133923 \n",
            " epoch : 1620, validation loss did not decrease \n",
            " Training loss : 0.0013572982279583812 , validation_loss : 0.0016600171802565455 , Best Valid Loss : 0.0016436385922133923 \n",
            " epoch : 1621, validation loss did not decrease \n",
            " Training loss : 0.0013493122532963753 , validation_loss : 0.0016543293604627252 , Best Valid Loss : 0.0016436385922133923 \n",
            " epoch : 1622, Validation loss decreased : 0.0016436385922133923 --> 0.0016435732832178473 \n",
            " Training loss : 0.00134049984626472 , validation_loss : 0.0016435732832178473 , Best Valid Loss : 0.0016435732832178473 \n",
            " epoch : 1623, Validation loss decreased : 0.0016435732832178473 --> 0.0016406741924583912 \n",
            " Training loss : 0.0013331181835383177 , validation_loss : 0.0016406741924583912 , Best Valid Loss : 0.0016406741924583912 \n",
            " epoch : 1624, Validation loss decreased : 0.0016406741924583912 --> 0.0016362940659746528 \n",
            " Training loss : 0.001328547834418714 , validation_loss : 0.0016362940659746528 , Best Valid Loss : 0.0016362940659746528 \n",
            " epoch : 1625, Validation loss decreased : 0.0016362940659746528 --> 0.0016353751998394728 \n",
            " Training loss : 0.0013258347753435373 , validation_loss : 0.0016353751998394728 , Best Valid Loss : 0.0016353751998394728 \n",
            " epoch : 1626, Validation loss decreased : 0.0016353751998394728 --> 0.0016351020894944668 \n",
            " Training loss : 0.0013245005393400788 , validation_loss : 0.0016351020894944668 , Best Valid Loss : 0.0016351020894944668 \n",
            " epoch : 1627, Validation loss decreased : 0.0016351020894944668 --> 0.0016349824145436287 \n",
            " Training loss : 0.0013241355773061514 , validation_loss : 0.0016349824145436287 , Best Valid Loss : 0.0016349824145436287 \n",
            " epoch : 1628, validation loss did not decrease \n",
            " Training loss : 0.0013244517613202333 , validation_loss : 0.001636768109165132 , Best Valid Loss : 0.0016349824145436287 \n",
            " epoch : 1629, validation loss did not decrease \n",
            " Training loss : 0.0013252797070890665 , validation_loss : 0.00163654750213027 , Best Valid Loss : 0.0016349824145436287 \n",
            " epoch : 1630, validation loss did not decrease \n",
            " Training loss : 0.0013267208123579621 , validation_loss : 0.001640991889871657 , Best Valid Loss : 0.0016349824145436287 \n",
            " epoch : 1631, validation loss did not decrease \n",
            " Training loss : 0.0013290871866047382 , validation_loss : 0.0016424980713054538 , Best Valid Loss : 0.0016349824145436287 \n",
            " epoch : 1632, validation loss did not decrease \n",
            " Training loss : 0.0013330295914784074 , validation_loss : 0.0016517118783667684 , Best Valid Loss : 0.0016349824145436287 \n",
            " epoch : 1633, validation loss did not decrease \n",
            " Training loss : 0.0013387633953243494 , validation_loss : 0.0016568141290917993 , Best Valid Loss : 0.0016349824145436287 \n",
            " epoch : 1634, validation loss did not decrease \n",
            " Training loss : 0.001347043551504612 , validation_loss : 0.0016696135280653834 , Best Valid Loss : 0.0016349824145436287 \n",
            " epoch : 1635, validation loss did not decrease \n",
            " Training loss : 0.001354945357888937 , validation_loss : 0.0016780048608779907 , Best Valid Loss : 0.0016349824145436287 \n",
            " epoch : 1636, validation loss did not decrease \n",
            " Training loss : 0.001367649412713945 , validation_loss : 0.0016981431981548667 , Best Valid Loss : 0.0016349824145436287 \n",
            " epoch : 1637, validation loss did not decrease \n",
            " Training loss : 0.0013812027173116803 , validation_loss : 0.0017096784431487322 , Best Valid Loss : 0.0016349824145436287 \n",
            " epoch : 1638, validation loss did not decrease \n",
            " Training loss : 0.0013961214572191238 , validation_loss : 0.0017246240749955177 , Best Valid Loss : 0.0016349824145436287 \n",
            " epoch : 1639, validation loss did not decrease \n",
            " Training loss : 0.0014056341024115682 , validation_loss : 0.0017353252042084932 , Best Valid Loss : 0.0016349824145436287 \n",
            " epoch : 1640, validation loss did not decrease \n",
            " Training loss : 0.0014220153680071235 , validation_loss : 0.001750748255290091 , Best Valid Loss : 0.0016349824145436287 \n",
            " epoch : 1641, validation loss did not decrease \n",
            " Training loss : 0.0014295446453616023 , validation_loss : 0.0017670715460553765 , Best Valid Loss : 0.0016349824145436287 \n",
            " epoch : 1642, validation loss did not decrease \n",
            " Training loss : 0.0014509606407955289 , validation_loss : 0.0017760221380740404 , Best Valid Loss : 0.0016349824145436287 \n",
            " epoch : 1643, validation loss did not decrease \n",
            " Training loss : 0.0014537698589265347 , validation_loss : 0.0017789175035431981 , Best Valid Loss : 0.0016349824145436287 \n",
            " epoch : 1644, validation loss did not decrease \n",
            " Training loss : 0.0014603766612708569 , validation_loss : 0.0017625187756493688 , Best Valid Loss : 0.0016349824145436287 \n",
            " epoch : 1645, validation loss did not decrease \n",
            " Training loss : 0.0014411514857783914 , validation_loss : 0.0017479292582720518 , Best Valid Loss : 0.0016349824145436287 \n",
            " epoch : 1646, validation loss did not decrease \n",
            " Training loss : 0.0014357049949467182 , validation_loss : 0.0017280674073845148 , Best Valid Loss : 0.0016349824145436287 \n",
            " epoch : 1647, validation loss did not decrease \n",
            " Training loss : 0.0014086153823882341 , validation_loss : 0.0017011839663609862 , Best Valid Loss : 0.0016349824145436287 \n",
            " epoch : 1648, validation loss did not decrease \n",
            " Training loss : 0.0013892992865294218 , validation_loss : 0.0016751040238887072 , Best Valid Loss : 0.0016349824145436287 \n",
            " epoch : 1649, validation loss did not decrease \n",
            " Training loss : 0.0013607055880129337 , validation_loss : 0.001645625103265047 , Best Valid Loss : 0.0016349824145436287 \n",
            " epoch : 1650, Validation loss decreased : 0.0016349824145436287 --> 0.001631421153433621 \n",
            " Training loss : 0.001337120309472084 , validation_loss : 0.001631421153433621 , Best Valid Loss : 0.001631421153433621 \n",
            " epoch : 1651, Validation loss decreased : 0.001631421153433621 --> 0.0016229513566941023 \n",
            " Training loss : 0.0013218665262684226 , validation_loss : 0.0016229513566941023 , Best Valid Loss : 0.0016229513566941023 \n",
            " epoch : 1652, validation loss did not decrease \n",
            " Training loss : 0.001315470552071929 , validation_loss : 0.0016240320401266217 , Best Valid Loss : 0.0016229513566941023 \n",
            " epoch : 1653, validation loss did not decrease \n",
            " Training loss : 0.001316225971095264 , validation_loss : 0.0016322085866704583 , Best Valid Loss : 0.0016229513566941023 \n",
            " epoch : 1654, validation loss did not decrease \n",
            " Training loss : 0.0013223252026364207 , validation_loss : 0.0016376941930502653 , Best Valid Loss : 0.0016229513566941023 \n",
            " epoch : 1655, validation loss did not decrease \n",
            " Training loss : 0.001329487538896501 , validation_loss : 0.0016496058087795973 , Best Valid Loss : 0.0016229513566941023 \n",
            " epoch : 1656, validation loss did not decrease \n",
            " Training loss : 0.0013376702554523945 , validation_loss : 0.001652908744290471 , Best Valid Loss : 0.0016229513566941023 \n",
            " epoch : 1657, validation loss did not decrease \n",
            " Training loss : 0.0013449877733364701 , validation_loss : 0.0016601078677922487 , Best Valid Loss : 0.0016229513566941023 \n",
            " epoch : 1658, validation loss did not decrease \n",
            " Training loss : 0.0013469255063682795 , validation_loss : 0.001656960230320692 , Best Valid Loss : 0.0016229513566941023 \n",
            " epoch : 1659, validation loss did not decrease \n",
            " Training loss : 0.0013476351741701365 , validation_loss : 0.0016579178627580404 , Best Valid Loss : 0.0016229513566941023 \n",
            " epoch : 1660, validation loss did not decrease \n",
            " Training loss : 0.0013448904501274228 , validation_loss : 0.0016513188602402806 , Best Valid Loss : 0.0016229513566941023 \n",
            " epoch : 1661, validation loss did not decrease \n",
            " Training loss : 0.0013433137210085988 , validation_loss : 0.0016525069950148463 , Best Valid Loss : 0.0016229513566941023 \n",
            " epoch : 1662, validation loss did not decrease \n",
            " Training loss : 0.0013400084571912885 , validation_loss : 0.0016450021648779511 , Best Valid Loss : 0.0016229513566941023 \n",
            " epoch : 1663, validation loss did not decrease \n",
            " Training loss : 0.0013361633755266666 , validation_loss : 0.0016414516139775515 , Best Valid Loss : 0.0016229513566941023 \n",
            " epoch : 1664, validation loss did not decrease \n",
            " Training loss : 0.0013302401639521122 , validation_loss : 0.0016331375809386373 , Best Valid Loss : 0.0016229513566941023 \n",
            " epoch : 1665, validation loss did not decrease \n",
            " Training loss : 0.001325803343206644 , validation_loss : 0.0016319714486598969 , Best Valid Loss : 0.0016229513566941023 \n",
            " epoch : 1666, validation loss did not decrease \n",
            " Training loss : 0.0013217031955718994 , validation_loss : 0.0016256007365882397 , Best Valid Loss : 0.0016229513566941023 \n",
            " epoch : 1667, validation loss did not decrease \n",
            " Training loss : 0.001317417249083519 , validation_loss : 0.001623261603526771 , Best Valid Loss : 0.0016229513566941023 \n",
            " epoch : 1668, Validation loss decreased : 0.0016229513566941023 --> 0.0016183641273528337 \n",
            " Training loss : 0.0013138782232999802 , validation_loss : 0.0016183641273528337 , Best Valid Loss : 0.0016183641273528337 \n",
            " epoch : 1669, Validation loss decreased : 0.0016183641273528337 --> 0.001616915687918663 \n",
            " Training loss : 0.0013108570128679276 , validation_loss : 0.001616915687918663 , Best Valid Loss : 0.001616915687918663 \n",
            " epoch : 1670, Validation loss decreased : 0.001616915687918663 --> 0.001615088083781302 \n",
            " Training loss : 0.001308901933953166 , validation_loss : 0.001615088083781302 , Best Valid Loss : 0.001615088083781302 \n",
            " epoch : 1671, Validation loss decreased : 0.001615088083781302 --> 0.0016148100839927793 \n",
            " Training loss : 0.0013076241593807936 , validation_loss : 0.0016148100839927793 , Best Valid Loss : 0.0016148100839927793 \n",
            " epoch : 1672, Validation loss decreased : 0.0016148100839927793 --> 0.0016144785331562161 \n",
            " Training loss : 0.001306961989030242 , validation_loss : 0.0016144785331562161 , Best Valid Loss : 0.0016144785331562161 \n",
            " epoch : 1673, Validation loss decreased : 0.0016144785331562161 --> 0.0016138965729624033 \n",
            " Training loss : 0.001306680729612708 , validation_loss : 0.0016138965729624033 , Best Valid Loss : 0.0016138965729624033 \n",
            " epoch : 1674, validation loss did not decrease \n",
            " Training loss : 0.0013066960964351892 , validation_loss : 0.00161473557818681 , Best Valid Loss : 0.0016138965729624033 \n",
            " epoch : 1675, validation loss did not decrease \n",
            " Training loss : 0.0013069455744698644 , validation_loss : 0.0016147253336384892 , Best Valid Loss : 0.0016138965729624033 \n",
            " epoch : 1676, validation loss did not decrease \n",
            " Training loss : 0.0013073899317532778 , validation_loss : 0.0016166312852874398 , Best Valid Loss : 0.0016138965729624033 \n",
            " epoch : 1677, validation loss did not decrease \n",
            " Training loss : 0.00130820507183671 , validation_loss : 0.0016165064880624413 , Best Valid Loss : 0.0016138965729624033 \n",
            " epoch : 1678, validation loss did not decrease \n",
            " Training loss : 0.001309346640482545 , validation_loss : 0.0016198877710849047 , Best Valid Loss : 0.0016138965729624033 \n",
            " epoch : 1679, validation loss did not decrease \n",
            " Training loss : 0.001311176223680377 , validation_loss : 0.0016209435416385531 , Best Valid Loss : 0.0016138965729624033 \n",
            " epoch : 1680, validation loss did not decrease \n",
            " Training loss : 0.00131404644344002 , validation_loss : 0.001629295526072383 , Best Valid Loss : 0.0016138965729624033 \n",
            " epoch : 1681, validation loss did not decrease \n",
            " Training loss : 0.0013197717489674687 , validation_loss : 0.0016367279458791018 , Best Valid Loss : 0.0016138965729624033 \n",
            " epoch : 1682, validation loss did not decrease \n",
            " Training loss : 0.0013293258380144835 , validation_loss : 0.001654630177654326 , Best Valid Loss : 0.0016138965729624033 \n",
            " epoch : 1683, validation loss did not decrease \n",
            " Training loss : 0.0013428378151729703 , validation_loss : 0.0016735189128667116 , Best Valid Loss : 0.0016138965729624033 \n",
            " epoch : 1684, validation loss did not decrease \n",
            " Training loss : 0.0013646119041368365 , validation_loss : 0.0017032549949362874 , Best Valid Loss : 0.0016138965729624033 \n",
            " epoch : 1685, validation loss did not decrease \n",
            " Training loss : 0.0013879573671147227 , validation_loss : 0.001738915452733636 , Best Valid Loss : 0.0016138965729624033 \n",
            " epoch : 1686, validation loss did not decrease \n",
            " Training loss : 0.0014248975785449147 , validation_loss : 0.0017774327425286174 , Best Valid Loss : 0.0016138965729624033 \n",
            " epoch : 1687, validation loss did not decrease \n",
            " Training loss : 0.0014568250626325607 , validation_loss : 0.0018304353579878807 , Best Valid Loss : 0.0016138965729624033 \n",
            " epoch : 1688, validation loss did not decrease \n",
            " Training loss : 0.0015102667966857553 , validation_loss : 0.0018489250214770436 , Best Valid Loss : 0.0016138965729624033 \n",
            " epoch : 1689, validation loss did not decrease \n",
            " Training loss : 0.0015224727103486657 , validation_loss : 0.0018877185648307204 , Best Valid Loss : 0.0016138965729624033 \n",
            " epoch : 1690, validation loss did not decrease \n",
            " Training loss : 0.0015632616123184562 , validation_loss : 0.0018498400459066033 , Best Valid Loss : 0.0016138965729624033 \n",
            " epoch : 1691, validation loss did not decrease \n",
            " Training loss : 0.0015235021710395813 , validation_loss : 0.0018263335805386305 , Best Valid Loss : 0.0016138965729624033 \n",
            " epoch : 1692, validation loss did not decrease \n",
            " Training loss : 0.0015059721190482378 , validation_loss : 0.001752789132297039 , Best Valid Loss : 0.0016138965729624033 \n",
            " epoch : 1693, validation loss did not decrease \n",
            " Training loss : 0.0014328882098197937 , validation_loss : 0.0016866427613422275 , Best Valid Loss : 0.0016138965729624033 \n",
            " epoch : 1694, validation loss did not decrease \n",
            " Training loss : 0.0013774822000414133 , validation_loss : 0.0016383571783080697 , Best Valid Loss : 0.0016138965729624033 \n",
            " epoch : 1695, Validation loss decreased : 0.0016138965729624033 --> 0.0016086496179923415 \n",
            " Training loss : 0.00132844690233469 , validation_loss : 0.0016086496179923415 , Best Valid Loss : 0.0016086496179923415 \n",
            " epoch : 1696, Validation loss decreased : 0.0016086496179923415 --> 0.001605996279977262 \n",
            " Training loss : 0.0013037384487688541 , validation_loss : 0.001605996279977262 , Best Valid Loss : 0.001605996279977262 \n",
            " epoch : 1697, validation loss did not decrease \n",
            " Training loss : 0.0013011754490435123 , validation_loss : 0.0016216890653595328 , Best Valid Loss : 0.001605996279977262 \n",
            " epoch : 1698, validation loss did not decrease \n",
            " Training loss : 0.001314014894887805 , validation_loss : 0.0016413312405347824 , Best Valid Loss : 0.001605996279977262 \n",
            " epoch : 1699, validation loss did not decrease \n",
            " Training loss : 0.0013353009708225727 , validation_loss : 0.001662811147980392 , Best Valid Loss : 0.001605996279977262 \n",
            " epoch : 1700, validation loss did not decrease \n",
            " Training loss : 0.001351478393189609 , validation_loss : 0.0016686847666278481 , Best Valid Loss : 0.001605996279977262 \n",
            " epoch : 1701, validation loss did not decrease \n",
            " Training loss : 0.0013602218823507428 , validation_loss : 0.0016625846037641168 , Best Valid Loss : 0.001605996279977262 \n",
            " epoch : 1702, validation loss did not decrease \n",
            " Training loss : 0.001350852893665433 , validation_loss : 0.001643323921598494 , Best Valid Loss : 0.001605996279977262 \n",
            " epoch : 1703, validation loss did not decrease \n",
            " Training loss : 0.0013377497671172023 , validation_loss : 0.0016297578113153577 , Best Valid Loss : 0.001605996279977262 \n",
            " epoch : 1704, validation loss did not decrease \n",
            " Training loss : 0.0013207443989813328 , validation_loss : 0.0016122852684929967 , Best Valid Loss : 0.001605996279977262 \n",
            " epoch : 1705, Validation loss decreased : 0.001605996279977262 --> 0.001604487537406385 \n",
            " Training loss : 0.001307284808717668 , validation_loss : 0.001604487537406385 , Best Valid Loss : 0.001604487537406385 \n",
            " epoch : 1706, Validation loss decreased : 0.001604487537406385 --> 0.0015994033310562372 \n",
            " Training loss : 0.0012981643667444587 , validation_loss : 0.0015994033310562372 , Best Valid Loss : 0.0015994033310562372 \n",
            " epoch : 1707, validation loss did not decrease \n",
            " Training loss : 0.0012945054331794381 , validation_loss : 0.001599672483280301 , Best Valid Loss : 0.0015994033310562372 \n",
            " epoch : 1708, validation loss did not decrease \n",
            " Training loss : 0.0012944950722157955 , validation_loss : 0.001603481126949191 , Best Valid Loss : 0.0015994033310562372 \n",
            " epoch : 1709, validation loss did not decrease \n",
            " Training loss : 0.0012970772804692388 , validation_loss : 0.001607437850907445 , Best Valid Loss : 0.0015994033310562372 \n",
            " epoch : 1710, validation loss did not decrease \n",
            " Training loss : 0.0013028433313593268 , validation_loss : 0.0016187469009310007 , Best Valid Loss : 0.0015994033310562372 \n",
            " epoch : 1711, validation loss did not decrease \n",
            " Training loss : 0.0013106991536915302 , validation_loss : 0.0016265277517959476 , Best Valid Loss : 0.0015994033310562372 \n",
            " epoch : 1712, validation loss did not decrease \n",
            " Training loss : 0.0013208569725975394 , validation_loss : 0.001645364216528833 , Best Valid Loss : 0.0015994033310562372 \n",
            " epoch : 1713, validation loss did not decrease \n",
            " Training loss : 0.0013351902598515153 , validation_loss : 0.0016572540625929832 , Best Valid Loss : 0.0015994033310562372 \n",
            " epoch : 1714, validation loss did not decrease \n",
            " Training loss : 0.0013499025953933597 , validation_loss : 0.0016711953794583678 , Best Valid Loss : 0.0015994033310562372 \n",
            " epoch : 1715, validation loss did not decrease \n",
            " Training loss : 0.0013586926506832242 , validation_loss : 0.0016756684053689241 , Best Valid Loss : 0.0015994033310562372 \n",
            " epoch : 1716, validation loss did not decrease \n",
            " Training loss : 0.0013678427785634995 , validation_loss : 0.0016799108125269413 , Best Valid Loss : 0.0015994033310562372 \n",
            " epoch : 1717, validation loss did not decrease \n",
            " Training loss : 0.0013679451076313853 , validation_loss : 0.0016782507300376892 , Best Valid Loss : 0.0015994033310562372 \n",
            " epoch : 1718, validation loss did not decrease \n",
            " Training loss : 0.0013676092494279146 , validation_loss : 0.0016683960566297174 , Best Valid Loss : 0.0015994033310562372 \n",
            " epoch : 1719, validation loss did not decrease \n",
            " Training loss : 0.0013576500350609422 , validation_loss : 0.0016514218878000975 , Best Valid Loss : 0.0015994033310562372 \n",
            " epoch : 1720, validation loss did not decrease \n",
            " Training loss : 0.0013442103518173099 , validation_loss : 0.0016365242190659046 , Best Valid Loss : 0.0015994033310562372 \n",
            " epoch : 1721, validation loss did not decrease \n",
            " Training loss : 0.0013281955616548657 , validation_loss : 0.0016182694816961884 , Best Valid Loss : 0.0015994033310562372 \n",
            " epoch : 1722, validation loss did not decrease \n",
            " Training loss : 0.0013130359584465623 , validation_loss : 0.001608130638487637 , Best Valid Loss : 0.0015994033310562372 \n",
            " epoch : 1723, Validation loss decreased : 0.0015994033310562372 --> 0.0015982550103217363 \n",
            " Training loss : 0.0013017224846407771 , validation_loss : 0.0015982550103217363 , Best Valid Loss : 0.0015982550103217363 \n",
            " epoch : 1724, Validation loss decreased : 0.0015982550103217363 --> 0.0015951498644426465 \n",
            " Training loss : 0.0012949189404025674 , validation_loss : 0.0015951498644426465 , Best Valid Loss : 0.0015951498644426465 \n",
            " epoch : 1725, Validation loss decreased : 0.0015951498644426465 --> 0.0015925245825201273 \n",
            " Training loss : 0.0012902389280498028 , validation_loss : 0.0015925245825201273 , Best Valid Loss : 0.0015925245825201273 \n",
            " epoch : 1726, Validation loss decreased : 0.0015925245825201273 --> 0.0015918557764962316 \n",
            " Training loss : 0.0012878660345450044 , validation_loss : 0.0015918557764962316 , Best Valid Loss : 0.0015918557764962316 \n",
            " epoch : 1727, validation loss did not decrease \n",
            " Training loss : 0.0012872995575889945 , validation_loss : 0.0015926529886201024 , Best Valid Loss : 0.0015918557764962316 \n",
            " epoch : 1728, validation loss did not decrease \n",
            " Training loss : 0.0012880670838057995 , validation_loss : 0.0015936235431581736 , Best Valid Loss : 0.0015918557764962316 \n",
            " epoch : 1729, validation loss did not decrease \n",
            " Training loss : 0.0012900198344141245 , validation_loss : 0.0015980472089722753 , Best Valid Loss : 0.0015918557764962316 \n",
            " epoch : 1730, validation loss did not decrease \n",
            " Training loss : 0.0012927015777677298 , validation_loss : 0.001600848394446075 , Best Valid Loss : 0.0015918557764962316 \n",
            " epoch : 1731, validation loss did not decrease \n",
            " Training loss : 0.0012961147585883737 , validation_loss : 0.0016064976807683706 , Best Valid Loss : 0.0015918557764962316 \n",
            " epoch : 1732, validation loss did not decrease \n",
            " Training loss : 0.001300281728617847 , validation_loss : 0.001610000734217465 , Best Valid Loss : 0.0015918557764962316 \n",
            " epoch : 1733, validation loss did not decrease \n",
            " Training loss : 0.0013071647845208645 , validation_loss : 0.0016235342482104897 , Best Valid Loss : 0.0015918557764962316 \n",
            " epoch : 1734, validation loss did not decrease \n",
            " Training loss : 0.0013158416841179132 , validation_loss : 0.0016309352358803153 , Best Valid Loss : 0.0015918557764962316 \n",
            " epoch : 1735, validation loss did not decrease \n",
            " Training loss : 0.0013244397705420852 , validation_loss : 0.0016419158782809973 , Best Valid Loss : 0.0015918557764962316 \n",
            " epoch : 1736, validation loss did not decrease \n",
            " Training loss : 0.0013329604407772422 , validation_loss : 0.0016471886774525046 , Best Valid Loss : 0.0015918557764962316 \n",
            " epoch : 1737, validation loss did not decrease \n",
            " Training loss : 0.0013421650510281324 , validation_loss : 0.001655997708439827 , Best Valid Loss : 0.0015918557764962316 \n",
            " epoch : 1738, validation loss did not decrease \n",
            " Training loss : 0.0013457646127790213 , validation_loss : 0.0016599847003817558 , Best Valid Loss : 0.0015918557764962316 \n",
            " epoch : 1739, validation loss did not decrease \n",
            " Training loss : 0.0013520359061658382 , validation_loss : 0.001658806810155511 , Best Valid Loss : 0.0015918557764962316 \n",
            " epoch : 1740, validation loss did not decrease \n",
            " Training loss : 0.0013491034042090178 , validation_loss : 0.0016548414714634418 , Best Valid Loss : 0.0015918557764962316 \n",
            " epoch : 1741, validation loss did not decrease \n",
            " Training loss : 0.0013481435598805547 , validation_loss : 0.0016491259448230267 , Best Valid Loss : 0.0015918557764962316 \n",
            " epoch : 1742, validation loss did not decrease \n",
            " Training loss : 0.0013394374400377274 , validation_loss : 0.001639858353883028 , Best Valid Loss : 0.0015918557764962316 \n",
            " epoch : 1743, validation loss did not decrease \n",
            " Training loss : 0.0013343156315386295 , validation_loss : 0.001632858533412218 , Best Valid Loss : 0.0015918557764962316 \n",
            " epoch : 1744, validation loss did not decrease \n",
            " Training loss : 0.0013246433809399605 , validation_loss : 0.001620326191186905 , Best Valid Loss : 0.0015918557764962316 \n",
            " epoch : 1745, validation loss did not decrease \n",
            " Training loss : 0.0013148451689630747 , validation_loss : 0.0016121905064210296 , Best Valid Loss : 0.0015918557764962316 \n",
            " epoch : 1746, validation loss did not decrease \n",
            " Training loss : 0.0013057230971753597 , validation_loss : 0.0016002921620383859 , Best Valid Loss : 0.0015918557764962316 \n",
            " epoch : 1747, validation loss did not decrease \n",
            " Training loss : 0.0012975288555026054 , validation_loss : 0.0015950448578223586 , Best Valid Loss : 0.0015918557764962316 \n",
            " epoch : 1748, Validation loss decreased : 0.0015918557764962316 --> 0.0015889875357970595 \n",
            " Training loss : 0.0012903616297990084 , validation_loss : 0.0015889875357970595 , Best Valid Loss : 0.0015889875357970595 \n",
            " epoch : 1749, Validation loss decreased : 0.0015889875357970595 --> 0.0015863538719713688 \n",
            " Training loss : 0.0012858647387474775 , validation_loss : 0.0015863538719713688 , Best Valid Loss : 0.0015863538719713688 \n",
            " epoch : 1750, Validation loss decreased : 0.0015863538719713688 --> 0.0015831377822905779 \n",
            " Training loss : 0.0012826287420466542 , validation_loss : 0.0015831377822905779 , Best Valid Loss : 0.0015831377822905779 \n",
            " epoch : 1751, Validation loss decreased : 0.0015831377822905779 --> 0.001582471071742475 \n",
            " Training loss : 0.0012807936873286963 , validation_loss : 0.001582471071742475 , Best Valid Loss : 0.001582471071742475 \n",
            " epoch : 1752, Validation loss decreased : 0.001582471071742475 --> 0.0015813341597095132 \n",
            " Training loss : 0.0012792330235242844 , validation_loss : 0.0015813341597095132 , Best Valid Loss : 0.0015813341597095132 \n",
            " epoch : 1753, Validation loss decreased : 0.0015813341597095132 --> 0.0015808222815394402 \n",
            " Training loss : 0.0012783525744453073 , validation_loss : 0.0015808222815394402 , Best Valid Loss : 0.0015808222815394402 \n",
            " epoch : 1754, Validation loss decreased : 0.0015808222815394402 --> 0.0015795977087691426 \n",
            " Training loss : 0.0012775635113939643 , validation_loss : 0.0015795977087691426 , Best Valid Loss : 0.0015795977087691426 \n",
            " epoch : 1755, Validation loss decreased : 0.0015795977087691426 --> 0.0015794284408912063 \n",
            " Training loss : 0.001277160132303834 , validation_loss : 0.0015794284408912063 , Best Valid Loss : 0.0015794284408912063 \n",
            " epoch : 1756, Validation loss decreased : 0.0015794284408912063 --> 0.0015793332131579518 \n",
            " Training loss : 0.0012766873696818948 , validation_loss : 0.0015793332131579518 , Best Valid Loss : 0.0015793332131579518 \n",
            " epoch : 1757, Validation loss decreased : 0.0015793332131579518 --> 0.001578914700075984 \n",
            " Training loss : 0.001276251277886331 , validation_loss : 0.001578914700075984 , Best Valid Loss : 0.001578914700075984 \n",
            " epoch : 1758, Validation loss decreased : 0.001578914700075984 --> 0.0015775405336171389 \n",
            " Training loss : 0.0012759200762957335 , validation_loss : 0.0015775405336171389 , Best Valid Loss : 0.0015775405336171389 \n",
            " epoch : 1759, validation loss did not decrease \n",
            " Training loss : 0.0012756630312651396 , validation_loss : 0.001577863935381174 , Best Valid Loss : 0.0015775405336171389 \n",
            " epoch : 1760, validation loss did not decrease \n",
            " Training loss : 0.0012753983028233051 , validation_loss : 0.0015783557901158929 , Best Valid Loss : 0.0015775405336171389 \n",
            " epoch : 1761, validation loss did not decrease \n",
            " Training loss : 0.001275682938285172 , validation_loss : 0.0015798789681866765 , Best Valid Loss : 0.0015775405336171389 \n",
            " epoch : 1762, validation loss did not decrease \n",
            " Training loss : 0.0012766766594722867 , validation_loss : 0.0015806902665644884 , Best Valid Loss : 0.0015775405336171389 \n",
            " epoch : 1763, validation loss did not decrease \n",
            " Training loss : 0.001279057702049613 , validation_loss : 0.0015875089447945356 , Best Valid Loss : 0.0015775405336171389 \n",
            " epoch : 1764, validation loss did not decrease \n",
            " Training loss : 0.0012838348047807813 , validation_loss : 0.0015965828206390142 , Best Valid Loss : 0.0015775405336171389 \n",
            " epoch : 1765, validation loss did not decrease \n",
            " Training loss : 0.001293829409405589 , validation_loss : 0.0016136885387822986 , Best Valid Loss : 0.0015775405336171389 \n",
            " epoch : 1766, validation loss did not decrease \n",
            " Training loss : 0.0013083083322271705 , validation_loss : 0.0016370067605748773 , Best Valid Loss : 0.0015775405336171389 \n",
            " epoch : 1767, validation loss did not decrease \n",
            " Training loss : 0.0013319598510861397 , validation_loss : 0.0016687080496922135 , Best Valid Loss : 0.0015775405336171389 \n",
            " epoch : 1768, validation loss did not decrease \n",
            " Training loss : 0.0013595306081697345 , validation_loss : 0.0017211663071066141 , Best Valid Loss : 0.0015775405336171389 \n",
            " epoch : 1769, validation loss did not decrease \n",
            " Training loss : 0.0014099790714681149 , validation_loss : 0.00176794093567878 , Best Valid Loss : 0.0015775405336171389 \n",
            " epoch : 1770, validation loss did not decrease \n",
            " Training loss : 0.0014532170025631785 , validation_loss : 0.0018393946811556816 , Best Valid Loss : 0.0015775405336171389 \n",
            " epoch : 1771, validation loss did not decrease \n",
            " Training loss : 0.0015149337705224752 , validation_loss : 0.00183075328823179 , Best Valid Loss : 0.0015775405336171389 \n",
            " epoch : 1772, validation loss did not decrease \n",
            " Training loss : 0.001510251546278596 , validation_loss : 0.001850215601734817 , Best Valid Loss : 0.0015775405336171389 \n",
            " epoch : 1773, validation loss did not decrease \n",
            " Training loss : 0.0015303799882531166 , validation_loss : 0.001790974522009492 , Best Valid Loss : 0.0015775405336171389 \n",
            " epoch : 1774, validation loss did not decrease \n",
            " Training loss : 0.0014739561593160033 , validation_loss : 0.0017514682840555906 , Best Valid Loss : 0.0015775405336171389 \n",
            " epoch : 1775, validation loss did not decrease \n",
            " Training loss : 0.0014348889235407114 , validation_loss : 0.0016706526512280107 , Best Valid Loss : 0.0015775405336171389 \n",
            " epoch : 1776, validation loss did not decrease \n",
            " Training loss : 0.001361312810331583 , validation_loss : 0.001608812715858221 , Best Valid Loss : 0.0015775405336171389 \n",
            " epoch : 1777, validation loss did not decrease \n",
            " Training loss : 0.0013080883072689176 , validation_loss : 0.0015787839656695724 , Best Valid Loss : 0.0015775405336171389 \n",
            " epoch : 1778, Validation loss decreased : 0.0015775405336171389 --> 0.0015717016067355871 \n",
            " Training loss : 0.0012775526847690344 , validation_loss : 0.0015717016067355871 , Best Valid Loss : 0.0015717016067355871 \n",
            " epoch : 1779, validation loss did not decrease \n",
            " Training loss : 0.0012712591560557485 , validation_loss : 0.001583010540343821 , Best Valid Loss : 0.0015717016067355871 \n",
            " epoch : 1780, validation loss did not decrease \n",
            " Training loss : 0.001282842829823494 , validation_loss : 0.0016076872125267982 , Best Valid Loss : 0.0015717016067355871 \n",
            " epoch : 1781, validation loss did not decrease \n",
            " Training loss : 0.0013039754703640938 , validation_loss : 0.0016328199999406934 , Best Valid Loss : 0.0015717016067355871 \n",
            " epoch : 1782, validation loss did not decrease \n",
            " Training loss : 0.001329587772488594 , validation_loss : 0.0016484190709888935 , Best Valid Loss : 0.0015717016067355871 \n",
            " epoch : 1783, validation loss did not decrease \n",
            " Training loss : 0.0013414757559075952 , validation_loss : 0.0016513734590262175 , Best Valid Loss : 0.0015717016067355871 \n",
            " epoch : 1784, validation loss did not decrease \n",
            " Training loss : 0.0013450939441099763 , validation_loss : 0.001634460175409913 , Best Valid Loss : 0.0015717016067355871 \n",
            " epoch : 1785, validation loss did not decrease \n",
            " Training loss : 0.0013280464336276054 , validation_loss : 0.0016098575433716178 , Best Valid Loss : 0.0015717016067355871 \n",
            " epoch : 1786, validation loss did not decrease \n",
            " Training loss : 0.0013087268453091383 , validation_loss : 0.001591990701854229 , Best Valid Loss : 0.0015717016067355871 \n",
            " epoch : 1787, validation loss did not decrease \n",
            " Training loss : 0.0012890849029645324 , validation_loss : 0.0015753128100186586 , Best Valid Loss : 0.0015717016067355871 \n",
            " epoch : 1788, Validation loss decreased : 0.0015717016067355871 --> 0.0015677385963499546 \n",
            " Training loss : 0.001275017624720931 , validation_loss : 0.0015677385963499546 , Best Valid Loss : 0.0015677385963499546 \n",
            " epoch : 1789, Validation loss decreased : 0.0015677385963499546 --> 0.0015662882942706347 \n",
            " Training loss : 0.001267333165742457 , validation_loss : 0.0015662882942706347 , Best Valid Loss : 0.0015662882942706347 \n",
            " epoch : 1790, validation loss did not decrease \n",
            " Training loss : 0.0012662236113101244 , validation_loss : 0.0015698678325861692 , Best Valid Loss : 0.0015662882942706347 \n",
            " epoch : 1791, validation loss did not decrease \n",
            " Training loss : 0.0012698841746896505 , validation_loss : 0.001577385002747178 , Best Valid Loss : 0.0015662882942706347 \n",
            " epoch : 1792, validation loss did not decrease \n",
            " Training loss : 0.0012762305559590459 , validation_loss : 0.0015865219756960869 , Best Valid Loss : 0.0015662882942706347 \n",
            " epoch : 1793, validation loss did not decrease \n",
            " Training loss : 0.001286868005990982 , validation_loss : 0.0016042378265410662 , Best Valid Loss : 0.0015662882942706347 \n",
            " epoch : 1794, validation loss did not decrease \n",
            " Training loss : 0.0013009414542466402 , validation_loss : 0.001618941780179739 , Best Valid Loss : 0.0015662882942706347 \n",
            " epoch : 1795, validation loss did not decrease \n",
            " Training loss : 0.0013152481988072395 , validation_loss : 0.0016300594434142113 , Best Valid Loss : 0.0015662882942706347 \n",
            " epoch : 1796, validation loss did not decrease \n",
            " Training loss : 0.0013248103205114603 , validation_loss : 0.0016345216426998377 , Best Valid Loss : 0.0015662882942706347 \n",
            " epoch : 1797, validation loss did not decrease \n",
            " Training loss : 0.0013319790596142411 , validation_loss : 0.001636283821426332 , Best Valid Loss : 0.0015662882942706347 \n",
            " epoch : 1798, validation loss did not decrease \n",
            " Training loss : 0.0013306179316714406 , validation_loss : 0.0016344061587005854 , Best Valid Loss : 0.0015662882942706347 \n",
            " epoch : 1799, validation loss did not decrease \n",
            " Training loss : 0.001330025726929307 , validation_loss : 0.0016239136457443237 , Best Valid Loss : 0.0015662882942706347 \n",
            " epoch : 1800, validation loss did not decrease \n",
            " Training loss : 0.001319722505286336 , validation_loss : 0.0016121268272399902 , Best Valid Loss : 0.0015662882942706347 \n",
            " epoch : 1801, validation loss did not decrease \n",
            " Training loss : 0.0013099403586238623 , validation_loss : 0.0015991985565051436 , Best Valid Loss : 0.0015662882942706347 \n",
            " epoch : 1802, validation loss did not decrease \n",
            " Training loss : 0.0012967847287654877 , validation_loss : 0.0015880012651905417 , Best Valid Loss : 0.0015662882942706347 \n",
            " epoch : 1803, validation loss did not decrease \n",
            " Training loss : 0.001287447172217071 , validation_loss : 0.0015812608180567622 , Best Valid Loss : 0.0015662882942706347 \n",
            " epoch : 1804, validation loss did not decrease \n",
            " Training loss : 0.0012801358243450522 , validation_loss : 0.0015740058152005076 , Best Valid Loss : 0.0015662882942706347 \n",
            " epoch : 1805, validation loss did not decrease \n",
            " Training loss : 0.0012740824604406953 , validation_loss : 0.0015685156686231494 , Best Valid Loss : 0.0015662882942706347 \n",
            " epoch : 1806, Validation loss decreased : 0.0015662882942706347 --> 0.001563427154906094 \n",
            " Training loss : 0.001268507563509047 , validation_loss : 0.001563427154906094 , Best Valid Loss : 0.001563427154906094 \n",
            " epoch : 1807, Validation loss decreased : 0.001563427154906094 --> 0.0015616255113855004 \n",
            " Training loss : 0.0012646667892113328 , validation_loss : 0.0015616255113855004 , Best Valid Loss : 0.0015616255113855004 \n",
            " epoch : 1808, Validation loss decreased : 0.0015616255113855004 --> 0.001559628639370203 \n",
            " Training loss : 0.001262009609490633 , validation_loss : 0.001559628639370203 , Best Valid Loss : 0.001559628639370203 \n",
            " epoch : 1809, Validation loss decreased : 0.001559628639370203 --> 0.0015582859050482512 \n",
            " Training loss : 0.001260301098227501 , validation_loss : 0.0015582859050482512 , Best Valid Loss : 0.0015582859050482512 \n",
            " epoch : 1810, Validation loss decreased : 0.0015582859050482512 --> 0.0015580321196466684 \n",
            " Training loss : 0.0012592271668836474 , validation_loss : 0.0015580321196466684 , Best Valid Loss : 0.0015580321196466684 \n",
            " epoch : 1811, validation loss did not decrease \n",
            " Training loss : 0.0012588734971359372 , validation_loss : 0.0015584503998979926 , Best Valid Loss : 0.0015580321196466684 \n",
            " epoch : 1812, validation loss did not decrease \n",
            " Training loss : 0.0012590789701789618 , validation_loss : 0.001558633055537939 , Best Valid Loss : 0.0015580321196466684 \n",
            " epoch : 1813, validation loss did not decrease \n",
            " Training loss : 0.0012594268191605806 , validation_loss : 0.0015585926594212651 , Best Valid Loss : 0.0015580321196466684 \n",
            " epoch : 1814, validation loss did not decrease \n",
            " Training loss : 0.0012603712966665626 , validation_loss : 0.001561162294819951 , Best Valid Loss : 0.0015580321196466684 \n",
            " epoch : 1815, validation loss did not decrease \n",
            " Training loss : 0.001261868979781866 , validation_loss : 0.0015639036428183317 , Best Valid Loss : 0.0015580321196466684 \n",
            " epoch : 1816, validation loss did not decrease \n",
            " Training loss : 0.0012650463031604886 , validation_loss : 0.0015691391890868545 , Best Valid Loss : 0.0015580321196466684 \n",
            " epoch : 1817, validation loss did not decrease \n",
            " Training loss : 0.001269403612241149 , validation_loss : 0.0015756366774439812 , Best Valid Loss : 0.0015580321196466684 \n",
            " epoch : 1818, validation loss did not decrease \n",
            " Training loss : 0.0012768527958542109 , validation_loss : 0.0015862566651776433 , Best Valid Loss : 0.0015580321196466684 \n",
            " epoch : 1819, validation loss did not decrease \n",
            " Training loss : 0.0012854302767664194 , validation_loss : 0.0015997857553884387 , Best Valid Loss : 0.0015580321196466684 \n",
            " epoch : 1820, validation loss did not decrease \n",
            " Training loss : 0.0012984472559764981 , validation_loss : 0.0016157609643414617 , Best Valid Loss : 0.0015580321196466684 \n",
            " epoch : 1821, validation loss did not decrease \n",
            " Training loss : 0.0013133209431543946 , validation_loss : 0.0016351909143850207 , Best Valid Loss : 0.0015580321196466684 \n",
            " epoch : 1822, validation loss did not decrease \n",
            " Training loss : 0.0013313187519088387 , validation_loss : 0.0016471367562189698 , Best Valid Loss : 0.0015580321196466684 \n",
            " epoch : 1823, validation loss did not decrease \n",
            " Training loss : 0.0013419155729934573 , validation_loss : 0.0016668394673615694 , Best Valid Loss : 0.0015580321196466684 \n",
            " epoch : 1824, validation loss did not decrease \n",
            " Training loss : 0.0013612345792353153 , validation_loss : 0.0016689857002347708 , Best Valid Loss : 0.0015580321196466684 \n",
            " epoch : 1825, validation loss did not decrease \n",
            " Training loss : 0.001362776616588235 , validation_loss : 0.0016755572287365794 , Best Valid Loss : 0.0015580321196466684 \n",
            " epoch : 1826, validation loss did not decrease \n",
            " Training loss : 0.001367664895951748 , validation_loss : 0.0016524608945474029 , Best Valid Loss : 0.0015580321196466684 \n",
            " epoch : 1827, validation loss did not decrease \n",
            " Training loss : 0.0013466813834384084 , validation_loss : 0.001637885463424027 , Best Valid Loss : 0.0015580321196466684 \n",
            " epoch : 1828, validation loss did not decrease \n",
            " Training loss : 0.0013357240241020918 , validation_loss : 0.0016127803828567266 , Best Valid Loss : 0.0015580321196466684 \n",
            " epoch : 1829, validation loss did not decrease \n",
            " Training loss : 0.0013105613179504871 , validation_loss : 0.0015915394760668278 , Best Valid Loss : 0.0015580321196466684 \n",
            " epoch : 1830, validation loss did not decrease \n",
            " Training loss : 0.001289806910790503 , validation_loss : 0.001568848849274218 , Best Valid Loss : 0.0015580321196466684 \n",
            " epoch : 1831, Validation loss decreased : 0.0015580321196466684 --> 0.0015546588692814112 \n",
            " Training loss : 0.0012699909275397658 , validation_loss : 0.0015546588692814112 , Best Valid Loss : 0.0015546588692814112 \n",
            " epoch : 1832, Validation loss decreased : 0.0015546588692814112 --> 0.0015503198374062777 \n",
            " Training loss : 0.0012585363583639264 , validation_loss : 0.0015503198374062777 , Best Valid Loss : 0.0015503198374062777 \n",
            " epoch : 1833, validation loss did not decrease \n",
            " Training loss : 0.0012531168758869171 , validation_loss : 0.001551362918689847 , Best Valid Loss : 0.0015503198374062777 \n",
            " epoch : 1834, validation loss did not decrease \n",
            " Training loss : 0.001253656460903585 , validation_loss : 0.0015551119577139616 , Best Valid Loss : 0.0015503198374062777 \n",
            " epoch : 1835, validation loss did not decrease \n",
            " Training loss : 0.0012576895533129573 , validation_loss : 0.0015621831407770514 , Best Valid Loss : 0.0015503198374062777 \n",
            " epoch : 1836, validation loss did not decrease \n",
            " Training loss : 0.001264097634702921 , validation_loss : 0.0015705425757914782 , Best Valid Loss : 0.0015503198374062777 \n",
            " epoch : 1837, validation loss did not decrease \n",
            " Training loss : 0.0012729791924357414 , validation_loss : 0.0015802282141521573 , Best Valid Loss : 0.0015503198374062777 \n",
            " epoch : 1838, validation loss did not decrease \n",
            " Training loss : 0.0012814616784453392 , validation_loss : 0.0015920858131721616 , Best Valid Loss : 0.0015503198374062777 \n",
            " epoch : 1839, validation loss did not decrease \n",
            " Training loss : 0.0012921902816742659 , validation_loss : 0.0016030017286539078 , Best Valid Loss : 0.0015503198374062777 \n",
            " epoch : 1840, validation loss did not decrease \n",
            " Training loss : 0.0013021099148318172 , validation_loss : 0.0016162815736606717 , Best Valid Loss : 0.0015503198374062777 \n",
            " epoch : 1841, validation loss did not decrease \n",
            " Training loss : 0.0013154862681403756 , validation_loss : 0.0016251850174739957 , Best Valid Loss : 0.0015503198374062777 \n",
            " epoch : 1842, validation loss did not decrease \n",
            " Training loss : 0.0013232453493401408 , validation_loss : 0.0016420145984739065 , Best Valid Loss : 0.0015503198374062777 \n",
            " epoch : 1843, validation loss did not decrease \n",
            " Training loss : 0.0013383375480771065 , validation_loss : 0.0016502541257068515 , Best Valid Loss : 0.0015503198374062777 \n",
            " epoch : 1844, validation loss did not decrease \n",
            " Training loss : 0.0013460101326927543 , validation_loss : 0.0016659849788993597 , Best Valid Loss : 0.0015503198374062777 \n",
            " epoch : 1845, validation loss did not decrease \n",
            " Training loss : 0.0013611151371151209 , validation_loss : 0.00165748770814389 , Best Valid Loss : 0.0015503198374062777 \n",
            " epoch : 1846, validation loss did not decrease \n",
            " Training loss : 0.0013530587311834097 , validation_loss : 0.0016564646502956748 , Best Valid Loss : 0.0015503198374062777 \n",
            " epoch : 1847, validation loss did not decrease \n",
            " Training loss : 0.0013513147132471204 , validation_loss : 0.001630589016713202 , Best Valid Loss : 0.0015503198374062777 \n",
            " epoch : 1848, validation loss did not decrease \n",
            " Training loss : 0.0013277498073875904 , validation_loss : 0.0016116310143843293 , Best Valid Loss : 0.0015503198374062777 \n",
            " epoch : 1849, validation loss did not decrease \n",
            " Training loss : 0.001311365864239633 , validation_loss : 0.0015866569010540843 , Best Valid Loss : 0.0015503198374062777 \n",
            " epoch : 1850, validation loss did not decrease \n",
            " Training loss : 0.0012870067730545998 , validation_loss : 0.0015661569777876139 , Best Valid Loss : 0.0015503198374062777 \n",
            " epoch : 1851, validation loss did not decrease \n",
            " Training loss : 0.0012678891653195024 , validation_loss : 0.00155056978110224 , Best Valid Loss : 0.0015503198374062777 \n",
            " epoch : 1852, Validation loss decreased : 0.0015503198374062777 --> 0.0015432643704116344 \n",
            " Training loss : 0.0012538009323179722 , validation_loss : 0.0015432643704116344 , Best Valid Loss : 0.0015432643704116344 \n",
            " epoch : 1853, validation loss did not decrease \n",
            " Training loss : 0.001247906475327909 , validation_loss : 0.0015433570370078087 , Best Valid Loss : 0.0015432643704116344 \n",
            " epoch : 1854, validation loss did not decrease \n",
            " Training loss : 0.0012472937814891338 , validation_loss : 0.0015478909481316805 , Best Valid Loss : 0.0015432643704116344 \n",
            " epoch : 1855, validation loss did not decrease \n",
            " Training loss : 0.0012512973044067621 , validation_loss : 0.0015549019444733858 , Best Valid Loss : 0.0015432643704116344 \n",
            " epoch : 1856, validation loss did not decrease \n",
            " Training loss : 0.0012585127260535955 , validation_loss : 0.0015635201707482338 , Best Valid Loss : 0.0015432643704116344 \n",
            " epoch : 1857, validation loss did not decrease \n",
            " Training loss : 0.001266089966520667 , validation_loss : 0.0015744965057820082 , Best Valid Loss : 0.0015432643704116344 \n",
            " epoch : 1858, validation loss did not decrease \n",
            " Training loss : 0.0012842508731409907 , validation_loss : 0.0016204796265810728 , Best Valid Loss : 0.0015432643704116344 \n",
            " epoch : 1859, validation loss did not decrease \n",
            " Training loss : 0.0013303266605362296 , validation_loss : 0.0016673981444910169 , Best Valid Loss : 0.0015432643704116344 \n",
            " epoch : 1860, validation loss did not decrease \n",
            " Training loss : 0.001355595188215375 , validation_loss : 0.0016762533923611045 , Best Valid Loss : 0.0015432643704116344 \n",
            " epoch : 1861, validation loss did not decrease \n",
            " Training loss : 0.0013667178573086858 , validation_loss : 0.0018603922799229622 , Best Valid Loss : 0.0015432643704116344 \n",
            " epoch : 1862, validation loss did not decrease \n",
            " Training loss : 0.0015353962080553174 , validation_loss : 0.0025334025267511606 , Best Valid Loss : 0.0015432643704116344 \n",
            " epoch : 1863, validation loss did not decrease \n",
            " Training loss : 0.002146602375432849 , validation_loss : 0.0042495098896324635 , Best Valid Loss : 0.0015432643704116344 \n",
            " epoch : 1864, validation loss did not decrease \n",
            " Training loss : 0.0036500985734164715 , validation_loss : 0.002887464128434658 , Best Valid Loss : 0.0015432643704116344 \n",
            " epoch : 1865, validation loss did not decrease \n",
            " Training loss : 0.0025709746405482292 , validation_loss : 0.002017686842009425 , Best Valid Loss : 0.0015432643704116344 \n",
            " epoch : 1866, validation loss did not decrease \n",
            " Training loss : 0.0016581754898652434 , validation_loss : 0.0016080251662060618 , Best Valid Loss : 0.0015432643704116344 \n",
            " epoch : 1867, validation loss did not decrease \n",
            " Training loss : 0.001320547889918089 , validation_loss : 0.00252222316339612 , Best Valid Loss : 0.0015432643704116344 \n",
            " epoch : 1868, validation loss did not decrease \n",
            " Training loss : 0.002124814549461007 , validation_loss : 0.0033152292016893625 , Best Valid Loss : 0.0015432643704116344 \n",
            " epoch : 1869, validation loss did not decrease \n",
            " Training loss : 0.0028915998991578817 , validation_loss : 0.0018764003179967403 , Best Valid Loss : 0.0015432643704116344 \n",
            " epoch : 1870, validation loss did not decrease \n",
            " Training loss : 0.0016929820412769914 , validation_loss : 0.0020058718509972095 , Best Valid Loss : 0.0015432643704116344 \n",
            " epoch : 1871, validation loss did not decrease \n",
            " Training loss : 0.0017445458797737956 , validation_loss : 0.003085671691223979 , Best Valid Loss : 0.0015432643704116344 \n",
            " epoch : 1872, validation loss did not decrease \n",
            " Training loss : 0.0028835763223469257 , validation_loss : 0.0021137117873877287 , Best Valid Loss : 0.0015432643704116344 \n",
            " epoch : 1873, validation loss did not decrease \n",
            " Training loss : 0.0018102042376995087 , validation_loss : 0.00167036522179842 , Best Valid Loss : 0.0015432643704116344 \n",
            " epoch : 1874, validation loss did not decrease \n",
            " Training loss : 0.001428006449714303 , validation_loss : 0.0022600567899644375 , Best Valid Loss : 0.0015432643704116344 \n",
            " epoch : 1875, validation loss did not decrease \n",
            " Training loss : 0.0019040636252611876 , validation_loss : 0.0018779876409098506 , Best Valid Loss : 0.0015432643704116344 \n",
            " epoch : 1876, validation loss did not decrease \n",
            " Training loss : 0.0015527057694271207 , validation_loss : 0.0016125666443258524 , Best Valid Loss : 0.0015432643704116344 \n",
            " epoch : 1877, validation loss did not decrease \n",
            " Training loss : 0.0013234906364232302 , validation_loss : 0.001972541445866227 , Best Valid Loss : 0.0015432643704116344 \n",
            " epoch : 1878, validation loss did not decrease \n",
            " Training loss : 0.0016312140505760908 , validation_loss : 0.0017027283320203424 , Best Valid Loss : 0.0015432643704116344 \n",
            " epoch : 1879, validation loss did not decrease \n",
            " Training loss : 0.0014193493407219648 , validation_loss : 0.0016141424421221018 , Best Valid Loss : 0.0015432643704116344 \n",
            " epoch : 1880, validation loss did not decrease \n",
            " Training loss : 0.0013181120157241821 , validation_loss : 0.0017970887711271644 , Best Valid Loss : 0.0015432643704116344 \n",
            " epoch : 1881, validation loss did not decrease \n",
            " Training loss : 0.001562237273901701 , validation_loss : 0.001678191008977592 , Best Valid Loss : 0.0015432643704116344 \n",
            " epoch : 1882, validation loss did not decrease \n",
            " Training loss : 0.001375050051137805 , validation_loss : 0.0015974348643794656 , Best Valid Loss : 0.0015432643704116344 \n",
            " epoch : 1883, validation loss did not decrease \n",
            " Training loss : 0.0013093880843371153 , validation_loss : 0.0017072700429707766 , Best Valid Loss : 0.0015432643704116344 \n",
            " epoch : 1884, validation loss did not decrease \n",
            " Training loss : 0.0014057131484150887 , validation_loss : 0.001651566126383841 , Best Valid Loss : 0.0015432643704116344 \n",
            " epoch : 1885, validation loss did not decrease \n",
            " Training loss : 0.0013558187056332827 , validation_loss : 0.0015529876109212637 , Best Valid Loss : 0.0015432643704116344 \n",
            " epoch : 1886, validation loss did not decrease \n",
            " Training loss : 0.0012711933813989162 , validation_loss : 0.0016412906115874648 , Best Valid Loss : 0.0015432643704116344 \n",
            " epoch : 1887, validation loss did not decrease \n",
            " Training loss : 0.0013399769086390734 , validation_loss : 0.0016203389968723059 , Best Valid Loss : 0.0015432643704116344 \n",
            " epoch : 1888, validation loss did not decrease \n",
            " Training loss : 0.0013307856861501932 , validation_loss : 0.0015454280655831099 , Best Valid Loss : 0.0015432643704116344 \n",
            " epoch : 1889, validation loss did not decrease \n",
            " Training loss : 0.0012617335887625813 , validation_loss : 0.0015584930079057813 , Best Valid Loss : 0.0015432643704116344 \n",
            " epoch : 1890, validation loss did not decrease \n",
            " Training loss : 0.001287815859541297 , validation_loss : 0.0016065590316429734 , Best Valid Loss : 0.0015432643704116344 \n",
            " epoch : 1891, validation loss did not decrease \n",
            " Training loss : 0.00131069659255445 , validation_loss : 0.0015857205726206303 , Best Valid Loss : 0.0015432643704116344 \n",
            " epoch : 1892, Validation loss decreased : 0.0015432643704116344 --> 0.0015404396690428257 \n",
            " Training loss : 0.001287910039536655 , validation_loss : 0.0015404396690428257 , Best Valid Loss : 0.0015404396690428257 \n",
            " epoch : 1893, validation loss did not decrease \n",
            " Training loss : 0.0012504052137956023 , validation_loss : 0.0015747754368931055 , Best Valid Loss : 0.0015404396690428257 \n",
            " epoch : 1894, validation loss did not decrease \n",
            " Training loss : 0.0012839270057156682 , validation_loss : 0.001575688598677516 , Best Valid Loss : 0.0015404396690428257 \n",
            " epoch : 1895, validation loss did not decrease \n",
            " Training loss : 0.001293784473091364 , validation_loss : 0.0015495185507461429 , Best Valid Loss : 0.0015404396690428257 \n",
            " epoch : 1896, validation loss did not decrease \n",
            " Training loss : 0.0012590447440743446 , validation_loss : 0.001541014527902007 , Best Valid Loss : 0.0015404396690428257 \n",
            " epoch : 1897, validation loss did not decrease \n",
            " Training loss : 0.0012502858880907297 , validation_loss : 0.0015578806633129716 , Best Valid Loss : 0.0015404396690428257 \n",
            " epoch : 1898, validation loss did not decrease \n",
            " Training loss : 0.001267023733817041 , validation_loss : 0.00156315672211349 , Best Valid Loss : 0.0015404396690428257 \n",
            " epoch : 1899, Validation loss decreased : 0.0015404396690428257 --> 0.0015345889842137694 \n",
            " Training loss : 0.0012712692841887474 , validation_loss : 0.0015345889842137694 , Best Valid Loss : 0.0015345889842137694 \n",
            " epoch : 1900, validation loss did not decrease \n",
            " Training loss : 0.0012443495215848088 , validation_loss : 0.001541490899398923 , Best Valid Loss : 0.0015345889842137694 \n",
            " epoch : 1901, validation loss did not decrease \n",
            " Training loss : 0.0012452382361516356 , validation_loss : 0.0015509716467931867 , Best Valid Loss : 0.0015345889842137694 \n",
            " epoch : 1902, validation loss did not decrease \n",
            " Training loss : 0.0012573859421536326 , validation_loss : 0.0015425535384565592 , Best Valid Loss : 0.0015345889842137694 \n",
            " epoch : 1903, Validation loss decreased : 0.0015345889842137694 --> 0.0015314610209316015 \n",
            " Training loss : 0.0012532303808256984 , validation_loss : 0.0015314610209316015 , Best Valid Loss : 0.0015314610209316015 \n",
            " epoch : 1904, validation loss did not decrease \n",
            " Training loss : 0.0012413313379511237 , validation_loss : 0.0015374264912679791 , Best Valid Loss : 0.0015314610209316015 \n",
            " epoch : 1905, validation loss did not decrease \n",
            " Training loss : 0.0012438490521162748 , validation_loss : 0.0015514802653342485 , Best Valid Loss : 0.0015314610209316015 \n",
            " epoch : 1906, validation loss did not decrease \n",
            " Training loss : 0.00125316868070513 , validation_loss : 0.0015384580474346876 , Best Valid Loss : 0.0015314610209316015 \n",
            " epoch : 1907, Validation loss decreased : 0.0015314610209316015 --> 0.001530161709524691 \n",
            " Training loss : 0.0012451537186279893 , validation_loss : 0.001530161709524691 , Best Valid Loss : 0.001530161709524691 \n",
            " epoch : 1908, validation loss did not decrease \n",
            " Training loss : 0.0012391493655741215 , validation_loss : 0.001534341718070209 , Best Valid Loss : 0.001530161709524691 \n",
            " epoch : 1909, validation loss did not decrease \n",
            " Training loss : 0.0012420123675838113 , validation_loss : 0.001538974465802312 , Best Valid Loss : 0.001530161709524691 \n",
            " epoch : 1910, validation loss did not decrease \n",
            " Training loss : 0.0012456821277737617 , validation_loss : 0.0015361597761511803 , Best Valid Loss : 0.001530161709524691 \n",
            " epoch : 1911, Validation loss decreased : 0.001530161709524691 --> 0.001527893473394215 \n",
            " Training loss : 0.0012407543836161494 , validation_loss : 0.001527893473394215 , Best Valid Loss : 0.001527893473394215 \n",
            " epoch : 1912, validation loss did not decrease \n",
            " Training loss : 0.0012360968394204974 , validation_loss : 0.001532599562779069 , Best Valid Loss : 0.001527893473394215 \n",
            " epoch : 1913, validation loss did not decrease \n",
            " Training loss : 0.0012406347086653113 , validation_loss : 0.0015369430184364319 , Best Valid Loss : 0.001527893473394215 \n",
            " epoch : 1914, validation loss did not decrease \n",
            " Training loss : 0.001242977217771113 , validation_loss : 0.0015318137593567371 , Best Valid Loss : 0.001527893473394215 \n",
            " epoch : 1915, Validation loss decreased : 0.001527893473394215 --> 0.0015275636687874794 \n",
            " Training loss : 0.001238363329321146 , validation_loss : 0.0015275636687874794 , Best Valid Loss : 0.0015275636687874794 \n",
            " epoch : 1916, validation loss did not decrease \n",
            " Training loss : 0.0012341842520982027 , validation_loss : 0.0015299624064937234 , Best Valid Loss : 0.0015275636687874794 \n",
            " epoch : 1917, validation loss did not decrease \n",
            " Training loss : 0.0012388813775032759 , validation_loss : 0.0015348083106800914 , Best Valid Loss : 0.0015275636687874794 \n",
            " epoch : 1918, validation loss did not decrease \n",
            " Training loss : 0.0012414318043738604 , validation_loss : 0.0015322014223784208 , Best Valid Loss : 0.0015275636687874794 \n",
            " epoch : 1919, Validation loss decreased : 0.0015275636687874794 --> 0.0015272224554792047 \n",
            " Training loss : 0.0012372583150863647 , validation_loss : 0.0015272224554792047 , Best Valid Loss : 0.0015272224554792047 \n",
            " epoch : 1920, validation loss did not decrease \n",
            " Training loss : 0.0012331809848546982 , validation_loss : 0.0015292050084099174 , Best Valid Loss : 0.0015272224554792047 \n",
            " epoch : 1921, validation loss did not decrease \n",
            " Training loss : 0.0012361732078716159 , validation_loss : 0.0015299514634534717 , Best Valid Loss : 0.0015272224554792047 \n",
            " epoch : 1922, validation loss did not decrease \n",
            " Training loss : 0.001238322351127863 , validation_loss : 0.001527663436718285 , Best Valid Loss : 0.0015272224554792047 \n",
            " epoch : 1923, Validation loss decreased : 0.0015272224554792047 --> 0.0015261933440342546 \n",
            " Training loss : 0.0012342898407950997 , validation_loss : 0.0015261933440342546 , Best Valid Loss : 0.0015261933440342546 \n",
            " epoch : 1924, validation loss did not decrease \n",
            " Training loss : 0.0012324285926297307 , validation_loss : 0.0015273343306034803 , Best Valid Loss : 0.0015261933440342546 \n",
            " epoch : 1925, validation loss did not decrease \n",
            " Training loss : 0.0012343700509518385 , validation_loss : 0.0015268296701833606 , Best Valid Loss : 0.0015261933440342546 \n",
            " epoch : 1926, Validation loss decreased : 0.0015261933440342546 --> 0.0015236996114253998 \n",
            " Training loss : 0.0012347884476184845 , validation_loss : 0.0015236996114253998 , Best Valid Loss : 0.0015236996114253998 \n",
            " epoch : 1927, validation loss did not decrease \n",
            " Training loss : 0.0012318583903834224 , validation_loss : 0.00152440438978374 , Best Valid Loss : 0.0015236996114253998 \n",
            " epoch : 1928, validation loss did not decrease \n",
            " Training loss : 0.0012314217165112495 , validation_loss : 0.0015254910103976727 , Best Valid Loss : 0.0015236996114253998 \n",
            " epoch : 1929, validation loss did not decrease \n",
            " Training loss : 0.0012328517623245716 , validation_loss : 0.0015239594504237175 , Best Valid Loss : 0.0015236996114253998 \n",
            " epoch : 1930, Validation loss decreased : 0.0015236996114253998 --> 0.0015220221830531955 \n",
            " Training loss : 0.0012323600240051746 , validation_loss : 0.0015220221830531955 , Best Valid Loss : 0.0015220221830531955 \n",
            " epoch : 1931, validation loss did not decrease \n",
            " Training loss : 0.0012305618729442358 , validation_loss : 0.0015221646754071116 , Best Valid Loss : 0.0015220221830531955 \n",
            " epoch : 1932, validation loss did not decrease \n",
            " Training loss : 0.0012300796806812286 , validation_loss : 0.0015236899489536881 , Best Valid Loss : 0.0015220221830531955 \n",
            " epoch : 1933, validation loss did not decrease \n",
            " Training loss : 0.0012311587342992425 , validation_loss : 0.0015229410491883755 , Best Valid Loss : 0.0015220221830531955 \n",
            " epoch : 1934, Validation loss decreased : 0.0015220221830531955 --> 0.0015207813121378422 \n",
            " Training loss : 0.0012309389421716332 , validation_loss : 0.0015207813121378422 , Best Valid Loss : 0.0015207813121378422 \n",
            " epoch : 1935, Validation loss decreased : 0.0015207813121378422 --> 0.001520400051958859 \n",
            " Training loss : 0.001229624031111598 , validation_loss : 0.001520400051958859 , Best Valid Loss : 0.001520400051958859 \n",
            " epoch : 1936, validation loss did not decrease \n",
            " Training loss : 0.0012287987628951669 , validation_loss : 0.001521443948149681 , Best Valid Loss : 0.001520400051958859 \n",
            " epoch : 1937, validation loss did not decrease \n",
            " Training loss : 0.0012292956234887242 , validation_loss : 0.0015214974991977215 , Best Valid Loss : 0.001520400051958859 \n",
            " epoch : 1938, Validation loss decreased : 0.001520400051958859 --> 0.0015199925983324647 \n",
            " Training loss : 0.0012295262422412634 , validation_loss : 0.0015199925983324647 , Best Valid Loss : 0.0015199925983324647 \n",
            " epoch : 1939, Validation loss decreased : 0.0015199925983324647 --> 0.0015190682606771588 \n",
            " Training loss : 0.0012285748962312937 , validation_loss : 0.0015190682606771588 , Best Valid Loss : 0.0015190682606771588 \n",
            " epoch : 1940, validation loss did not decrease \n",
            " Training loss : 0.00122770422603935 , validation_loss : 0.0015196698950603604 , Best Valid Loss : 0.0015190682606771588 \n",
            " epoch : 1941, validation loss did not decrease \n",
            " Training loss : 0.0012277475325390697 , validation_loss : 0.0015199319459497929 , Best Valid Loss : 0.0015190682606771588 \n",
            " epoch : 1942, Validation loss decreased : 0.0015190682606771588 --> 0.0015189965488389134 \n",
            " Training loss : 0.0012282630195841193 , validation_loss : 0.0015189965488389134 , Best Valid Loss : 0.0015189965488389134 \n",
            " epoch : 1943, Validation loss decreased : 0.0015189965488389134 --> 0.001518505741842091 \n",
            " Training loss : 0.0012283981777727604 , validation_loss : 0.001518505741842091 , Best Valid Loss : 0.001518505741842091 \n",
            " epoch : 1944, Validation loss decreased : 0.001518505741842091 --> 0.0015182980569079518 \n",
            " Training loss : 0.0012276394991204143 , validation_loss : 0.0015182980569079518 , Best Valid Loss : 0.0015182980569079518 \n",
            " epoch : 1945, Validation loss decreased : 0.0015182980569079518 --> 0.001518133212812245 \n",
            " Training loss : 0.0012267616111785173 , validation_loss : 0.001518133212812245 , Best Valid Loss : 0.001518133212812245 \n",
            " epoch : 1946, Validation loss decreased : 0.001518133212812245 --> 0.0015175606822595 \n",
            " Training loss : 0.0012265759287402034 , validation_loss : 0.0015175606822595 , Best Valid Loss : 0.0015175606822595 \n",
            " epoch : 1947, Validation loss decreased : 0.0015175606822595 --> 0.001517064985819161 \n",
            " Training loss : 0.0012267958372831345 , validation_loss : 0.001517064985819161 , Best Valid Loss : 0.001517064985819161 \n",
            " epoch : 1948, validation loss did not decrease \n",
            " Training loss : 0.0012270128354430199 , validation_loss : 0.0015174183063209057 , Best Valid Loss : 0.001517064985819161 \n",
            " epoch : 1949, validation loss did not decrease \n",
            " Training loss : 0.001226527732796967 , validation_loss : 0.0015170968836173415 , Best Valid Loss : 0.001517064985819161 \n",
            " epoch : 1950, Validation loss decreased : 0.001517064985819161 --> 0.0015158591559156775 \n",
            " Training loss : 0.0012258401839062572 , validation_loss : 0.0015158591559156775 , Best Valid Loss : 0.0015158591559156775 \n",
            " epoch : 1951, Validation loss decreased : 0.0015158591559156775 --> 0.0015155259752646089 \n",
            " Training loss : 0.0012252286542207003 , validation_loss : 0.0015155259752646089 , Best Valid Loss : 0.0015155259752646089 \n",
            " epoch : 1952, validation loss did not decrease \n",
            " Training loss : 0.0012251980369910598 , validation_loss : 0.0015158930327743292 , Best Valid Loss : 0.0015155259752646089 \n",
            " epoch : 1953, validation loss did not decrease \n",
            " Training loss : 0.0012253670720383525 , validation_loss : 0.001516201300546527 , Best Valid Loss : 0.0015155259752646089 \n",
            " epoch : 1954, Validation loss decreased : 0.0015155259752646089 --> 0.001515378593467176 \n",
            " Training loss : 0.0012254021130502224 , validation_loss : 0.001515378593467176 , Best Valid Loss : 0.001515378593467176 \n",
            " epoch : 1955, Validation loss decreased : 0.001515378593467176 --> 0.0015147468075156212 \n",
            " Training loss : 0.001225198619067669 , validation_loss : 0.0015147468075156212 , Best Valid Loss : 0.0015147468075156212 \n",
            " epoch : 1956, Validation loss decreased : 0.0015147468075156212 --> 0.0015146576333791018 \n",
            " Training loss : 0.0012245307443663478 , validation_loss : 0.0015146576333791018 , Best Valid Loss : 0.0015146576333791018 \n",
            " epoch : 1957, validation loss did not decrease \n",
            " Training loss : 0.0012239349307492375 , validation_loss : 0.001514729461632669 , Best Valid Loss : 0.0015146576333791018 \n",
            " epoch : 1958, Validation loss decreased : 0.0015146576333791018 --> 0.001514632604084909 \n",
            " Training loss : 0.0012240607757121325 , validation_loss : 0.001514632604084909 , Best Valid Loss : 0.001514632604084909 \n",
            " epoch : 1959, Validation loss decreased : 0.001514632604084909 --> 0.0015140004688873887 \n",
            " Training loss : 0.0012242920929566026 , validation_loss : 0.0015140004688873887 , Best Valid Loss : 0.0015140004688873887 \n",
            " epoch : 1960, Validation loss decreased : 0.0015140004688873887 --> 0.0015136431902647018 \n",
            " Training loss : 0.0012239485513418913 , validation_loss : 0.0015136431902647018 , Best Valid Loss : 0.0015136431902647018 \n",
            " epoch : 1961, Validation loss decreased : 0.0015136431902647018 --> 0.0015134504064917564 \n",
            " Training loss : 0.0012232084991410375 , validation_loss : 0.0015134504064917564 , Best Valid Loss : 0.0015134504064917564 \n",
            " epoch : 1962, Validation loss decreased : 0.0015134504064917564 --> 0.0015132351545616984 \n",
            " Training loss : 0.0012229265412315726 , validation_loss : 0.0015132351545616984 , Best Valid Loss : 0.0015132351545616984 \n",
            " epoch : 1963, Validation loss decreased : 0.0015132351545616984 --> 0.0015129958046600223 \n",
            " Training loss : 0.0012230388820171356 , validation_loss : 0.0015129958046600223 , Best Valid Loss : 0.0015129958046600223 \n",
            " epoch : 1964, Validation loss decreased : 0.0015129958046600223 --> 0.0015125006902962923 \n",
            " Training loss : 0.0012229931307956576 , validation_loss : 0.0015125006902962923 , Best Valid Loss : 0.0015125006902962923 \n",
            " epoch : 1965, Validation loss decreased : 0.0015125006902962923 --> 0.0015124079072847962 \n",
            " Training loss : 0.0012228089617565274 , validation_loss : 0.0015124079072847962 , Best Valid Loss : 0.0015124079072847962 \n",
            " epoch : 1966, Validation loss decreased : 0.0015124079072847962 --> 0.0015117872972041368 \n",
            " Training loss : 0.0012222062796354294 , validation_loss : 0.0015117872972041368 , Best Valid Loss : 0.0015117872972041368 \n",
            " epoch : 1967, Validation loss decreased : 0.0015117872972041368 --> 0.00151164794806391 \n",
            " Training loss : 0.0012218998745083809 , validation_loss : 0.00151164794806391 , Best Valid Loss : 0.00151164794806391 \n",
            " epoch : 1968, Validation loss decreased : 0.00151164794806391 --> 0.0015113299014046788 \n",
            " Training loss : 0.001221669022925198 , validation_loss : 0.0015113299014046788 , Best Valid Loss : 0.0015113299014046788 \n",
            " epoch : 1969, Validation loss decreased : 0.0015113299014046788 --> 0.0015110817039385438 \n",
            " Training loss : 0.0012214250164106488 , validation_loss : 0.0015110817039385438 , Best Valid Loss : 0.0015110817039385438 \n",
            " epoch : 1970, Validation loss decreased : 0.0015110817039385438 --> 0.0015107092913240194 \n",
            " Training loss : 0.0012211903231218457 , validation_loss : 0.0015107092913240194 , Best Valid Loss : 0.0015107092913240194 \n",
            " epoch : 1971, Validation loss decreased : 0.0015107092913240194 --> 0.0015106180217117071 \n",
            " Training loss : 0.0012209831038489938 , validation_loss : 0.0015106180217117071 , Best Valid Loss : 0.0015106180217117071 \n",
            " epoch : 1972, Validation loss decreased : 0.0015106180217117071 --> 0.0015104507328942418 \n",
            " Training loss : 0.0012207678519189358 , validation_loss : 0.0015104507328942418 , Best Valid Loss : 0.0015104507328942418 \n",
            " epoch : 1973, Validation loss decreased : 0.0015104507328942418 --> 0.0015098691219463944 \n",
            " Training loss : 0.0012205684324726462 , validation_loss : 0.0015098691219463944 , Best Valid Loss : 0.0015098691219463944 \n",
            " epoch : 1974, Validation loss decreased : 0.0015098691219463944 --> 0.0015097592258825898 \n",
            " Training loss : 0.0012203502701595426 , validation_loss : 0.0015097592258825898 , Best Valid Loss : 0.0015097592258825898 \n",
            " epoch : 1975, Validation loss decreased : 0.0015097592258825898 --> 0.0015096401330083609 \n",
            " Training loss : 0.0012201911304146051 , validation_loss : 0.0015096401330083609 , Best Valid Loss : 0.0015096401330083609 \n",
            " epoch : 1976, validation loss did not decrease \n",
            " Training loss : 0.0012202677316963673 , validation_loss : 0.0015098570147529244 , Best Valid Loss : 0.0015096401330083609 \n",
            " epoch : 1977, Validation loss decreased : 0.0015096401330083609 --> 0.0015094775008037686 \n",
            " Training loss : 0.0012204432860016823 , validation_loss : 0.0015094775008037686 , Best Valid Loss : 0.0015094775008037686 \n",
            " epoch : 1978, Validation loss decreased : 0.0015094775008037686 --> 0.001509287627413869 \n",
            " Training loss : 0.0012204834492877126 , validation_loss : 0.001509287627413869 , Best Valid Loss : 0.001509287627413869 \n",
            " epoch : 1979, Validation loss decreased : 0.001509287627413869 --> 0.0015087855281308293 \n",
            " Training loss : 0.0012201085919514298 , validation_loss : 0.0015087855281308293 , Best Valid Loss : 0.0015087855281308293 \n",
            " epoch : 1980, Validation loss decreased : 0.0015087855281308293 --> 0.00150852813385427 \n",
            " Training loss : 0.0012197005562484264 , validation_loss : 0.00150852813385427 , Best Valid Loss : 0.00150852813385427 \n",
            " epoch : 1981, Validation loss decreased : 0.00150852813385427 --> 0.0015078624710440636 \n",
            " Training loss : 0.0012191907735541463 , validation_loss : 0.0015078624710440636 , Best Valid Loss : 0.0015078624710440636 \n",
            " epoch : 1982, Validation loss decreased : 0.0015078624710440636 --> 0.0015078007709234953 \n",
            " Training loss : 0.0012189315166324377 , validation_loss : 0.0015078007709234953 , Best Valid Loss : 0.0015078007709234953 \n",
            " epoch : 1983, validation loss did not decrease \n",
            " Training loss : 0.0012186503736302257 , validation_loss : 0.0015078614233061671 , Best Valid Loss : 0.0015078007709234953 \n",
            " epoch : 1984, Validation loss decreased : 0.0015078007709234953 --> 0.001507473993115127 \n",
            " Training loss : 0.0012184317456558347 , validation_loss : 0.001507473993115127 , Best Valid Loss : 0.001507473993115127 \n",
            " epoch : 1985, Validation loss decreased : 0.001507473993115127 --> 0.0015070115914568305 \n",
            " Training loss : 0.0012182446662336588 , validation_loss : 0.0015070115914568305 , Best Valid Loss : 0.0015070115914568305 \n",
            " epoch : 1986, Validation loss decreased : 0.0015070115914568305 --> 0.0015068108914420009 \n",
            " Training loss : 0.0012181128840893507 , validation_loss : 0.0015068108914420009 , Best Valid Loss : 0.0015068108914420009 \n",
            " epoch : 1987, validation loss did not decrease \n",
            " Training loss : 0.0012178986798971891 , validation_loss : 0.0015095180133357644 , Best Valid Loss : 0.0015068108914420009 \n",
            " epoch : 1988, validation loss did not decrease \n",
            " Training loss : 0.0012211528373882174 , validation_loss : 0.0015408392064273357 , Best Valid Loss : 0.0015068108914420009 \n",
            " epoch : 1989, validation loss did not decrease \n",
            " Training loss : 0.0012459084391593933 , validation_loss : 0.0015639381017535925 , Best Valid Loss : 0.0015068108914420009 \n",
            " epoch : 1990, validation loss did not decrease \n",
            " Training loss : 0.0012729015434160829 , validation_loss : 0.0015522345202043653 , Best Valid Loss : 0.0015068108914420009 \n",
            " epoch : 1991, validation loss did not decrease \n",
            " Training loss : 0.0012639685301110148 , validation_loss : 0.0015166931552812457 , Best Valid Loss : 0.0015068108914420009 \n",
            " epoch : 1992, validation loss did not decrease \n",
            " Training loss : 0.0012278325157240033 , validation_loss : 0.001506884815171361 , Best Valid Loss : 0.0015068108914420009 \n",
            " epoch : 1993, validation loss did not decrease \n",
            " Training loss : 0.0012177902972325683 , validation_loss : 0.0015268612187355757 , Best Valid Loss : 0.0015068108914420009 \n",
            " epoch : 1994, validation loss did not decrease \n",
            " Training loss : 0.0012380513362586498 , validation_loss : 0.0015447636833414435 , Best Valid Loss : 0.0015068108914420009 \n",
            " epoch : 1995, validation loss did not decrease \n",
            " Training loss : 0.0012545584468171 , validation_loss : 0.0015386879676952958 , Best Valid Loss : 0.0015068108914420009 \n",
            " epoch : 1996, validation loss did not decrease \n",
            " Training loss : 0.0012472473317757249 , validation_loss : 0.0015126215294003487 , Best Valid Loss : 0.0015068108914420009 \n",
            " epoch : 1997, Validation loss decreased : 0.0015068108914420009 --> 0.00150410202331841 \n",
            " Training loss : 0.0012240710202604532 , validation_loss : 0.00150410202331841 , Best Valid Loss : 0.00150410202331841 \n",
            " epoch : 1998, validation loss did not decrease \n",
            " Training loss : 0.0012163739884272218 , validation_loss : 0.001515114912763238 , Best Valid Loss : 0.00150410202331841 \n",
            " epoch : 1999, validation loss did not decrease \n",
            " Training loss : 0.0012274803593754768 , validation_loss : 0.0015251410659402609 , Best Valid Loss : 0.00150410202331841 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#IMP :\n",
        "Note that **state_dict() always stores the best model parameters** during training, Hence when you load it back, You are testing optimal model parameters."
      ],
      "metadata": {
        "id": "Q_uRcu0Xl1f_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Model.load_state_dict( torch.load('./state_dict.pt') )\n",
        "\n",
        "testPred = Model( Xtest ) # object representing the output of LSTM corresponding to Xtest\n",
        "\n",
        "ypred = testPred.data.numpy() # .data() accessess the underlying tensor which is converted to numpy for working with ease\n",
        "\n",
        "ypred = scaler.inverse_transform( ypred ) # Note that output of LSTM is by default scaled by earlier scaler hence scale down with inverse\n"
      ],
      "metadata": {
        "id": "0Ncgi3CCl07K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ypred.size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8JiVyePsqbw",
        "outputId": "904a5820-a343-4fd5-878b-fbfe8061d9f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "349"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets use last 2 windows for testing (12*2 = 24 values)\n",
        "\n",
        "df_test = train.iloc[-96:].copy()\n",
        "\n",
        "df_test['pred'] = ypred[-96:]  # Append ypred to df_test dataframe\n"
      ],
      "metadata": {
        "id": "lAY8E2bjpFx0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.rename( columns={'IPG2211A2N' : 'values'}, inplace= True )\n",
        "df_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "YmOAcN4pt_bo",
        "outputId": "bbce2c83-07b7-4c28-a569-e3edb1658fd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              values        pred\n",
              "DATE                            \n",
              "2010-02-01  110.5330  108.189247\n",
              "2010-03-01   98.2672   98.022636\n",
              "2010-04-01   86.3000   89.566872\n",
              "2010-05-01   90.8364   87.842155\n",
              "2010-06-01  104.3538  101.199883\n",
              "...              ...         ...\n",
              "2017-09-01   98.6154  101.331413\n",
              "2017-10-01   93.6137   91.242645\n",
              "2017-11-01   97.3359   95.823662\n",
              "2017-12-01  114.7212  109.888031\n",
              "2018-01-01  129.4048  116.399162\n",
              "\n",
              "[96 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a5a68d1e-3a57-4f26-9fd4-2a43c9b9857d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>values</th>\n",
              "      <th>pred</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DATE</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2010-02-01</th>\n",
              "      <td>110.5330</td>\n",
              "      <td>108.189247</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-03-01</th>\n",
              "      <td>98.2672</td>\n",
              "      <td>98.022636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-04-01</th>\n",
              "      <td>86.3000</td>\n",
              "      <td>89.566872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-05-01</th>\n",
              "      <td>90.8364</td>\n",
              "      <td>87.842155</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-06-01</th>\n",
              "      <td>104.3538</td>\n",
              "      <td>101.199883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-09-01</th>\n",
              "      <td>98.6154</td>\n",
              "      <td>101.331413</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-10-01</th>\n",
              "      <td>93.6137</td>\n",
              "      <td>91.242645</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-11-01</th>\n",
              "      <td>97.3359</td>\n",
              "      <td>95.823662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-12-01</th>\n",
              "      <td>114.7212</td>\n",
              "      <td>109.888031</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-01-01</th>\n",
              "      <td>129.4048</td>\n",
              "      <td>116.399162</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>96 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a5a68d1e-3a57-4f26-9fd4-2a43c9b9857d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a5a68d1e-3a57-4f26-9fd4-2a43c9b9857d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a5a68d1e-3a57-4f26-9fd4-2a43c9b9857d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e154318f-6c71-4f41-8195-2cd7432bde4c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e154318f-6c71-4f41-8195-2cd7432bde4c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e154318f-6c71-4f41-8195-2cd7432bde4c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_91941e3d-994a-4fcc-ba30-bbc76087e7ef\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_test')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_91941e3d-994a-4fcc-ba30-bbc76087e7ef button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_test');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_test",
              "summary": "{\n  \"name\": \"df_test\",\n  \"rows\": 96,\n  \"fields\": [\n    {\n      \"column\": \"DATE\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2010-02-01 00:00:00\",\n        \"max\": \"2018-01-01 00:00:00\",\n        \"num_unique_values\": 96,\n        \"samples\": [\n          \"2016-10-01 00:00:00\",\n          \"2016-07-01 00:00:00\",\n          \"2016-03-01 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"values\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9.785380235856366,\n        \"min\": 86.3,\n        \"max\": 129.4048,\n        \"num_unique_values\": 96,\n        \"samples\": [\n          91.4867,\n          114.5397,\n          95.3548\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 96,\n        \"samples\": [\n          91.91697692871094,\n          112.37865447998047,\n          100.35618591308594\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visulation"
      ],
      "metadata": {
        "id": "gQucEsDJpvSn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure( figsize= (12,4) )\n",
        "plt.plot( df_test.index, df_test['values'], label = \"Real Values\" , marker = \"o\" )\n",
        "plt.plot( df_test.index, df_test['pred'], label = \"Predicted Values\", marker = \"o\")\n",
        "plt.ylabel(\"ylabel\")\n",
        "plt.legend(title_fontsize=14, fontsize=13, fancybox=True, shadow=True, frameon=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "id": "P_yXg_nVpuBy",
        "outputId": "9e52a16d-1c5f-47fc-cab2-831513337860"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AsaEQN0sq0Pu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}